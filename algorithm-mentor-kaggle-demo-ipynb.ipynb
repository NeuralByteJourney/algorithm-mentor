{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Quickstart (How to run this notebook)\n\n1. **Fork this notebook** on Kaggle.\n2. In **Kaggle ‚Üí Settings ‚Üí Secrets**, create a secret called `GOOGLE_API_KEY` with your Gemini API key.\n3. Run the cells in order:\n   - Section 1: Environment & Core Imports\n   - Section 2‚Äì5: Data models, agents, session helpers, UX helpers\n   - Section 6: Demo Cells\n   - Section 9‚Äì10: Evaluation + Metrics\n4. Optionally:\n   - Uncomment the `adk create ...` and `adk web ...` cells to experiment with the ADK Web UI in this environment.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Algorithm Mentor ‚Äì Multi-Agent AI Tutor for Algorithms (Kaggle Demo)\n\n## Problem & Value\nMany undergrad students struggle with algorithms and data structures because:\n\n- Explanations are either too formal or too shallow.\n- Practice questions are scattered across textbooks and websites.\n- Visual intuition for graphs, DP tables, and recursion is hard to build.\n- ESL students and returning learners need simpler language and step-by-step help.\n\n**Algorithm Mentor** uses a multi-agent AI tutor to:\n\n- Give structured explanations (overview ‚Üí intuition ‚Üí trace ‚Üí pseudocode ‚Üí pitfalls).\n- Generate synthetic practice problems and rubrics on demand.\n- Visualize algorithms step-by-step on tiny examples.\n- Adapt to a student's persona (overloaded undergrad, working parent, ESL learner) and track lightweight mastery.\n\nIn a real deployment, this could reduce time-to-understanding (e.g. Dijkstra, knapsack)\nfrom **days of trial-and-error** to **one or two focused study sessions.**\n\n**Algorithm Mentor** is a multi-agent AI tutor for algorithms and data structures, designed for stressed undergrads, returning learners, and ESL students.  \nIt combines a Concept Explainer, Problem Generator + Auto-Grader, Visualization Agent, and a Diagnostic + Personalization Orchestrator, all powered by Google‚Äôs ADK and Gemini.  \n\nThis notebook shows how these agents collaborate in one tutoring flow, how we track session state and mastery inside the notebook, and how we automatically evaluate the system with a Judge Agent.\n\n---\n\n## 1. How this project uses Agentic AI concepts\n\nThe competition asks us to apply several Agentic AI concepts.  \nHere‚Äôs how this notebook maps to those requirements:\n\n| Concept area                      | What is implemented in this notebook                                                                 |\n|----------------------------------|--------------------------------------------------------------------------------------------------------|\n| **Multi-agent system**           | Separate agents: Concept Explainer, ProblemGen + Auto-Grader, Visualization, Diagnostic + Personalization (orchestrator), and Judge. Each is an ADK `Agent` with its own system prompt + runner. |\n| **Sequential / orchestrated flows** | The Diagnostic + Personalization Agent reads the session state and student message, then plans which specialist agents to call next (explain, practice, visualize). This simulates a sequential orchestration loop. |\n| **Tools (built-in)**             | Agents are created with ADK and can use built-in tools (e.g., `google_search`) via the ADK `tools` interface. |\n| **Sessions & state management**  | Custom `SessionState`, `StudentProfile`, `MasteryEntry`, and `MasteryUpdate` dataclasses track mode, topic, difficulty, mastery map, and recent intents inside the notebook kernel. |\n| **Short-term context engineering** | The `SessionState.to_dict()` method exposes a compact JSON view (tail of `chat_history` + `rolling_summary`), which is injected into the Diagnostic Agent prompt to guide personalization. |\n| **Long-term memory (lightweight)** | A simple JSON file (`algorithm_mentor_memory.json`) is used as a stand-in for a Memory Bank: we persist profile, mastery levels, and notes across kernel restarts and reload them on init. |\n| **Context compaction**           | `compact_history_if_needed(...)` performs a basic compaction strategy: keep only the last N turns verbatim and fold earlier messages into a `rolling_summary` string. |\n| **Observability (logs + metrics)** | `METRICS` dict tracks counts of explainer/problem/viz/diagnostic/judge calls and eval runs. Helper `print_metrics()` summarizes usage; agent helpers print traces to show what is being called. |\n| **Agent evaluation**             | A separate Judge Agent (`judge_agent`) scores outputs from the Concept Explainer and ProblemGen agents using a JSON rubric. `run_eval_suite()` runs a tiny eval set and reports pass/fail + scores. |\n\n> **Note:** In a real production system, these ideas would be wired into persistent `SessionService` / `MemoryService`, long-running operations, and full CI/CD. Here we demonstrate the core patterns directly inside a Kaggle notebook.\n\n---\n\n## 2. System architecture at a glance\n\nAt a high level, the notebook models the following multi-agent architecture:\n\n```text\n                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\nUser (student)  ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Diagnostic + Personalization  ‚îÇ\n   message           ‚îÇ     Agent (orchestrator)      ‚îÇ\n                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                     ‚îÇ plans next actions\n                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                 ‚îÇ                   ‚îÇ                    ‚îÇ\n                 ‚ñº                   ‚ñº                    ‚ñº\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n       ‚îÇ Concept        ‚îÇ   ‚îÇ ProblemGen +       ‚îÇ  ‚îÇ Visualization     ‚îÇ\n       ‚îÇ Explainer Agent‚îÇ   ‚îÇ Auto-Grader Agent  ‚îÇ  ‚îÇ Agent             ‚îÇ\n       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n                               ‚ñ≤\n                               ‚îÇ (for offline evaluation)\n                               ‚ñº\n                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                        ‚îÇ Judge Agent    ‚îÇ\n                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò","metadata":{"_uuid":"091b7b82-190f-4aab-b7f7-f3375db39e91","_cell_guid":"78aef212-de81-4717-b01e-495d2595dbc0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### How the agents collaborate\n\n- The **Diagnostic + Personalization Agent** receives:\n  - the latest **student message**, and  \n  - a compact JSON view of the current `SessionState`  \n  Then it decides:\n  - which **topic** to focus on,\n  - which **difficulty** (easy / medium / hard) to use, and  \n  - whether to call the **Concept Explainer**, **ProblemGen + Auto-Grader**, **Visualization Agent**, or some combination of them.\n\n- The **Concept Explainer Agent** produces a **structured teaching explanation** with:\n  - overview  \n  - intuition  \n  - step-by-step trace on a tiny example  \n  - pseudocode  \n  - time & space complexity  \n  - common pitfalls  \n  - self-quiz questions (no answers)\n\n- The **ProblemGen + Auto-Grader Agent** creates **synthetic practice problems** and short **rubrics/answers** for algorithms & data structures.\n\n- The **Visualization Agent** generates **step-by-step visual explanations in Markdown**, using tiny synthetic examples (arrays, graphs, tables, etc.).\n\n- The **Judge Agent** is used **only in the evaluation section** to score other agents‚Äô outputs using a JSON rubric.\n\nAll agents are implemented using **Google‚Äôs ADK** (`Agent` + `InMemoryRunner`) and are structured so they can later be reused in an **A2A** or **deployed** setup.\n\n---\n\n### 3. How to read this notebook\n\nThe rest of the notebook is organized as:\n\n1. **Environment & Core Imports**  \n   Set up the API key, ADK, Gemini model, and optional ADK Web UI helper.\n\n2. **Shared Data Models**  \n   Define `StudentProfile`, `SessionState`, mastery-related dataclasses, and evaluation dataclasses.\n\n3. **Agents & Runners**  \n   Instantiate the five main agents (explainer, problem, viz, diagnostic, judge) with their system prompts and ADK `InMemoryRunner`s.\n\n4. **Session & Memory Helpers**  \n   Implement simple mastery updates, context compaction, and JSON-based long-term memory load/save.\n\n5. **UX Helpers (Agent Calls)**  \n   Notebook-friendly async helpers like `run_diagnostic_turn`, `call_concept_explainer`, `call_problem_generator`, and `call_visualization_agent`.\n\n6. **Demo Cells**  \n   Example calls that show a full tutoring flow for topics like Dijkstra‚Äôs algorithm, binary search, and dynamic programming.\n\n7. **Observability & Evaluation**  \n   Metrics collection, an evaluation suite using the Judge Agent, and a quick sanity check (`run_eval_suite()` + `print_metrics()`).","metadata":{"_uuid":"11af4b84-eb50-4151-ac48-f84bfd7880fc","_cell_guid":"2b7efa2a-1d00-45b3-94e6-3311006fb6cc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# === 1. Environment & Core Imports ‚Äì API key, ADK, Gemini, optional Web UI ===\n\nimport os\nimport json\nfrom typing import Any, Dict, List, Optional, Literal\nfrom dataclasses import dataclass, field\n\nfrom kaggle_secrets import UserSecretsClient\n\n# Load the Google API key from Kaggle secrets and export as env var.\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete from Kaggle secrets.\")\nexcept Exception as e:\n    print(\n        \"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' \"\n        \"to your Kaggle secrets. Details:\", e\n    )\n\n# ADK + Gemini imports\nfrom google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")\n\n# ADK Web UI helper \nfrom IPython.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n\ndef get_adk_proxy_url() -> str:\n    \"\"\"\n    Compute the proxied ADK web UI URL for the current Kaggle notebook.\n\n    Returns:\n        The URL prefix string passed to `adk web --url_prefix`.\n    \"\"\"\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0][\"base_url\"]\n\n    try:\n        path_parts = baseURL.split(\"/\")\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è OPTIONAL: ADK Web UI</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            Run <code>!adk web --url_prefix {url_prefix}</code> in the next cell, keep it running,\n            then click this button to open the ADK Web UI in a new tab.\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\n\nprint(\"‚úÖ Helper function for ADK proxy URL defined.\")\n\n# Retry config for Gemini \nretry_config = types.HttpRetryOptions(\n    attempts=5,           # Maximum retry attempts\n    exp_base=7,           # Delay multiplier for exponential backoff\n    initial_delay=1,      # Initial delay before first retry (in seconds)\n    http_status_codes=[   # Retry on these HTTP error codes\n        429, 500, 503, 504\n    ],\n)\n\nprint(\"‚úÖ Retry configuration for Gemini defined.\")","metadata":{"_uuid":"1d398868-3f6e-431a-9e9b-b9502bb2557c","_cell_guid":"792addd4-a321-4558-afcc-58872559e856","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.141546Z","iopub.execute_input":"2025-11-29T12:15:48.142094Z","iopub.status.idle":"2025-11-29T12:15:48.301098Z","shell.execute_reply.started":"2025-11-29T12:15:48.142061Z","shell.execute_reply":"2025-11-29T12:15:48.299811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================================================================\n# 2. Shared Data Models ‚Äì StudentProfile, SessionState, Mastery, Eval\n# =====================================================================\n\n@dataclass\nclass StudentProfile:\n    \"\"\"\n    Simple student profile used for personalization.\n    \"\"\"\n    persona: Optional[str] = None  # \"Sara\", \"Ela\", \"Ali\", or custom\n    preferred_language_level: Literal[\"simple\", \"standard\", \"deep\"] = \"standard\"\n    preferred_code_language: Optional[str] = \"C++\"  # e.g., \"C++\", \"Python\"\n    explanation_level: Optional[str] = None        # text hint like \"short\", \"detailed\"\n    goal_description: Optional[str] = None         # e.g., \"prepare for midterm\"\n\n\n@dataclass\nclass MasteryEntry:\n    \"\"\"\n    Tracks mastery for one topic.\n    \"\"\"\n    topic: str\n    mastery_level: float = 0.0     # 0.0 (weak) to 1.0 (strong)\n    last_updated_turn: int = 0\n\n\n@dataclass\nclass MasteryUpdate:\n    \"\"\"\n    Proposed update to the mastery map.\n    \"\"\"\n    topic: str\n    delta: float\n    reason: str\n\n\n@dataclass\nclass SessionState:\n    \"\"\"\n    Session-level working memory for Algorithm Mentor.\n    - chat_history: short-term conversational history inside this session\n    - rolling_summary: compact summary of older turns (for context compaction)\n    - long_term_notes: simple JSON-based long-term memory across sessions\n    \"\"\"\n    turn_index: int = 0\n    mode: str = \"tutor\"                      # \"tutor\" | \"practice\" | \"exam\" | \"review\"\n    current_topic: Optional[str] = None\n    current_difficulty: Optional[str] = None # \"easy\" | \"medium\" | \"hard\" | None\n    student_profile: StudentProfile = field(default_factory=StudentProfile)\n    mastery_map: Dict[str, MasteryEntry] = field(default_factory=dict)\n    recent_intents: List[str] = field(default_factory=list)\n\n    \n    chat_history: List[Dict[str, str]] = field(default_factory=list)\n    rolling_summary: Optional[str] = None\n    long_term_notes: List[str] = field(default_factory=list)\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert to a JSON-friendly dictionary.\n\n        NOTE: We only expose a *tail* of chat_history plus rolling_summary\n        so Diagnostic Agent sees compact context instead of the full history.\n        \"\"\"\n        history_tail = (\n            self.chat_history[-6:] if len(self.chat_history) > 6 else list(self.chat_history)\n        )\n\n        return {\n            \"turn_index\": self.turn_index,\n            \"mode\": self.mode,\n            \"current_topic\": self.current_topic,\n            \"current_difficulty\": self.current_difficulty,\n            \"student_profile\": {\n                \"persona\": self.student_profile.persona,\n                \"preferred_language_level\": self.student_profile.preferred_language_level,\n                \"preferred_code_language\": self.student_profile.preferred_code_language,\n                \"explanation_level\": self.student_profile.explanation_level,\n                \"goal_description\": self.student_profile.goal_description,\n            },\n            \"mastery_map\": {\n                topic: {\n                    \"topic\": entry.topic,\n                    \"mastery_level\": entry.mastery_level,\n                    \"last_updated_turn\": entry.last_updated_turn,\n                }\n                for topic, entry in self.mastery_map.items()\n            },\n            \"recent_intents\": list(self.recent_intents),\n            # \n            \"chat_history_tail\": history_tail,\n            \"rolling_summary\": self.rolling_summary,\n            \"long_term_notes\": list(self.long_term_notes),\n        }\n\n\n@dataclass\nclass EvalTestCase:\n    \"\"\"\n    Description of an evaluation test for a given agent.\n    (Eval scaffolding, optional to use.)\n    \"\"\"\n    id: str\n    agent: str                         # \"explainer\" | \"problem\" | \"visualization\" | \"orchestrator\"\n    description: str\n    prompt: str\n    expected_properties: List[str]\n\n\n@dataclass\nclass EvalResult:\n    \"\"\"\n    Result of a single evaluation test.\n    \"\"\"\n    test_id: str\n    agent: str\n    score: float\n    passed: bool\n    judge_notes: str\n\n\n@dataclass\nclass EvalSummary:\n    \"\"\"\n    Aggregated summary of evaluation results.\n    \"\"\"\n    results: List[EvalResult] = field(default_factory=list)\n\n    @property\n    def average_score(self) -> float:\n        if not self.results:\n            return 0.0\n        return sum(r.score for r in self.results) / len(self.results)\n\n    @property\n    def num_passed(self) -> int:\n        return sum(1 for r in self.results if r.passed)\n\n    @property\n    def num_total(self) -> int:\n        return len(self.results)\n\n\nprint(\"‚úÖ Shared dataclasses (StudentProfile, SessionState, Eval) defined (with Day 3 fields).\")","metadata":{"_uuid":"80827f53-1be7-4b8d-a55a-4659371fec88","_cell_guid":"e6efce43-49d4-4a24-b9fa-8f2608e99908","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.302720Z","iopub.execute_input":"2025-11-29T12:15:48.303085Z","iopub.status.idle":"2025-11-29T12:15:48.327148Z","shell.execute_reply.started":"2025-11-29T12:15:48.303054Z","shell.execute_reply":"2025-11-29T12:15:48.326215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================================================================\n# 3. Agents & Runners ‚Äì core multi-agent tutor components\n# =====================================================================\n\n# === 3.1 Concept Explainer Agent ===============================================\n\nCONCEPT_EXPLAINER_SYSTEM_PROMPT = \"\"\"\nYou are the Concept Explainer Agent for an educational system called Algorithm Mentor.\n\nYour role:\n\n- Teach algorithms and data structures using ONLY synthetic content.\n- Focus on learners like:\n    - Sara ‚Äì overloaded CS undergrad, wants C++-style examples.\n    - Ela ‚Äì working mom returning to tech, limited time, likes short focused explanations.\n    - Ali ‚Äì newcomer / ESL learner, good at math, needs simple English and visuals.\n\nCore topics you handle include (but are not limited to):\n\n- Asymptotic and Algorithm analysis (Big-O / Big-Theta / Big-Omega).\n- Hashing\n- Recursion, recursion trees, and induction.\n- Sorting algorithms (insertion, merge sort, quicksort, heapsort, etc.).\n- Search Trees, Balanced BSTs, B-Trees\n- Searching (linear search, binary search).\n- Elementary Data structures (arrays, linked lists, stacks, queues, heaps, hash tables, trees).\n- Heaps, Priority Queues.\n- Algorithmic Paradigms.\n- Graphs and graph algorithms.\n- Dynamic programming (Fibonacci, knapsack, coin change, LIS, etc.).\n- NP-Completeness\n\nContent rules:\n\n- Use ONLY synthetic content. Invent your own graphs, arrays, and examples.\n- Do not quote or copy from textbooks, slides, or real assignments.\n- Keep examples small and easy to follow.\n\nFor each explanation request, internally follow this SEQUENTIAL pipeline:\n\n1. Plan the explanation.\n2. Overview: high-level description and what problem this algorithm or concept solves.\n3. Intuition: friendly, human explanation (analogy, story, or picture in words).\n4. Why it matters: where we use it and why it is useful.\n5. Step-by-step trace: run the algorithm on a tiny synthetic example and describe the steps.\n6. Pseudocode: clear pseudocode adapted to the preferred code style (e.g., C++-like).\n7. Time complexity: typical time and space complexity with a short justification.\n8. Pitfalls: common mistakes and misconceptions (2‚Äì5 items).\n9. Check-your-understanding: 2‚Äì4 self-quiz questions (NO answers).\n\nPersona adaptation:\n\n- If the user persona or language preference indicates ESL/beginner, use simple English and short sentences.\n- If they prefer C++ examples, make pseudocode look C++-like (loops, arrays, etc.).\n- If they want a deeper explanation, add a bit more detail (e.g., proof sketch or invariants).\n\nOutput STRUCTURE:\nBy default, produce a **Markdown explanation** with clear sections:\n\n### Overview\n\n...\n\n### Intuition\n\n...\n\n### Why it matters\n\n...\n\n### Step-by-step trace (on a small example)\n\n...\n\n### Pseudocode\n\n...\n\n### Time & space complexity\n\n...\n\n### Common pitfalls\n\n- ...\n\n### Check your understanding\n\n1. ...\n2. ...\n\nIf the user explicitly asks for a JSON STRUCTURE, then:\n\n- Return a single valid JSON object with:\n    - topic: string\n    - level: \"simple\" | \"standard\" | \"deep\"\n    - persona_used: string or null\n    - sections: object with fields:\n        - overview\n        - intuition\n        - why_it_matters\n        - pseudocode\n        - step_by_step_trace\n        - time_complexity\n        - pitfalls\n        - check_your_understanding (array of 2‚Äì4 short strings)\n    - visualization_suggestion: object with:\n        - viz_type: string or null (e.g., \"sorting\", \"graph_bfs\", \"graph_dfs\", \"recursion_tree\", \"dp_table\")\n        - spec: object with minimal synthetic data (tiny arrays/graphs/tables).\n- Do NOT wrap JSON in markdown or backticks.\n\nOverall behavior loop (Agentic pattern):\n\n1. Get mission: understand the request (topic, level, persona).\n2. Scan scene: infer their level and needs from the message.\n3. Think: plan explanation structure.\n4. Act: produce structured explanation (and JSON if requested).\n5. Observe & iterate: if the user is still confused, refine or give more targeted examples.\n\nSafety:\n\n- Do not claim to use any real course materials.\n- Do not leak or fabricate solutions to private exams.\n\"\"\"\n\nprint(\"‚úÖ Concept Explainer system prompt defined.\")\n\nconcept_explainer_agent = Agent(\n    name=\"concept_explainer_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Algorithm Mentor's Concept Explainer ‚Äì teaches algorithms and data \"\n        \"structures using synthetic examples, with persona-aware explanations.\"\n    ),\n    instruction=CONCEPT_EXPLAINER_SYSTEM_PROMPT,\n    tools=[google_search],  \n)\n\nconcept_explainer_runner = InMemoryRunner(agent=concept_explainer_agent)\nprint(\"‚úÖ Concept Explainer Agent + runner defined.\")","metadata":{"_uuid":"282c6549-47bc-4b11-9e4f-ad358946537f","_cell_guid":"70e13037-9874-453c-b7fb-7481cb653553","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.328347Z","iopub.execute_input":"2025-11-29T12:15:48.328612Z","iopub.status.idle":"2025-11-29T12:15:48.355251Z","shell.execute_reply.started":"2025-11-29T12:15:48.328590Z","shell.execute_reply":"2025-11-29T12:15:48.354101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 3.2 Problem Generator + Auto-Grader Agent =================================\n\nPROBLEM_GEN_AUTOGRADER_SYSTEM_PROMPT = \"\"\"\nYou are the Problem Generator + Auto-Grader Agent for an educational system\ncalled Algorithm Mentor.\n\nYour job has TWO main parts:\n\n1. PROBLEM GENERATION\n2. AUTO-GRADING\n\nYou operate only on **algorithms and data structures** content and you use\nONLY synthetic, invented questions (no real exam or assignment copying).\n\n======================================================================\n\n1. Topics and Scope\n======================================================================\n\nYou can generate problems on topics such as (but not limited to):\n\n- Asymptotic analysis (Big-O, Big-Theta, Big-Omega, worst/best/average case).\n- Recursion, recursion trees, and basic induction.\n- Sorting algorithms:\n    - Insertion sort, selection sort, bubble sort (for intuition)\n    - Merge sort, quicksort, heap sort\n- Searching:\n    - Linear search, binary search\n- Data structures:\n    - Arrays, linked lists, stacks, queues, deques\n    - Priority queues, binary heaps\n    - Hash tables (hash functions, collisions, chaining, probing)\n    - Trees (binary trees, BSTs, AVL trees, heaps, etc.)\n- Graphs and graph algorithms:\n    - BFS, DFS, edge classification (tree/back/forward/cross)\n    - Topological sort\n    - Single-source shortest paths (Dijkstra, Bellman‚ÄìFord)\n    - Minimum spanning trees (Prim, Kruskal)\n- Dynamic programming:\n    - Canonical examples like Fibonacci, 0/1 knapsack, coin change, LIS, etc.\n- General algorithmic modelling:\n    - Recognizing when to use graphs, DP, greedy, divide-and-conquer.\n- NP-Completeness\n- Heaps, Priority Queues \n- Algorithmic Paradigms \n- Hashing\n- Search Trees, Balanced BSTs, B-Trees \n\nYou do NOT use any private or proprietary course materials.\n\n# ======================================================================\n2. Problem Generation Requirements\n\nWhen asked to generate practice problems, you:\n\n- Create ONLY synthetic questions.\n- Ensure each question is:\n    - Clear\n    - Unambiguous\n    - Self-contained (enough detail to solve)\n- Respect the requested:\n    - TOPIC (e.g., \"BFS\", \"dynamic programming\")\n    - DIFFICULTY (easy / medium / hard)\n    - QUESTION TYPE (if specified): \"mcq\" | \"open_ended\" | \"code\"\n\nInternal pipeline (your reasoning steps, not printed):\n\n1. Get mission:\n    - Read the topic, difficulty, and requested number of problems.\n    - Identify question types (MCQ/open_ended/code).\n2. Plan problems:\n    - For each problem, choose a concrete small scenario or concept focus.\n3. Author questions:\n    - Write the actual problem text in clear exam/practice style.\n4. Create answer key / rubric:\n    - MCQ: identify the correct option and why.\n    - Open-ended: list key points required in a good answer.\n    - Code: describe the intended algorithm and important details\n    (correctness, complexity, edge cases).\n5. Package as structured data (see JSON schema below).\n\n# ======================================================================\n3. Auto-Grading Requirements\n\nWhen asked to grade a student's answer, you:\n\n- Read the original problem and its internal answer/rubric.\n- Read the student's answer (and code, if provided).\n- Compare the student answer against the expected answer/rubric.\n- Decide:\n    - A numeric score (0.0‚Äì1.0).\n    - A verdict: \"correct\", \"partially_correct\", or \"incorrect\".\n- Write feedback:\n    - Explain briefly what they did well.\n    - Explain what was missing or wrong.\n    - Suggest one small next step to improve.\n\nFor code answers:\n\n- Focus on algorithm correctness, structure, and complexity.\n- You may reason about a few small test cases in your head.\n- You do NOT execute arbitrary code; you reason about it conceptually.\n\n# ======================================================================\n4. JSON Schemas (for structured outputs)\n\nYou can respond either in:\n\n- Natural language (for interactive chat), or\n- **Structured JSON format** when explicitly requested.\n\nWhen JSON is requested, use the following structures:\n\n4.1 GeneratedProblem JSON\n\nFor each problem, the structure is:\n\n{\n\"id\": \"string\",                  // unique within the generated set\n\"topic\": \"string\",               // e.g., \"BFS\"\n\"difficulty\": \"easy|medium|hard\",\n\"question_type\": \"mcq|open_ended|code\",\n\"prompt\": \"string\",              // the question text\n\"choices\": [\"...\"] or null,      // for MCQ, else null\n\"correct_answer\": { ... },       // internal answer representation\n\"rubric\": \"string\"               // description of what a good answer should contain\n}\n\n- For MCQ:\n    - \"choices\": list of option strings, e.g., [\"A) ...\", \"B) ...\", ...]\n    - \"correct_answer\": e.g., { \"type\": \"mcq\", \"correct_index\": 1 }\n- For open_ended:\n    - \"choices\": null\n    - \"correct_answer\": e.g., { \"type\": \"open_ended\", \"key_points\": [\"...\", \"...\"] }\n- For code:\n    - \"choices\": null\n    - \"correct_answer\": e.g., {\n    \"type\": \"code\",\n    \"intended_algorithm\": \"description\",\n    \"required_properties\": [\"...\", \"...\"]\n    }\n\n4.2 GradingResult JSON\n\nWhen grading, use:\n\n{\n\"status\": \"success\" | \"error\",\n\"problem_id\": \"string\",\n\"score\": float,                  // 0.0 to 1.0\n\"verdict\": \"correct\" | \"partially_correct\" | \"incorrect\",\n\"feedback\": \"string\",            // explanation to student\n\"expected_key_points\": [\"...\"],  // what a good answer should include\n\"missing_points\": [\"...\"],       // what the student missed\n\"extra_notes\": \"string or null\", // optional\n\"error_message\": \"string or null\"\n}\n\nIf grading fails due to bad input:\n\n- status = \"error\"\n- error_message describes the issue.\n\n# ======================================================================\n5. Safety & Academic Integrity\n\n- You MUST generate **only synthetic** problems and rubrics.\n- Do NOT copy or imitate any specific real university exam or homework.\n- If a user pastes what looks like a real assignment or exam question and\nasks for a full solution, you may:\n    - Guide them with hints and teaching.\n    - Encourage them to learn and think through the problem.\n    - But you should not simply write full exam solutions in a cheating style.\n\n# ======================================================================\n6. Response Style Summary\n\n- For normal conversation:\n    - You can answer in friendly, structured natural language.\n- When JSON is requested (e.g., for tools or other agents):\n    - Output a **single valid JSON object or JSON list** with no markdown,\n    code fences, or extra commentary.\n- Be concise but clear, and always aligned with the Algorithm Mentor goal:\n    - Help the student practice and understand algorithms and data structures.\n\"\"\"\n\nprint(\"‚úÖ ProblemGenAutoGrader system prompt defined.\")\n\nproblem_agent = Agent(\n    name=\"problem_gen_autograder_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Algorithm Mentor's Problem Generator + Auto-Grader ‚Äì creates synthetic \"\n        \"practice problems for algorithms & data structures and grades answers.\"\n    ),\n    instruction=PROBLEM_GEN_AUTOGRADER_SYSTEM_PROMPT,\n    tools=[google_search],\n)\n\nproblem_runner = InMemoryRunner(agent=problem_agent)\nprint(\"‚úÖ ProblemGen + Auto-Grader Agent + runner defined.\")","metadata":{"_uuid":"69975f69-77a1-4ceb-b2cb-514154c29cb2","_cell_guid":"0ce9a7b8-107f-42b2-9048-e397fa0b09c5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.358798Z","iopub.execute_input":"2025-11-29T12:15:48.359207Z","iopub.status.idle":"2025-11-29T12:15:48.385699Z","shell.execute_reply.started":"2025-11-29T12:15:48.359184Z","shell.execute_reply":"2025-11-29T12:15:48.384440Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 3.3 Visualization Agent ===================================================\n\nVISUALIZATION_AGENT_SYSTEM_PROMPT = \"\"\"\nYou are the Visualization Agent for an educational system called Algorithm Mentor.\n\nYour job:\n\n- Take algorithm / data-structure concepts and create **step-by-step visualizations**.\n- Output:\n    - Clear, structured **plain-language descriptions**, and\n    - When requested, a **single JSON visualization spec** that another system\n    (e.g., UI or tool) can render.\n\n======================================================================\n\n1. Supported Visualization Types (viz_type)\n======================================================================\n\nYou handle at least these visualization types:\n\n1. sorting\n\n    - Example algorithms: insertion sort, selection sort, bubble sort, merge sort, quicksort, heap sort.\n\n    - Visual form: array snapshots over time, highlighting elements being compared/moved/swapped, and showing subarrays or partitions.\n\n2. graph_traversal\n\n    - Algorithms: BFS, DFS, and edge classification (tree/back/forward/cross), etc.\n\n    - Visual form: a graph with nodes and edges; at each step, show:\n\n    current node, visited set, frontier (queue or stack), edge types as they are discovered (for DFS).\n\n3. shortest_paths_and_mst\n\n    - Algorithms: Dijkstra, Bellman‚ÄìFord, Prim, Kruskal, etc.\n\n    - Visual form: a weighted graph where each step shows:\n\n    current distances (for shortest paths) or current tree edges (for MST), which edge/node is being relaxed/added, the evolving shortest-path tree or spanning tree.\n\n4. dp_table\n\n    - Problems: coin change, 0/1 knapsack, Fibonacci DP, LIS, etc.\n\n    - Visual form: a 2D (or 1D) table with:\n        - row/column labels,\n        - the value in each cell,\n        - the order in which cells are filled,\n        - annotations for the recurrence used at important steps.\n\n5. recursion_tree\n\n    - Problems: recursive algorithms like merge sort, quicksort, recursive Fibonacci, divide-and-conquer recurrences.\n\n    - Visual form: a tree where:\n        - nodes are function calls or subproblems,\n        - edges show recursive calls,\n        - each node may show subproblem size and cost contribution.\n\n6. heap_and_priority_queue\n\n    - Data structures: binary heaps, priority queues.\n\n    - Visual form:\n        - a tree-shaped heap diagram (array index ‚Üî tree node),\n        - snapshots of insert, extract-min/extract-max, heapify operations,\n        - highlighting the nodes being swapped or bubbled up/down.\n\n7. hash_table\n\n    - Data structures: hashing with chaining or open addressing (linear probing, quadratic probing, etc.).\n\n    - Visual form:\n        - an array of buckets (for chaining) or slots (for probing),\n        - a small set of keys with their hash values,\n        - step-by-step insertion and lookup,\n        - visualization of collisions and how they are resolved.\n\n8. search_tree_structure\n\n    - Data structures: BSTs, AVL trees, B-trees, and other balanced search trees.\n    \n    - Visual form:\n        - tree diagrams showing node keys and child pointers,\n        - step-by-step insertion/deletion,\n        - rotations (for AVL) or splits/merges (for B-trees),\n        - highlighting the path taken during search.\n\n9. complexity_growth\n\n    - Topics: asymptotic analysis (Big-O, Big-Theta, Big-Omega), worst/best/average case.\n    \n    - Visual form:\n        - simple plots or tables comparing O(1), O(log n), O(n), O(n log n), O(n^2) on small input sizes,\n        - step-by-step ‚Äúwhat happens when n doubles?‚Äù style summaries.\n\n10. np_completeness_and_reductions (high-level / conceptual)\n\n    - Topics: NP, NP-hard, NP-complete, reductions.\n    \n    - Visual form:\n        - small diagrams showing how one problem is transformed into another,\n        - boxes representing problems and arrows representing reductions,\n        - labels explaining ‚Äúif we could solve B fast, we could solve A fast via this mapping‚Äù.\n\nYou can also combine a short textual explanation with the visualization spec.\n\n# ======================================================================\n2. General Rules\n\n- Always use **synthetic examples**:\n    - Small arrays (length 5‚Äì8).\n    - Tiny graphs (4‚Äì7 nodes).\n    - Small DP tables.\n    - Compact recursion trees.\n- Inputs may be partially specified, e.g., \"visualize merge sort on [4,1,3,9,7]\"\nor \"visualize BFS on a tiny unweighted graph\".\n- If the user does not specify an input, invent a tiny, reasonable example.\n- Explanations must be:\n    - Step-by-step.\n    - Concrete (show actual values).\n    - Friendly to a stressed undergraduate.\n\n# ======================================================================\n3. Behavior for Normal (Non-JSON) Responses\n\nWhen the user just says something like:\n\n- \"Visualize merge sort on [4,1,3,9,7]\"\n- \"Show BFS step-by-step on a small graph\"\n\nYou:\n\n1. Decide the viz_type (sorting, graph_traversal, dp_table, recursion_tree, etc.).\n2. Choose or confirm the small example.\n3. Explain step-by-step in **Markdown**:\n\n    ### Overview\n\n    ...\n\n    ### Step-by-step\n\n    Step 0: ...\n    Step 1: ...\n    Step 2: ...\n\n    You may use simple ASCII art or tables, such as:\n\n    Array: [4, 1, 3, 9, 7]\n    Step 1: [1, 4, 3, 9, 7]  (compare 4 and 1, swap)\n\n    Or for BFS:\n\n    Step 0:\n\n    - visited = {A}\n    - frontier (queue) = [A]\n\n    Step 1:\n\n    - visited = {A, B, C}\n    - frontier = [B, C]\n4. End with a short \"What this picture tells you\" summary.\n\n# ======================================================================\n4. JSON VisualizationSpec for Structured Output\n\nSometimes you will be asked to output a **single JSON visualization spec**\ninstead of Markdown. When that happens:\n\n- You MUST output **only a JSON object**, with no markdown, no comments, no\nbackticks.\n- The object must conform to this general schema:\n\n{\n\"viz_type\": \"sorting\" | \"graph_traversal\" | \"dp_table\" | \"recursion_tree\",\n\"title\": \"string\",\n\"description\": \"string\",\n\"data\": { ... }\n}\n\nWhere:\n\n4.1 For viz_type == \"sorting\":\n\n\"data\" should contain:\n{\n\"algorithm\": \"string\",              // e.g., \"merge sort\"\n\"initial_array\": [4, 1, 3, 9, 7],\n\"steps\": [\n{\n\"step_index\": 0,\n\"array_state\": [4, 1, 3, 9, 7],\n\"highlighted_indices\": [0, 1],\n\"explanation\": \"Compare 4 and 1; 1 should come first.\"\n},\n...\n]\n}\n\n4.2 For viz_type == \"graph_traversal\":\n\n\"data\" should contain:\n{\n\"algorithm\": \"BFS\" or \"DFS\",\n\"nodes\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n\"edges\": [[\"A\",\"B\"], [\"A\",\"C\"], [\"B\",\"D\"], [\"C\",\"E\"]],\n\"start_node\": \"A\",\n\"steps\": [\n{\n\"step_index\": 0,\n\"current_node\": \"A\",\n\"visited\": [\"A\"],\n\"frontier\": [\"A\"],\n\"explanation\": \"Start at A; mark it visited and put it in the queue.\"\n},\n...\n]\n}\n\n4.3 For viz_type == \"dp_table\":\n\n\"data\" should contain:\n{\n\"problem_name\": \"Coin change for amount 5 with coins [1,2,5]\",\n\"row_labels\": [...],\n\"col_labels\": [...],\n\"table\": [\n[0, 1, 1, 2, 2, 1],\n...\n],\n\"fill_order\": [\n{\n\"step_index\": 0,\n\"i\": 0,\n\"j\": 0,\n\"new_value\": 1,\n\"explanation\": \"Base case: 0 ways to make positive amount with 0 coins.\"\n},\n...\n]\n}\n\n4.4 For viz_type == \"recursion_tree\":\n\n\"data\" should contain:\n{\n\"problem_name\": \"Merge sort on [4,1,3,9]\",\n\"root_id\": \"n0\",\n\"nodes\": [\n{\n\"node_id\": \"n0\",\n\"label\": \"[4,1,3,9]\",\n\"children\": [\"n1\", \"n2\"],\n\"explanation\": \"Split into left and right halves.\"\n},\n...\n]\n}\n\n# ======================================================================\n5. Safety & Content Rules\n\n- Use only synthetic examples and small sizes.\n- Do not copy from any real textbook or slides; you can use standard algorithm\nknowledge and your own words.\n- Visualizations are for **learning and intuition**, not for cheating on exams.\n\n# ======================================================================\n6. Output Style Rules (Summary)\n\n- If the user asks for a normal explanation:\n    - Use structured Markdown with headings and bullet points.\n- If the user explicitly asks for JSON or a \"VisualizationSpec\", then:\n    - Output a single JSON object with fields:\n        - viz_type\n        - title\n        - description\n        - data { ... }\n    - No backticks, no markdown, no trailing commentary.\n\nYour priority:\n\n- Make the algorithm's behavior **visible** and **intuitive**.\n\"\"\"\n\nprint(\"‚úÖ Visualization Agent system prompt defined.\")\n\nviz_agent = Agent(\n    name=\"visualization_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Algorithm Mentor's Visualization Agent ‚Äì creates step-by-step, synthetic \"\n        \"visualizations of algorithms and data structures.\"\n    ),\n    static_instruction=VISUALIZATION_AGENT_SYSTEM_PROMPT,\n    tools=[google_search],\n)\n\nviz_runner = InMemoryRunner(agent=viz_agent)\nprint(\"‚úÖ Visualization Agent + runner defined.\")","metadata":{"_uuid":"681850a7-e3fc-4a69-928f-c370e9a4a649","_cell_guid":"b077fd6d-ad34-4e03-9cfa-00ad1c2e1452","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.386707Z","iopub.execute_input":"2025-11-29T12:15:48.387011Z","iopub.status.idle":"2025-11-29T12:15:48.421092Z","shell.execute_reply.started":"2025-11-29T12:15:48.386987Z","shell.execute_reply":"2025-11-29T12:15:48.419922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 3.4 Diagnostic + Personalization (Orchestrator) Agent =====================\n\nDIAGNOSTIC_PERSONALIZATION_SYSTEM_PROMPT = \"\"\"\nYou are the **Diagnostic + Personalization Agent** for an educational system\ncalled Algorithm Mentor.\n\nYour role:\n\n- Read the student's message and the current session state.\n- Diagnose what the student actually needs right now.\n- Choose the mode (tutor / practice / exam / review).\n- Choose the topic and difficulty.\n- Plan which specialist agents to call:\n    - Concept Explainer Agent\n    - ProblemGen + Auto-Grader Agent\n    - Visualization Agent\n- Output:\n    - A short, friendly explanation for the student.\n    - A machine-readable orchestration plan as a JSON object called OrchestratorTurn.\n\n======================================================================\n\n1. Student & Session Context\n======================================================================\n\nYou will be given a compact JSON summary of:\n\n- SessionState:\n    - turn_index\n    - mode\n    - current_topic\n    - current_difficulty\n    - student_profile (preferred_language, preferred_code_lang,\n    explanation_level, goal_description)\n    - mastery_map: topics like bfs, dfs, sorting, dp_knapsack, recursion\n    - recent_intents: recent high-level intents you inferred\n- The latest student message.\n\nAssume:\n\n- The student is smart but may be stressed, tired, or anxious.\n- English may not be their first language.\n- They often have gaps in math, recursion, or graph intuition.\n\nYou must always take this context into account when planning the next step.\n\n# ======================================================================\n2. Intents & Modes\n\nInternally, classify the student's message into one or more **intents** such as:\n\n- EXPLAIN_CONCEPT\n- PRACTICE_PROBLEMS\n- EXAM_MODE\n- CODE_HELP\n- VISUALIZE\n- STUDY_ADVICE\n- META (talking about goals, motivation, progress, etc.)\n\nThen decide the **mode** for this turn:\n\n- \"tutor\"\n    - Gentle explanation + small practice.\n- \"practice\"\n    - More questions, grading, and feedback.\n- \"exam\"\n    - Simulate an exam: limited hints, more serious tone.\n- \"review\"\n    - Focus on weaker topics in the mastery map.\n\nGuidelines:\n\n- If the student says they are lost/confused/anxious -> prefer mode = \"tutor\".\n- If they explicitly ask for more questions -> mode = \"practice\".\n- If they explicitly request exam simulation -> mode = \"exam\".\n- If they ask what to review before an exam -> mode = \"review\".\n\n# ======================================================================\n3. Topics & Difficulty\n\nYou must also choose:\n\n- topic:\n    - Use explicit mentions like \"BFS\", \"DFS\", \"AVL tree\", \"hash table\",\n    \"dynamic programming knapsack\", \"shortest paths\", etc.\n    - If not given, infer from context or choose a topic where the mastery map\n    shows low mastery_level.\n- difficulty:\n    - \"easy\" | \"medium\" | \"hard\"\n    - Reflect student's anxiety and mastery:\n        - If mastery is low or they are anxious -> \"easy\".\n        - If mastery is medium and they ask for a challenge -> \"medium\" or \"hard\".\n        - If they are strong and near exam -> \"medium\" or \"hard\".\n\n# ======================================================================\n4. Planning Actions (Coordinator Pattern)\n\nYou do NOT execute algorithms or grade code yourself. Instead, you plan\nwhich specialist to call.\n\nYou have these abstract actions available:\n\n- CALL_CONCEPT_EXPLAINER\n    - When the student needs an explanation, example, or conceptual overview.\n- CALL_PROBLEM_GEN_AUTOGRADER\n    - When they need practice problems and/or grading.\n- CALL_VISUALIZATION\n    - When a visual or step-by-step simulation (sorting, BFS, DP table,\n    recursion tree) would help.\n\nYou can combine them in a sequence, for example:\n\n- Explain BFS intuition (Concept Explainer).\n- Then run a small BFS visualization (Visualization Agent).\n- Then give 2 easy BFS practice questions (ProblemGen + Auto-Grader).\n\nThe plan is represented as an array of **PlannedAction** objects with:\n\n- type: string (e.g., \"CALL_CONCEPT_EXPLAINER\")\n- payload: JSON object with parameters, e.g.:\n\n    {\n    \"type\": \"CALL_CONCEPT_EXPLAINER\",\n    \"payload\": {\n    \"topic\": \"bfs\",\n    \"focus\": \"edge types and intuition\",\n    \"mode\": \"tutor\"\n    }\n    }\n\n# ======================================================================\n5. Mastery Updates (Memory-lite)\n\nYou should optionally propose an update to the student's mastery map.\n\nRepresent mastery updates as a **MasteryUpdate** object:\n\n- topic: string\n- delta: float (how much to adjust mastery_level, e.g., +0.1 or -0.2)\n- reason: string (short explanation)\n\nExamples:\n\n- If the student says \"I finally get BFS now\" -> positive delta.\n- If they say \"I still do not understand DFS tree vs back edges\" -> negative delta.\n- If they struggled in practice questions (you can be told that in context),\nyou can use a negative delta.\n\nIf no update is appropriate, mastery_update can be null.\n\n# ======================================================================\n6. OrchestratorTurn JSON Schema\n\nWhen specifically asked (in the user message), you must output a **single\nOrchestratorTurn JSON object** with this structure:\n\n{\n\"intent\": \"EXPLAIN_CONCEPT\",\n\"selected_mode\": \"tutor\",\n\"topic\": \"bfs\",\n\"difficulty\": \"easy\",\n\"actions\": [\n{\n\"type\": \"CALL_CONCEPT_EXPLAINER\",\n\"payload\": {\n\"topic\": \"bfs\",\n\"emphasis\": \"edge types and intuition\",\n\"mode\": \"tutor\"\n}\n},\n{\n\"type\": \"CALL_PROBLEM_GEN_AUTOGRADER\",\n\"payload\": {\n\"topic\": \"bfs\",\n\"difficulty\": \"easy\",\n\"num_questions\": 2\n}\n}\n],\n\"mastery_update\": {\n\"topic\": \"bfs\",\n\"delta\": -0.2,\n\"reason\": \"student explicitly said they are confused\"\n},\n\"notes_for_subagents\": \"Use simple language and concrete examples; avoid heavy notation.\"\n}\n\nRules:\n\n- All fields must be present:\n    - intent (string)\n    - selected_mode (string)\n    - topic (string or null)\n    - difficulty (string or null)\n    - actions (array of objects with type and payload)\n    - mastery_update (object or null)\n    - notes_for_subagents (string or null)\n- actions must not be empty unless the student is only asking META questions.\n- The JSON must be valid and parseable.\n\n# ======================================================================\n7. Response Format for This Notebook\n\nWhen the notebook asks you to output **both** an explanation and an\nOrchestratorTurn JSON object, you must follow this format:\n\n1. First, write a short explanation for the student in natural language.\n2. Then on a new line write exactly:\nORCHESTRATOR_JSON:\n3. On the very next line, output ONLY a single JSON object representing\nthe OrchestratorTurn, with no extra markdown or backticks.\n\nExample pattern:\n\nI think you are mainly struggling with BFS intuition, especially how the queue\ndrives the order of exploration. We should start with a clear explanation and\nthen do two easy practice questions.\n\nORCHESTRATOR_JSON:\n{\n\"intent\": \"EXPLAIN_CONCEPT\",\n\"selected_mode\": \"tutor\",\n...\n}\n\nDo not wrap the JSON in backticks or markdown fences.\n\n# ======================================================================\n8. Safety & Academic Integrity\n\n- Encourage understanding, not cheating.\n- You may help with exam-style questions, but:\n    - Prefer to offer hints, explanations, and scaffolding.\n    - Avoid behaving like an answer-dump for real assignments or exams.\n- Do not claim to use any private or proprietary course materials.\n- Use only high-level, generic algorithm knowledge.\n\n# ======================================================================\n9. Style for Student-Facing Text\n\n- Be kind, concise, and structured.\n- Use short paragraphs and bullet points when helpful.\n- Acknowledge anxiety briefly if obvious:\n    - e.g., \"This topic is genuinely tricky; it is normal to feel stuck here.\"\n- End with 1‚Äì3 suggestions for what the student can ask next:\n\n    For example:\n\n    - \"We can now: (a) walk through a BFS example, (b) practice 2 easy questions,\n    or (c) visualize BFS on a small graph. Which would you prefer?\"\n\"\"\"\n\nprint(\"‚úÖ Diagnostic + Personalization system prompt defined.\")\n\ndiagnostic_agent = Agent(\n    name=\"diagnostic_personalization_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Diagnostic + Personalization agent that interprets the student's needs, \"\n        \"recommends mode/topic/difficulty, and plans calls to specialist agents.\"\n    ),\n    instruction=DIAGNOSTIC_PERSONALIZATION_SYSTEM_PROMPT,\n    tools=[google_search],\n)\n\ndiagnostic_runner = InMemoryRunner(agent=diagnostic_agent)\nprint(\"‚úÖ Diagnostic + Personalization Agent + runner defined.\")","metadata":{"_uuid":"d332073f-ff32-467e-91bc-7a5030b2cd7c","_cell_guid":"baa315f1-6043-4e93-9a56-bebcd8acb4d6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.422317Z","iopub.execute_input":"2025-11-29T12:15:48.422701Z","iopub.status.idle":"2025-11-29T12:15:48.452600Z","shell.execute_reply.started":"2025-11-29T12:15:48.422649Z","shell.execute_reply":"2025-11-29T12:15:48.451569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 3.5 Judge Agent (Evaluation Scaffold) =====================================\n\nJUDGE_SYSTEM_PROMPT = \"\"\"\nYou are the Judge Agent for Algorithm Mentor.\n\nYour role:\n\n- Evaluate the quality of outputs from:\n    - Concept Explainer Agent\n    - ProblemGen + Auto-Grader Agent\n    - Visualization Agent\n    - Diagnostic + Personalization Agent (orchestrator)\n- Use a simple, structured JSON rubric.\n\nGeneral behavior:\n\n- You will be given:\n    - A description of the test case.\n    - The requirements / expected properties.\n    - The actual agent output (as text).\n- You must:\n    - Read the description and requirements carefully.\n    - Inspect the agent output.\n    - Score it from 0.0 to 1.0.\n    - Decide whether it passes (score >= 0.7).\n    - Provide brief notes.\n\nOutput:\n\nReturn a SINGLE JSON object with:\n\n{\n\"score\": float,              // 0.0 to 1.0\n\"passed\": bool,              // true if score >= 0.7\n\"notes\": \"string\"            // short explanation of reasoning\n}\n\nRules:\n\n- Do NOT wrap this JSON in markdown or backticks.\n- Be strict but fair.\n- Focus on:\n    - Correctness\n    - Clarity and structure\n    - Whether the required sections/properties are present\n\"\"\"\n\njudge_agent = Agent(\n    name=\"judge_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=\"Judge Agent to evaluate Algorithm Mentor sub-agent outputs.\",\n    instruction=JUDGE_SYSTEM_PROMPT,\n    tools=[],\n)\n\njudge_runner = InMemoryRunner(agent=judge_agent)\nprint(\"‚úÖ Judge Agent + runner defined.\")","metadata":{"_uuid":"993007c5-3300-4d9b-81cc-7b319409b0e4","_cell_guid":"1d63f099-cd51-4cee-bbda-f1a56bace614","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.453614Z","iopub.execute_input":"2025-11-29T12:15:48.453974Z","iopub.status.idle":"2025-11-29T12:15:48.484269Z","shell.execute_reply.started":"2025-11-29T12:15:48.453947Z","shell.execute_reply":"2025-11-29T12:15:48.483094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================================================================\n# 4. Session & Memory Helpers ‚Äì mastery + lightweight long-term memory\n# =====================================================================\n\nMEMORY_FILE_PATH = \"/kaggle/working/algorithm_mentor_memory.json\"\n\n\ndef init_default_state() -> SessionState:\n    \"\"\"\n    Initialize a fresh session state with default values.\n    \"\"\"\n    profile = StudentProfile(\n        persona=None,\n        preferred_language_level=\"standard\",\n        preferred_code_language=\"C++\",\n        explanation_level=\"standard\",\n        goal_description=\"Learn algorithms and data structures with Algorithm Mentor.\",\n    )\n    state = SessionState(\n        turn_index=0,\n        mode=\"tutor\",\n        current_topic=None,\n        current_difficulty=None,\n        student_profile=profile,\n        mastery_map={},\n        recent_intents=[],\n        chat_history=[],\n        rolling_summary=None,\n        long_term_notes=[],\n    )\n    return state\n\n\ndef apply_mastery_update(state: SessionState, update: MasteryUpdate) -> None:\n    \"\"\"\n    Apply a mastery update to the session state in-place.\n\n    - Ensures the topic exists in mastery_map.\n    - Adjusts mastery_level by delta and clamps to [0.0, 1.0].\n    - Updates last_updated_turn.\n    \"\"\"\n    topic = update.topic\n    if topic not in state.mastery_map:\n        state.mastery_map[topic] = MasteryEntry(topic=topic, mastery_level=0.0, last_updated_turn=state.turn_index)\n\n    entry = state.mastery_map[topic]\n    new_level = entry.mastery_level + update.delta\n    # Clamp to [0.0, 1.0]\n    new_level = max(0.0, min(1.0, new_level))\n    entry.mastery_level = new_level\n    entry.last_updated_turn = state.turn_index\n\n\ndef compact_history_if_needed(state: SessionState, max_turns: int = 12) -> None:\n    \"\"\"\n     context compaction strategy:\n\n    - If chat_history is longer than max_turns:\n      - Move older messages into `rolling_summary` (as plain text).\n      - Keep only the last `max_turns` events verbatim.\n\n    This mimics \"keep last N turns + compress earlier content\" without\n    needing an extra LLM summarization call.\n    \"\"\"\n    if len(state.chat_history) <= max_turns:\n        return\n\n    old_events = state.chat_history[:-max_turns]\n    tail_events = state.chat_history[-max_turns:]\n\n    condensed_lines = []\n    for ev in old_events:\n        role = ev.get(\"role\", \"unknown\")\n        content = ev.get(\"content\", \"\")\n        condensed_lines.append(f\"{role}: {content}\")\n\n    merged = \"\\n\".join(condensed_lines)\n    if state.rolling_summary:\n        state.rolling_summary += \"\\n\\n[Earlier conversation continued]\\n\" + merged\n    else:\n        state.rolling_summary = merged\n\n    state.chat_history = tail_events\n\n\ndef save_long_term_memory(state: SessionState, path: str = MEMORY_FILE_PATH) -> None:\n    \"\"\"\n    Persist a small subset of state as JSON \"long-term memory\".\n\n    This is a simple stand-in for a Memory Bank:\n    - student_profile\n    - mastery_map (topic + mastery_level)\n    - long_term_notes\n    \"\"\"\n    try:\n        data = {\n            \"student_profile\": {\n                \"persona\": state.student_profile.persona,\n                \"preferred_language_level\": state.student_profile.preferred_language_level,\n                \"preferred_code_language\": state.student_profile.preferred_code_language,\n                \"explanation_level\": state.student_profile.explanation_level,\n                \"goal_description\": state.student_profile.goal_description,\n            },\n            \"mastery_map\": {\n                topic: {\n                    \"mastery_level\": entry.mastery_level,\n                    \"last_updated_turn\": entry.last_updated_turn,\n                }\n                for topic, entry in state.mastery_map.items()\n            },\n            \"long_term_notes\": list(state.long_term_notes),\n        }\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(data, f, indent=2)\n        # print(\"üíæ Long-term memory saved.\")\n    except Exception as e:\n        print(\"‚ö†Ô∏è Error saving long-term memory:\", e)\n\n\ndef load_long_term_memory(state: SessionState, path: str = MEMORY_FILE_PATH) -> None:\n    \"\"\"\n    Load prior long-term memory (if any) and merge into current SessionState.\n    \"\"\"\n    if not os.path.exists(path):\n        print(\"‚ÑπÔ∏è No existing long-term memory file found (fresh start).\")\n        return\n\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            data = json.load(f)\n    except Exception as e:\n        print(\"‚ö†Ô∏è Error loading long-term memory:\", e)\n        return\n\n    # Merge student_profile\n    sp = data.get(\"student_profile\", {})\n    state.student_profile.persona = sp.get(\"persona\", state.student_profile.persona)\n    state.student_profile.preferred_language_level = sp.get(\n        \"preferred_language_level\", state.student_profile.preferred_language_level\n    )\n    state.student_profile.preferred_code_language = sp.get(\n        \"preferred_code_language\", state.student_profile.preferred_code_language\n    )\n    state.student_profile.explanation_level = sp.get(\n        \"explanation_level\", state.student_profile.explanation_level\n    )\n    state.student_profile.goal_description = sp.get(\n        \"goal_description\", state.student_profile.goal_description\n    )\n\n    # Merge mastery_map\n    mm = data.get(\"mastery_map\", {})\n    for topic, info in mm.items():\n        level = float(info.get(\"mastery_level\", 0.0))\n        last_turn = int(info.get(\"last_updated_turn\", 0))\n        state.mastery_map[topic] = MasteryEntry(topic=topic, mastery_level=level, last_updated_turn=last_turn)\n\n    # Merge long_term_notes\n    ltn = data.get(\"long_term_notes\", [])\n    state.long_term_notes.extend([str(x) for x in ltn])\n\n    print(\"‚úÖ Long-term memory loaded into session_state.\")\n\n\nprint(\"‚úÖ Session helpers (init_default_state / apply_mastery_update / compaction / memory IO) defined.\")","metadata":{"_uuid":"473f0f7c-337a-4e42-91c4-afec163e3fff","_cell_guid":"329c2f4b-7e91-4483-a0dd-767423a7e98f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.485298Z","iopub.execute_input":"2025-11-29T12:15:48.485585Z","iopub.status.idle":"2025-11-29T12:15:48.515879Z","shell.execute_reply.started":"2025-11-29T12:15:48.485558Z","shell.execute_reply":"2025-11-29T12:15:48.514867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4.1 Initialize global session_state once per kernel and load memory (Day 3)\n\ntry:\n    session_state\n    print(\"‚ÑπÔ∏è session_state already exists.\")\nexcept NameError:\n    session_state = init_default_state()\n    load_long_term_memory(session_state)\n    print(\"‚úÖ session_state initialized with init_default_state() + long-term memory load.\")","metadata":{"_uuid":"038a62bc-63e7-4697-b2d8-b7d5577354b7","_cell_guid":"71eccae5-7bdc-40c1-a1a2-05734544b21d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.517297Z","iopub.execute_input":"2025-11-29T12:15:48.517627Z","iopub.status.idle":"2025-11-29T12:15:48.543731Z","shell.execute_reply.started":"2025-11-29T12:15:48.517597Z","shell.execute_reply":"2025-11-29T12:15:48.542648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================================================================\n# 5. UX Helpers (Agent Calls) ‚Äì notebook-friendly wrappers\n# =====================================================================\n\ndef build_diagnostic_prompt(user_message: str, state: \"SessionState\") -> str:\n    \"\"\"\n    Build the user message for the Diagnostic Agent.\n\n    We include:\n    - A JSON dump of the current session state (already compacted).\n    - The student's latest natural-language message.\n    - A reminder of the required ORCHESTRATOR_JSON format.\n    \"\"\"\n    state_json = json.dumps(state.to_dict(), indent=2)\n\n    prompt = (\n        \"You are the Diagnostic + Personalization Agent.\\n\\n\"\n        \"Here is the current session state in JSON (already compacted):\\n\\n\"\n        f\"{state_json}\\n\\n\"\n        \"Student message:\\n\"\n        f\"\\\"\\\"\\\"{user_message}\\\"\\\"\\\"\\n\\n\"\n        \"Your tasks:\\n\\n\"\n        \"1. Briefly explain (in 2‚Äì4 sentences) what you think this student needs next.\\n\"\n        \"   - Consider the mastery_map, mode, and student_profile from the JSON.\\n\"\n        \"2. Then output a single OrchestratorTurn JSON object exactly as described\\n\"\n        \"   in your system prompt, using this pattern:\\n\\n\"\n        \"Explanation for the student.\\n\\n\"\n        \"ORCHESTRATOR_JSON:\\n\"\n        \"{ ... one valid JSON object ... }\\n\\n\"\n        \"Rules:\\n\"\n        \"- Do NOT wrap the JSON in backticks or markdown fences.\\n\"\n        \"- The JSON must include:\\n\"\n        \"  - intent\\n\"\n        \"  - selected_mode\\n\"\n        \"  - topic\\n\"\n        \"  - difficulty\\n\"\n        \"  - actions (non-empty, unless pure META)\\n\"\n        \"  - mastery_update (object or null)\\n\"\n        \"  - notes_for_subagents (string or null)\\n\"\n        \"- At least one action should call:\\n\"\n        \"  - CALL_CONCEPT_EXPLAINER, CALL_PROBLEM_GEN_AUTOGRADER, or CALL_VISUALIZATION,\\n\"\n        \"    depending on what the student needs.\\n\\n\"\n        \"Now respond following this format.\\n\"\n    )\n    return prompt\n\n\nprint(\"‚úÖ build_diagnostic_prompt(...) defined.\")","metadata":{"_uuid":"1aed3504-3e02-4dbb-90e3-3d810d622619","_cell_guid":"bc6f5cf0-f34a-4b66-a211-fb8b36e0b7e4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.547223Z","iopub.execute_input":"2025-11-29T12:15:48.547514Z","iopub.status.idle":"2025-11-29T12:15:48.571070Z","shell.execute_reply.started":"2025-11-29T12:15:48.547493Z","shell.execute_reply":"2025-11-29T12:15:48.570100Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from typing import Any as _Any\n\nasync def run_diagnostic_turn(user_message: str) -> _Any:\n    \"\"\"\n    Run a single turn of the Diagnostic + Personalization Agent.\n\n    Uses:\n    - global `session_state`\n    - global `diagnostic_runner` (InMemoryRunner for `diagnostic_agent`)\n\n    Also:\n    - updates turn_index\n    - appends to chat_history\n    - compacts history if needed\n    - saves long-term memory snapshot\n    \"\"\"\n    global session_state\n\n    if \"diagnostic_runner\" not in globals():\n        print(\"‚ùå diagnostic_runner not found. Make sure you defined it earlier.\")\n        return None\n    if \"session_state\" not in globals():\n        print(\"‚ùå session_state not found. Make sure you initialized it earlier.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.chat_history.append({\"role\": \"user\", \"content\": user_message})\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    print(\"\\nüöÄ Running Diagnostic + Personalization turn...\")\n    prompt = build_diagnostic_prompt(user_message, session_state)\n    response = await diagnostic_runner.run_debug(prompt)\n\n    # We don't have structured access to the LLM text here, but we still record a placeholder.\n    session_state.chat_history.append({\"role\": \"assistant\", \"content\": \"[Diagnostic response above]\"})\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    # Track a recent intent tag for analytics / personalization\n    session_state.recent_intents.append(\"DIAGNOSTIC_TURN\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    return response\n\n\nprint(\"‚úÖ run_diagnostic_turn(...) defined.\")","metadata":{"_uuid":"654ed248-ab77-4304-b42f-ce4e3e252588","_cell_guid":"e03528af-1fc6-4dab-b393-009262036999","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.572405Z","iopub.execute_input":"2025-11-29T12:15:48.573535Z","iopub.status.idle":"2025-11-29T12:15:48.601034Z","shell.execute_reply.started":"2025-11-29T12:15:48.573384Z","shell.execute_reply":"2025-11-29T12:15:48.599755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"async def call_concept_explainer(\n    topic: str,\n    level: str = \"standard\",\n    persona_hint: str = \"\",\n) -> _Any:\n    \"\"\"\n    Call the Concept Explainer Agent via its runner.\n\n    Also:\n    - updates session_state.turn_index\n    - sets current_topic\n    - appends \"EXPLAIN_CONCEPT\" intent\n    - updates chat_history + compaction\n    - saves long-term memory\n    \"\"\"\n    global session_state\n\n    if \"concept_explainer_runner\" not in globals():\n        print(\"‚ùå concept_explainer_runner not found. Define it before calling this helper.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.current_topic = topic\n    session_state.recent_intents.append(\"EXPLAIN_CONCEPT\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    # Log a pseudo-user request for history purposes\n    session_state.chat_history.append(\n        {\"role\": \"user\", \"content\": f\"[Request explanation for topic '{topic}' at level '{level}']\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    user_prompt = (\n        \"You are Algorithm Mentor's Concept Explainer Agent.\\n\\n\"\n        \"Student persona hint:\\n\"\n        f\"{persona_hint}\\n\\n\"\n        \"Task:\\n\"\n        f'Explain the topic \"{topic}\" at a {level.upper()} level, following your\\n'\n        \"sequential pipeline (Overview, Intuition, Why it matters, Step-by-step trace,\\n\"\n        \"Pseudocode, Time & space complexity, Common pitfalls, Check your understanding).\\n\\n\"\n        \"Use Markdown sections.\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling Concept Explainer for topic: {topic}, level: {level}\")\n    response = await concept_explainer_runner.run_debug(user_prompt)\n\n    session_state.chat_history.append(\n        {\"role\": \"assistant\", \"content\": f\"[Concept explanation for {topic} shown above]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    return response\n\n\nasync def call_problem_generator(\n    topic: str,\n    difficulty: str = \"easy\",\n    num_questions: int = 2,\n) -> _Any:\n    \"\"\"\n    Call the ProblemGen + Auto-Grader Agent to generate practice problems.\n\n    Also:\n    - updates session_state.turn_index\n    - sets current_topic/current_difficulty\n    - appends \"PRACTICE_PROBLEMS\" intent\n    - updates chat_history + compaction\n    - saves long-term memory\n    \"\"\"\n    global session_state\n\n    if \"problem_runner\" not in globals():\n        print(\"‚ùå problem_runner not found. Define it before calling this helper.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.current_topic = topic\n    session_state.current_difficulty = difficulty\n    session_state.recent_intents.append(\"PRACTICE_PROBLEMS\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    session_state.chat_history.append(\n        {\n            \"role\": \"user\",\n            \"content\": f\"[Request {num_questions} {difficulty} practice problems on '{topic}']\",\n        }\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    user_prompt = (\n        \"You are the Problem Generator + Auto-Grader Agent for Algorithm Mentor.\\n\\n\"\n        \"Task:\\n\"\n        f\"Generate {num_questions} {difficulty} practice problems on \\\"{topic}\\\".\\n\\n\"\n        \"Requirements:\\n\"\n        \"- Use only synthetic problems (no copying real exams).\\n\"\n        \"- Make the questions clear and self-contained.\\n\"\n        \"- For each problem, provide:\\n\"\n        \"  - The question text.\\n\"\n        \"  - A brief internal answer/rubric.\\n\"\n        \"You may respond in structured, well-formatted natural language (no need for JSON here).\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling ProblemGen + Auto-Grader for topic: {topic}, difficulty: {difficulty}\")\n    response = await problem_runner.run_debug(user_prompt)\n\n    session_state.chat_history.append(\n        {\"role\": \"assistant\", \"content\": f\"[Generated practice problems for {topic} shown above]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    return response\n\n\nasync def call_visualization_agent(\n    viz_request: str,\n) -> _Any:\n    \"\"\"\n    Call the Visualization Agent via its runner.\n\n    Also:\n    - updates session_state.turn_index\n    - appends \"VISUALIZE\" intent\n    - updates chat_history + compaction\n    - saves long-term memory\n    \"\"\"\n    global session_state\n\n    if \"viz_runner\" not in globals():\n        print(\"‚ùå viz_runner not found. Define it before calling this helper.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.recent_intents.append(\"VISUALIZE\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    session_state.chat_history.append(\n        {\"role\": \"user\", \"content\": f\"[Request visualization: {viz_request}]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    user_prompt = (\n        f\"{viz_request}\\n\\n\"\n        \"Please:\\n\\n\"\n        \"Choose the appropriate viz_type (sorting, graph_traversal, dp_table,\\n\"\n        \"recursion_tree, heap_and_priority_queue, hash_table, search_tree_structure,\\n\"\n        \"complexity_growth, or np_completeness_and_reductions).\\n\\n\"\n        \"Use a tiny synthetic example.\\n\\n\"\n        \"Produce a step-by-step visualization in Markdown, with sections:\\n\\n\"\n        \"Overview\\n\\n\"\n        \"Step-by-step\\n\\n\"\n        \"What this picture tells you\\n\"\n    )\n\n    print(\"\\nüöÄ Calling Visualization Agent...\")\n    response = await viz_runner.run_debug(user_prompt)\n\n    session_state.chat_history.append(\n        {\"role\": \"assistant\", \"content\": \"[Visualization explanation shown above]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    return response\n\n\nprint(\n    \"‚úÖ call_concept_explainer(...), call_problem_generator(...), \"\n    \"call_visualization_agent(...) defined.\"\n)","metadata":{"_uuid":"75e8173a-fdec-4964-88b6-9b8a2165ca74","_cell_guid":"a6fc78f8-7b6a-4b12-8c2f-23715c5e6cba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.602168Z","iopub.execute_input":"2025-11-29T12:15:48.602502Z","iopub.status.idle":"2025-11-29T12:15:48.634284Z","shell.execute_reply.started":"2025-11-29T12:15:48.602475Z","shell.execute_reply":"2025-11-29T12:15:48.633044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================================================================\n# 6. Demo Cells ‚Äì end-to-end tutoring examples\n# =====================================================================\n\n# Example ‚Äì Concept Explainer\nawait call_concept_explainer(\n    topic=\"Dijkstra's algorithm\",\n    level=\"standard\",\n    persona_hint=\"Sara, overloaded CS undergrad, prefers C++-style pseudocode.\"\n)","metadata":{"_uuid":"1fd31874-47c6-4e7f-a675-af737105e89b","_cell_guid":"153a62c9-5cd5-4b5b-aae1-01550a5c34f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:15:48.635783Z","iopub.execute_input":"2025-11-29T12:15:48.636203Z","iopub.status.idle":"2025-11-29T12:16:01.227461Z","shell.execute_reply.started":"2025-11-29T12:15:48.636172Z","shell.execute_reply":"2025-11-29T12:16:01.226218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example ‚Äì Problem Generator\nawait call_problem_generator(\n    topic=\"binary search\",\n    difficulty=\"easy\",\n    num_questions=2,\n)","metadata":{"_uuid":"ba5c17ec-4c9a-47ec-bc79-7370ff4c1807","_cell_guid":"46d5b8ae-b20c-49db-9365-9c7896759489","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:16:01.228881Z","iopub.execute_input":"2025-11-29T12:16:01.229272Z","iopub.status.idle":"2025-11-29T12:16:06.515112Z","shell.execute_reply.started":"2025-11-29T12:16:01.229244Z","shell.execute_reply":"2025-11-29T12:16:06.513210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example ‚Äì Diagnostic (Orchestrator)\nawait run_diagnostic_turn(\n    \"I'm confused about dynamic programming, especially 0/1 knapsack tables.\"\n)","metadata":{"_uuid":"e6d9caeb-6545-478a-a1b2-36756a03e355","_cell_guid":"09a46c2d-6579-4211-87ff-2f5dca7d67d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:16:06.516683Z","iopub.execute_input":"2025-11-29T12:16:06.517291Z","iopub.status.idle":"2025-11-29T12:16:09.127571Z","shell.execute_reply.started":"2025-11-29T12:16:06.517254Z","shell.execute_reply":"2025-11-29T12:16:09.126315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example ‚Äì Visualization Agent\nawait call_visualization_agent(\n    viz_request=\"Visualize merge sort on [4, 1, 3, 9, 7].\",\n)","metadata":{"_uuid":"d373da00-b262-40eb-bf39-5697fc4accd4","_cell_guid":"7860ace1-28b4-4d99-8f89-f3d715cc9f3c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:16:09.128723Z","iopub.execute_input":"2025-11-29T12:16:09.129022Z","iopub.status.idle":"2025-11-29T12:16:12.341689Z","shell.execute_reply.started":"2025-11-29T12:16:09.129000Z","shell.execute_reply":"2025-11-29T12:16:12.340453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OPTIONAL: create ADK agent package \n# !adk create algorithm-mentor-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"_uuid":"a0b79451-7bd8-4e48-b29d-3eb76c1e2311","_cell_guid":"c973d26f-bc7d-47c1-9c0d-e78516a0bbff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:16:12.342712Z","iopub.execute_input":"2025-11-29T12:16:12.343005Z","iopub.status.idle":"2025-11-29T12:16:12.348499Z","shell.execute_reply.started":"2025-11-29T12:16:12.342983Z","shell.execute_reply":"2025-11-29T12:16:12.347143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OPTIONAL: get ADK Web UI URL\n# url_prefix = get_adk_proxy_url()\n# print(\"URL prefix:\", url_prefix)","metadata":{"_uuid":"e0faf9d9-567e-460b-989a-74017dccd8a5","_cell_guid":"480375bd-f5a2-4f88-b2f7-76f31c4fb12e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:16:12.349552Z","iopub.execute_input":"2025-11-29T12:16:12.349909Z","iopub.status.idle":"2025-11-29T12:16:12.373733Z","shell.execute_reply.started":"2025-11-29T12:16:12.349848Z","shell.execute_reply":"2025-11-29T12:16:12.372517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OPTIONAL: run ADK Web UI server (keep this cell running)\n# !adk web --url_prefix {url_prefix}","metadata":{"_uuid":"498c5009-c2cd-416e-a255-cdb00b52176c","_cell_guid":"d2b87e66-43c3-43f5-b090-38eb217f4cdf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T12:16:12.375042Z","iopub.execute_input":"2025-11-29T12:16:12.375421Z","iopub.status.idle":"2025-11-29T12:16:12.398461Z","shell.execute_reply.started":"2025-11-29T12:16:12.375388Z","shell.execute_reply":"2025-11-29T12:16:12.397043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 6. Helper: extract plain text from ADK runner responses ================\n\nimport json\nfrom typing import Any as _Any\n\ndef _extract_text(response: _Any) -> str:\n    \"\"\"\n    Best-effort extraction of plain text from an ADK runner response.\n\n    It tries, in order:\n    - response if it's already a string\n    - response.text\n    - response.output_text\n    - str(response)\n    \"\"\"\n    if isinstance(response, str):\n        return response\n\n    for attr in (\"text\", \"output_text\", \"output\", \"content\"):\n        if hasattr(response, attr):\n            try:\n                value = getattr(response, attr)\n                if isinstance(value, str):\n                    return value\n            except Exception:\n                pass\n\n    # Fallback: whatever __str__ gives\n    return str(response)\n\nprint(\"‚úÖ _extract_text(...) helper defined.\")","metadata":{"_uuid":"565f140d-d432-4999-a277-22841ac6c8d6","_cell_guid":"db30931b-28f2-4534-9032-8c0c10a93b8f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-29T12:16:12.400997Z","iopub.execute_input":"2025-11-29T12:16:12.401607Z","iopub.status.idle":"2025-11-29T12:16:12.419292Z","shell.execute_reply.started":"2025-11-29T12:16:12.401573Z","shell.execute_reply":"2025-11-29T12:16:12.418020Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 7. Observability ‚Äì metrics store for basic logging =======================\n\nfrom dataclasses import asdict\n\nMETRICS = {\n    \"num_explainer_calls\": 0,\n    \"num_problem_gen_calls\": 0,\n    \"num_viz_calls\": 0,\n    \"num_diagnostic_turns\": 0,\n    \"num_judge_calls\": 0,\n    \"eval_runs\": 0,\n}\n\ndef print_metrics() -> None:\n    \"\"\"\n    Print current metrics in a compact, human-friendly way.\n    \"\"\"\n    print(\"\\nüìä Current Algorithm Mentor metrics:\")\n    for k, v in METRICS.items():\n        print(f\"  - {k}: {v}\")\n\nprint(\"‚úÖ METRICS dict and print_metrics() defined.\")","metadata":{"_uuid":"625fa18d-e428-443f-b1be-1755c3a8df50","_cell_guid":"834a965b-3d4f-45af-bb3d-2aee7f63c196","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-29T12:16:12.420811Z","iopub.execute_input":"2025-11-29T12:16:12.421253Z","iopub.status.idle":"2025-11-29T12:16:12.443614Z","shell.execute_reply.started":"2025-11-29T12:16:12.421225Z","shell.execute_reply":"2025-11-29T12:16:12.442580Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 8. Instrument existing helpers with metrics ============================\n\n# We assume:\n# - concept_explainer_runner, problem_runner, viz_runner, diagnostic_runner exist\n# - METRICS and _extract_text are defined\n\nasync def run_diagnostic_turn(user_message: str) -> _Any:\n    \"\"\"\n    Run a single turn of the Diagnostic + Personalization Agent.\n\n    Uses:\n    - global `session_state`\n    - global `diagnostic_runner`\n\n    Adds:\n    - metrics bump for num_diagnostic_turns\n    \"\"\"\n    if \"diagnostic_runner\" not in globals():\n        print(\"‚ùå diagnostic_runner not found. Make sure you defined it earlier.\")\n        return None\n    if \"session_state\" not in globals():\n        print(\"‚ùå session_state not found. Make sure you initialized it earlier.\")\n        return None\n\n    METRICS[\"num_diagnostic_turns\"] += 1\n\n    print(\"\\nüöÄ Running Diagnostic + Personalization turn...\")\n    prompt = build_diagnostic_prompt(user_message, session_state)\n    response = await diagnostic_runner.run_debug(prompt)\n    return response\n\n\nasync def call_concept_explainer(\n    topic: str,\n    level: str = \"standard\",\n    persona_hint: str = \"\",\n) -> _Any:\n    \"\"\"\n    Call the Concept Explainer Agent via its runner.\n\n    Adds:\n    - metrics bump for num_explainer_calls\n    \"\"\"\n    if \"concept_explainer_runner\" not in globals():\n        print(\"‚ùå concept_explainer_runner not found. Define it before calling this helper.\")\n        return None\n\n    METRICS[\"num_explainer_calls\"] += 1\n\n    user_prompt = (\n        \"You are Algorithm Mentor's Concept Explainer Agent.\\n\\n\"\n        \"Student persona hint:\\n\"\n        f\"{persona_hint}\\n\\n\"\n        \"Task:\\n\"\n        f'Explain the topic \"{topic}\" at a {level.upper()} level, following your\\n'\n        \"sequential pipeline (Overview, Intuition, Why it matters, Step-by-step trace,\\n\"\n        \"Pseudocode, Time & space complexity, Common pitfalls, Check your understanding).\\n\\n\"\n        \"Use Markdown sections.\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling Concept Explainer for topic: {topic}, level: {level}\")\n    response = await concept_explainer_runner.run_debug(user_prompt)\n    return response\n\n\nasync def call_problem_generator(\n    topic: str,\n    difficulty: str = \"easy\",\n    num_questions: int = 2,\n) -> _Any:\n    \"\"\"\n    Call the ProblemGen + Auto-Grader Agent to generate practice problems.\n\n    Adds:\n    - metrics bump for num_problem_gen_calls\n    \"\"\"\n    if \"problem_runner\" not in globals():\n        print(\"‚ùå problem_runner not found. Define it before calling this helper.\")\n        return None\n\n    METRICS[\"num_problem_gen_calls\"] += 1\n\n    user_prompt = (\n        \"You are the Problem Generator + Auto-Grader Agent for Algorithm Mentor.\\n\\n\"\n        \"Task:\\n\"\n        f\"Generate {num_questions} {difficulty} practice problems on \\\"{topic}\\\".\\n\\n\"\n        \"Requirements:\\n\"\n        \"- Use only synthetic problems (no copying real exams).\\n\"\n        \"- Make the questions clear and self-contained.\\n\"\n        \"- For each problem, provide:\\n\"\n        \"  - The question text.\\n\"\n        \"  - A brief internal answer/rubric.\\n\"\n        \"You may respond in structured, well-formatted natural language (no need for JSON here).\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling ProblemGen + Auto-Grader for topic: {topic}, difficulty: {difficulty}\")\n    response = await problem_runner.run_debug(user_prompt)\n    return response\n\n\nasync def call_visualization_agent(\n    viz_request: str,\n) -> _Any:\n    \"\"\"\n    Call the Visualization Agent via its runner.\n\n    Adds:\n    - metrics bump for num_viz_calls\n    \"\"\"\n    if \"viz_runner\" not in globals():\n        print(\"‚ùå viz_runner not found. Define it before calling this helper.\")\n        return None\n\n    METRICS[\"num_viz_calls\"] += 1\n\n    user_prompt = (\n        f\"{viz_request}\\n\\n\"\n        \"Please:\\n\\n\"\n        \"Choose the appropriate viz_type (sorting, graph_traversal, dp_table,\\n\"\n        \"recursion_tree, heap_and_priority_queue, hash_table, search_tree_structure,\\n\"\n        \"complexity_growth, or np_completeness_and_reductions).\\n\\n\"\n        \"Use a tiny synthetic example.\\n\\n\"\n        \"Produce a step-by-step visualization in Markdown, with sections:\\n\\n\"\n        \"Overview\\n\\n\"\n        \"Step-by-step\\n\\n\"\n        \"What this picture tells you\\n\"\n    )\n\n    print(\"\\nüöÄ Calling Visualization Agent...\")\n    response = await viz_runner.run_debug(user_prompt)\n    return response\n\n\nprint(\"‚úÖ Existing helpers wrapped with basic metrics.\")","metadata":{"_uuid":"f3191270-7695-4712-9d6b-49bc9ed67dd6","_cell_guid":"79967474-c4b8-4235-b0c8-a9886a262430","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-29T12:16:12.445040Z","iopub.execute_input":"2025-11-29T12:16:12.445388Z","iopub.status.idle":"2025-11-29T12:16:12.479567Z","shell.execute_reply.started":"2025-11-29T12:16:12.445360Z","shell.execute_reply":"2025-11-29T12:16:12.477222Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 9. Evaluation ‚Äì Judge Agent + tiny eval suite ===========================\nfrom typing import List\n\n# Small eval set ‚Äì you can add more later\nEVAL_TESTS: List[EvalTestCase] = [\n    EvalTestCase(\n        id=\"explainer_dijkstra\",\n        agent=\"concept_explainer_agent\",\n        description=\"Checks Dijkstra explanation structure and clarity.\",\n        prompt=(\n            \"Explain Dijkstra's algorithm for single-source shortest paths on a graph \"\n            \"with non-negative edge weights. Follow your standard Algorithm Mentor \"\n            \"section structure.\"\n        ),\n        expected_properties=[\n            \"Has sections: Overview, Intuition, Why it matters, Step-by-step trace, \"\n            \"Pseudocode, Time & space complexity, Common pitfalls, Check your understanding.\",\n            \"Uses a small synthetic example graph.\",\n            \"Avoids copying any textbook wording.\",\n        ],\n    ),\n    EvalTestCase(\n        id=\"problemgen_binary_search_easy\",\n        agent=\"problem_gen_autograder_agent\",\n        description=\"Generate easy binary search practice problems.\",\n        prompt=(\n            \"Generate 2 **easy** practice problems on binary search, including \"\n            \"the question text and a short answer or rubric for each.\"\n        ),\n        expected_properties=[\n            \"Questions are clearly about binary search.\",\n            \"Problems are easy-level and self-contained.\",\n            \"Includes at least a short solution or rubric per question.\",\n        ],\n    ),\n]\n\n\nasync def run_eval_suite() -> EvalSummary:\n    \"\"\"\n    Run the small evaluation suite using the Judge Agent.\n\n    - Calls the target agent to get output (via runner.run_debug()).\n    - Sends (requirements + agent output) to Judge Agent (via judge_runner.run_debug()).\n    - Parses JSON from Judge and builds an EvalSummary.\n    - Updates METRICS and prints a short report.\n    \"\"\"\n    if \"judge_runner\" not in globals():\n        print(\"‚ùå judge_runner not found. Make sure you defined the Judge agent earlier.\")\n        return EvalSummary()\n\n    results: List[EvalResult] = []\n\n    print(\"\\nüß™ Running evaluation suite...\")\n    for test in EVAL_TESTS:\n        print(f\"\\n--- Test: {test.id} ({test.agent}) ---\")\n\n        # 1) Choose the correct runner for the target agent\n        if test.agent == \"concept_explainer_agent\":\n            target_runner = concept_explainer_runner\n        elif test.agent == \"problem_gen_autograder_agent\":\n            target_runner = problem_runner\n        else:\n            print(f\"‚ö†Ô∏è Unknown agent in eval test: {test.agent}, skipping.\")\n            continue\n\n        # 2) Call the target agent via run_debug(prompt)\n        agent_resp = await target_runner.run_debug(test.prompt)\n        agent_text = _extract_text(agent_resp)\n\n        # 3) Build judge prompt\n        judge_prompt = (\n            \"You are the Judge Agent for Algorithm Mentor.\\n\\n\"\n            f\"Test case description:\\n{test.description}\\n\\n\"\n            \"Expected properties:\\n\"\n            + \"\\n\".join(f\"- {prop}\" for prop in test.expected_properties)\n            + \"\\n\\n\"\n            \"Here is the agent output you must evaluate:\\n\\n\"\n            f\"--- BEGIN AGENT OUTPUT ---\\n{agent_text}\\n--- END AGENT OUTPUT ---\\n\\n\"\n            \"Now respond ONLY with a single JSON object:\\n\"\n            \"{\\n\"\n            '  \\\"score\\\": float,              // 0.0 to 1.0\\n'\n            '  \\\"passed\\\": bool,              // true if score >= 0.7\\n'\n            '  \\\"notes\\\": \\\"string\\\"          // short explanation\\n'\n            \"}\\n\"\n        )\n\n        # 4) Call Judge Agent via run_debug(prompt)\n        METRICS[\"num_judge_calls\"] += 1\n        judge_resp = await judge_runner.run_debug(judge_prompt)\n        judge_text = _extract_text(judge_resp)\n\n        # 5) Parse JSON and build EvalResult\n        try:\n            judge_json = json.loads(judge_text)\n        except Exception as e:\n            print(\"‚ùå Failed to parse judge JSON:\", e)\n            print(\"Raw judge response:\")\n            print(judge_text)\n            continue\n\n        score = float(judge_json.get(\"score\", 0.0))\n        passed = bool(judge_json.get(\"passed\", False))\n        notes = str(judge_json.get(\"notes\", \"\"))\n\n        result = EvalResult(\n            test_id=test.id,\n            agent=test.agent,\n            score=score,\n            passed=passed,\n            judge_notes=notes,\n        )\n        results.append(result)\n\n        status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n        print(f\"{status} ‚Äì score={score:.2f}\")\n        print(\"Notes:\", notes)\n\n    summary = EvalSummary(results=results)\n    METRICS[\"eval_runs\"] += 1\n\n    print(\"\\nüìã EVAL SUMMARY\")\n    print(f\"- Tests run: {summary.num_total}\")\n    print(f\"- Passed:    {summary.num_passed}\")\n    print(f\"- Avg score: {summary.average_score:.2f}\")\n\n    return summary\n\n\nprint(\"‚úÖ Evaluation suite (EVAL_TESTS, run_eval_suite) defined with run_debug().\")","metadata":{"_uuid":"9d95295b-2e04-4dc2-9308-20baf2f418cf","_cell_guid":"a1c6b8e9-16e7-4ece-8756-314ad73e3168","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-29T12:16:12.481171Z","iopub.execute_input":"2025-11-29T12:16:12.481430Z","iopub.status.idle":"2025-11-29T12:16:12.505464Z","shell.execute_reply.started":"2025-11-29T12:16:12.481409Z","shell.execute_reply":"2025-11-29T12:16:12.504331Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 10. Sanity Check ‚Äì run eval suite + print metrics =======================\neval_summary = await run_eval_suite()\nprint_metrics()","metadata":{"_uuid":"81a2075f-58dd-420d-8341-38f0c6b91b46","_cell_guid":"c8cfb697-ba80-4900-9e6d-2c03936cf6ae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-29T12:16:12.507038Z","iopub.execute_input":"2025-11-29T12:16:12.507489Z","iopub.status.idle":"2025-11-29T12:16:27.140287Z","shell.execute_reply.started":"2025-11-29T12:16:12.507463Z","shell.execute_reply":"2025-11-29T12:16:27.139040Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"31ff5303-d1ea-4afd-804d-9c987edc4b59","_cell_guid":"7b9d3258-97e2-4236-94e9-af638c17a10a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}