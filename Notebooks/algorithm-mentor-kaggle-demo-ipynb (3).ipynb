{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Quickstart (How to run this notebook)\n\n1. **Fork this notebook** on Kaggle.\n2. In **Kaggle ‚Üí Settings ‚Üí Secrets**, create a secret called `GOOGLE_API_KEY` with your Gemini API key.\n3. Run the cells in order:\n   - Section 1: Environment & Core Imports\n   - Section 2‚Äì5: Data models, agents, session helpers, UX helpers\n   - Section 6: Demo Cells\n   - Section 9‚Äì10: Evaluation + Metrics\n4. Optionally:\n   - Uncomment the `adk create ...` and `adk web ...` cells to experiment with the ADK Web UI in this environment.\n","metadata":{"execution":{"iopub.status.busy":"2025-12-01T05:44:15.599068Z","iopub.execute_input":"2025-12-01T05:44:15.599508Z","iopub.status.idle":"2025-12-01T05:44:15.609945Z","shell.execute_reply.started":"2025-12-01T05:44:15.599476Z","shell.execute_reply":"2025-12-01T05:44:15.608320Z"}}},{"cell_type":"markdown","source":"# Algorithm Mentor ‚Äì Multi-Agent AI Tutor for Algorithms (Kaggle Demo)\n\n## Problem & Value\nMany undergrad students struggle with algorithms and data structures because:\n\n- Explanations are either too formal or too shallow.\n- Practice questions are scattered across textbooks and websites.\n- Visual intuition for graphs, DP tables, and recursion is hard to build.\n- ESL students and returning learners need simpler language and step-by-step help.\n\n**Algorithm Mentor** uses a multi-agent AI tutor to:\n\n- Give structured explanations (overview ‚Üí intuition ‚Üí trace ‚Üí pseudocode ‚Üí pitfalls).\n- Generate synthetic practice problems and rubrics on demand.\n- Visualize algorithms step-by-step on tiny examples.\n- Adapt to a student's persona (overloaded undergrad, working parent, ESL learner) and track lightweight mastery.\n\nIn a real deployment, this could reduce time-to-understanding (e.g. Dijkstra, knapsack)\nfrom **days of trial-and-error** to **one or two focused study sessions.**\n\n**Algorithm Mentor** is a multi-agent AI tutor for algorithms and data structures, designed for stressed undergrads, returning learners, and ESL students.  \nIt combines a Concept Explainer, Problem Generator + Auto-Grader, Visualization Agent, and a Diagnostic + Personalization Orchestrator, all powered by Google‚Äôs ADK and Gemini.  \n\nThis notebook shows how these agents collaborate in one tutoring flow, how we track session state and mastery inside the notebook, and how we automatically evaluate the system with a Judge Agent.\n\n---\n\n## 1. How this project uses Agentic AI concepts\n\nThe competition asks us to apply several Agentic AI concepts.  \nHere‚Äôs how this notebook maps to those requirements:\n\n| Concept area                      | What is implemented in this notebook                                                                 |\n|----------------------------------|--------------------------------------------------------------------------------------------------------|\n| **Multi-agent system**           | Separate agents: Concept Explainer, ProblemGen + Auto-Grader, Visualization, Diagnostic + Personalization (orchestrator), and Judge. Each is an ADK `Agent` with its own system prompt + runner. |\n| **Sequential / orchestrated flows** | The Diagnostic + Personalization Agent reads the session state and student message, then plans which specialist agents to call next (explain, practice, visualize). This simulates a sequential orchestration loop. |\n| **Tools (built-in)**             | Agents are created with ADK and can use built-in tools (e.g., `google_search`) via the ADK `tools` interface. |\n| **Sessions & state management**  | Custom `SessionState`, `StudentProfile`, `MasteryEntry`, and `MasteryUpdate` dataclasses track mode, topic, difficulty, mastery map, and recent intents inside the notebook kernel. |\n| **Short-term context engineering** | The `SessionState.to_dict()` method exposes a compact JSON view (tail of `chat_history` + `rolling_summary`), which is injected into the Diagnostic Agent prompt to guide personalization. |\n| **Long-term memory (lightweight)** | A simple JSON file (`algorithm_mentor_memory.json`) is used as a stand-in for a Memory Bank: we persist profile, mastery levels, and notes across kernel restarts and reload them on init. |\n| **Context compaction**           | `compact_history_if_needed(...)` performs a basic compaction strategy: keep only the last N turns verbatim and fold earlier messages into a `rolling_summary` string. |\n| **Observability (logs + metrics)** | `METRICS` dict tracks counts of explainer/problem/viz/diagnostic/judge calls and eval runs. Helper `print_metrics()` summarizes usage; agent helpers print traces to show what is being called. |\n| **Agent evaluation**             | A separate Judge Agent (`judge_agent`) scores outputs from the Concept Explainer and ProblemGen agents using a JSON rubric. `run_eval_suite()` runs a tiny eval set and reports pass/fail + scores. |\n\n> **Note:** In a real production system, these ideas would be wired into persistent `SessionService` / `MemoryService`, long-running operations, and full CI/CD. Here we demonstrate the core patterns directly inside a Kaggle notebook.\n\n---\n\n## 2. System architecture at a glance\n\nAt a high level, the notebook models the following multi-agent architecture:\n\n```text\n                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\nUser (student)  ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ Diagnostic + Personalization  ‚îÇ\n   message           ‚îÇ     Agent (orchestrator)      ‚îÇ\n                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                     ‚îÇ plans next actions\n                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                 ‚îÇ                   ‚îÇ                    ‚îÇ\n                 ‚ñº                   ‚ñº                    ‚ñº\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n       ‚îÇ Concept        ‚îÇ   ‚îÇ ProblemGen +       ‚îÇ  ‚îÇ Visualization     ‚îÇ\n       ‚îÇ Explainer Agent‚îÇ   ‚îÇ Auto-Grader Agent  ‚îÇ  ‚îÇ Agent             ‚îÇ\n       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n                               ‚ñ≤\n                               ‚îÇ (for offline evaluation)\n                               ‚ñº\n                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                        ‚îÇ Judge Agent    ‚îÇ\n                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò","metadata":{"_uuid":"091b7b82-190f-4aab-b7f7-f3375db39e91","_cell_guid":"78aef212-de81-4717-b01e-495d2595dbc0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"### How the agents collaborate\n\n- The **Diagnostic + Personalization Agent** receives:\n  - the latest **student message**, and  \n  - a compact JSON view of the current `SessionState`  \n  Then it decides:\n  - which **topic** to focus on,\n  - which **difficulty** (easy / medium / hard) to use, and  \n  - whether to call the **Concept Explainer**, **ProblemGen + Auto-Grader**, **Visualization Agent**, or some combination of them.\n\n- The **Concept Explainer Agent** produces a **structured teaching explanation** with:\n  - overview  \n  - intuition  \n  - step-by-step trace on a tiny example  \n  - pseudocode  \n  - time & space complexity  \n  - common pitfalls  \n  - self-quiz questions (no answers)\n\n- The **ProblemGen + Auto-Grader Agent** creates **synthetic practice problems** and short **rubrics/answers** for algorithms & data structures.\n\n- The **Visualization Agent** generates **step-by-step visual explanations in Markdown**, using tiny synthetic examples (arrays, graphs, tables, etc.).\n\n- The **Judge Agent** is used **only in the evaluation section** to score other agents‚Äô outputs using a JSON rubric.\n\nAll agents are implemented using **Google‚Äôs ADK** (`Agent` + `InMemoryRunner`) and are structured so they can later be reused in an **A2A** or **deployed** setup.\n\n---\n\n### 3. How to read this notebook\n\nThe rest of the notebook is organized as:\n\n1. **Environment & Core Imports**  \n   Set up the API key, ADK, Gemini model, and optional ADK Web UI helper.\n\n2. **Shared Data Models**  \n   Define `StudentProfile`, `SessionState`, mastery-related dataclasses, and evaluation dataclasses.\n\n3. **Agents & Runners**  \n   Instantiate the five main agents (explainer, problem, viz, diagnostic, judge) with their system prompts and ADK `InMemoryRunner`s.\n\n4. **Session & Memory Helpers**  \n   Implement simple mastery updates, context compaction, and JSON-based long-term memory load/save.\n\n5. **UX Helpers (Agent Calls)**  \n   Notebook-friendly async helpers like `run_diagnostic_turn`, `call_concept_explainer`, `call_problem_generator`, and `call_visualization_agent`.\n\n6. **Demo Cells**  \n   Example calls that show a full tutoring flow for topics like Dijkstra‚Äôs algorithm, binary search, and dynamic programming.\n\n7. **Observability & Evaluation**  \n   Metrics collection, an evaluation suite using the Judge Agent, and a quick sanity check (`run_eval_suite()` + `print_metrics()`).","metadata":{"_uuid":"11af4b84-eb50-4151-ac48-f84bfd7880fc","_cell_guid":"2b7efa2a-1d00-45b3-94e6-3311006fb6cc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# === 1. Environment & Core Imports ‚Äì API key, ADK, Gemini, optional Web UI ===\n\nimport os\nimport json\nfrom typing import Any, Dict, List, Optional, Literal\nfrom dataclasses import dataclass, field\n\nfrom kaggle_secrets import UserSecretsClient\n\n# Load the Google API key from Kaggle secrets and export as env var.\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete from Kaggle secrets.\")\nexcept Exception as e:\n    print(\n        \"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' \"\n        \"to your Kaggle secrets. Details:\", e\n    )\n\n# ADK + Gemini imports\nfrom google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")\n\n# ADK Web UI helper \nfrom IPython.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n\ndef get_adk_proxy_url() -> str:\n    \"\"\"\n    Compute the proxied ADK web UI URL for the current Kaggle notebook.\n\n    Returns:\n        The URL prefix string passed to `adk web --url_prefix`.\n    \"\"\"\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0][\"base_url\"]\n\n    try:\n        path_parts = baseURL.split(\"/\")\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è OPTIONAL: ADK Web UI</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            Run <code>!adk web --url_prefix {url_prefix}</code> in the next cell, keep it running,\n            then click this button to open the ADK Web UI in a new tab.\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\n\nprint(\"‚úÖ Helper function for ADK proxy URL defined.\")\n\n# Retry config for Gemini \nretry_config = types.HttpRetryOptions(\n    attempts=5,           # Maximum retry attempts\n    exp_base=7,           # Delay multiplier for exponential backoff\n    initial_delay=1,      # Initial delay before first retry (in seconds)\n    http_status_codes=[   # Retry on these HTTP error codes\n        429, 500, 503, 504\n    ],\n)\n\nprint(\"‚úÖ Retry configuration for Gemini defined.\")","metadata":{"_uuid":"1d398868-3f6e-431a-9e9b-b9502bb2557c","_cell_guid":"792addd4-a321-4558-afcc-58872559e856","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:23.502346Z","iopub.execute_input":"2025-12-01T06:00:23.503788Z","iopub.status.idle":"2025-12-01T06:00:23.653981Z","shell.execute_reply.started":"2025-12-01T06:00:23.503741Z","shell.execute_reply":"2025-12-01T06:00:23.652998Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete from Kaggle secrets.\n‚úÖ ADK components imported successfully.\n‚úÖ Helper function for ADK proxy URL defined.\n‚úÖ Retry configuration for Gemini defined.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# =====================================================================\n# 2. Shared Data Models ‚Äì StudentProfile, SessionState, Mastery, Eval\n# =====================================================================\n\n@dataclass\nclass StudentProfile:\n    \"\"\"\n    Simple student profile used for personalization.\n    \"\"\"\n    persona: Optional[str] = None  # \"Sara\", \"Ela\", \"Ali\", or custom\n    preferred_language_level: Literal[\"simple\", \"standard\", \"deep\"] = \"standard\"\n    preferred_code_language: Optional[str] = \"C++\"  # e.g., \"C++\", \"Python\"\n    explanation_level: Optional[str] = None        # text hint like \"short\", \"detailed\"\n    goal_description: Optional[str] = None         # e.g., \"prepare for midterm\"\n\n\n@dataclass\nclass MasteryEntry:\n    \"\"\"\n    Tracks mastery for one topic.\n    \"\"\"\n    topic: str\n    mastery_level: float = 0.0     # 0.0 (weak) to 1.0 (strong)\n    last_updated_turn: int = 0\n\n\n@dataclass\nclass MasteryUpdate:\n    \"\"\"\n    Proposed update to the mastery map.\n    \"\"\"\n    topic: str\n    delta: float\n    reason: str\n\n\n@dataclass\nclass SessionState:\n    \"\"\"\n    Session-level working memory for Algorithm Mentor.\n    - chat_history: short-term conversational history inside this session\n    - rolling_summary: compact summary of older turns (for context compaction)\n    - long_term_notes: simple JSON-based long-term memory across sessions\n    \"\"\"\n    turn_index: int = 0\n    mode: str = \"tutor\"                      # \"tutor\" | \"practice\" | \"exam\" | \"review\"\n    current_topic: Optional[str] = None\n    current_difficulty: Optional[str] = None # \"easy\" | \"medium\" | \"hard\" | None\n    student_profile: StudentProfile = field(default_factory=StudentProfile)\n    mastery_map: Dict[str, MasteryEntry] = field(default_factory=dict)\n    recent_intents: List[str] = field(default_factory=list)\n\n    \n    chat_history: List[Dict[str, str]] = field(default_factory=list)\n    rolling_summary: Optional[str] = None\n    long_term_notes: List[str] = field(default_factory=list)\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert to a JSON-friendly dictionary.\n\n        NOTE: We only expose a *tail* of chat_history plus rolling_summary\n        so Diagnostic Agent sees compact context instead of the full history.\n        \"\"\"\n        history_tail = (\n            self.chat_history[-6:] if len(self.chat_history) > 6 else list(self.chat_history)\n        )\n\n        return {\n            \"turn_index\": self.turn_index,\n            \"mode\": self.mode,\n            \"current_topic\": self.current_topic,\n            \"current_difficulty\": self.current_difficulty,\n            \"student_profile\": {\n                \"persona\": self.student_profile.persona,\n                \"preferred_language_level\": self.student_profile.preferred_language_level,\n                \"preferred_code_language\": self.student_profile.preferred_code_language,\n                \"explanation_level\": self.student_profile.explanation_level,\n                \"goal_description\": self.student_profile.goal_description,\n            },\n            \"mastery_map\": {\n                topic: {\n                    \"topic\": entry.topic,\n                    \"mastery_level\": entry.mastery_level,\n                    \"last_updated_turn\": entry.last_updated_turn,\n                }\n                for topic, entry in self.mastery_map.items()\n            },\n            \"recent_intents\": list(self.recent_intents),\n            # \n            \"chat_history_tail\": history_tail,\n            \"rolling_summary\": self.rolling_summary,\n            \"long_term_notes\": list(self.long_term_notes),\n        }\n\n\n@dataclass\nclass EvalTestCase:\n    \"\"\"\n    Description of an evaluation test for a given agent.\n    (Eval scaffolding, optional to use.)\n    \"\"\"\n    id: str\n    agent: str                         # \"explainer\" | \"problem\" | \"visualization\" | \"orchestrator\"\n    description: str\n    prompt: str\n    expected_properties: List[str]\n\n\n@dataclass\nclass EvalResult:\n    \"\"\"\n    Result of a single evaluation test.\n    \"\"\"\n    test_id: str\n    agent: str\n    score: float\n    passed: bool\n    judge_notes: str\n\n\n@dataclass\nclass EvalSummary:\n    \"\"\"\n    Aggregated summary of evaluation results.\n    \"\"\"\n    results: List[EvalResult] = field(default_factory=list)\n\n    @property\n    def average_score(self) -> float:\n        if not self.results:\n            return 0.0\n        return sum(r.score for r in self.results) / len(self.results)\n\n    @property\n    def num_passed(self) -> int:\n        return sum(1 for r in self.results if r.passed)\n\n    @property\n    def num_total(self) -> int:\n        return len(self.results)\n\n\nprint(\"‚úÖ Shared dataclasses (StudentProfile, SessionState, Eval) defined (with Day 3 fields).\")","metadata":{"_uuid":"80827f53-1be7-4b8d-a55a-4659371fec88","_cell_guid":"e6efce43-49d4-4a24-b9fa-8f2608e99908","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:26.644708Z","iopub.execute_input":"2025-12-01T06:00:26.645478Z","iopub.status.idle":"2025-12-01T06:00:26.669912Z","shell.execute_reply.started":"2025-12-01T06:00:26.645441Z","shell.execute_reply":"2025-12-01T06:00:26.668545Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Shared dataclasses (StudentProfile, SessionState, Eval) defined (with Day 3 fields).\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def _extract_text(response):\n    \"\"\"\n    Extract plain text from the ADK Event / list-of-Events returned by runner.run_debug().\n    Concatenates all Part.text strings.\n    \"\"\"\n    # If it‚Äôs already a string, just return it\n    if isinstance(response, str):\n        return response\n\n    # If it's a list/tuple of Events, extract text from each and join\n    if isinstance(response, (list, tuple)):\n        parts = []\n        for ev in response:\n            parts.append(_extract_text(ev))\n        return \"\\n\".join(p for p in parts if p)\n\n    # If it looks like a single Event with content.parts[*].text\n    if hasattr(response, \"content\") and hasattr(response.content, \"parts\"):\n        texts = []\n        for p in response.content.parts:\n            if hasattr(p, \"text\") and p.text is not None:\n                texts.append(p.text)\n        return \"\\n\".join(texts)\n\n    # Fallback: just string-ify it\n    return str(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:08:36.600602Z","iopub.execute_input":"2025-12-01T06:08:36.601043Z","iopub.status.idle":"2025-12-01T06:08:36.609986Z","shell.execute_reply.started":"2025-12-01T06:08:36.601014Z","shell.execute_reply":"2025-12-01T06:08:36.608823Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# =====================================================================\n# 3. Agents & Runners ‚Äì core multi-agent tutor components\n# =====================================================================\n\n# === 3.1 Concept Explainer Agent ===============================================\n\nCONCEPT_EXPLAINER_SYSTEM_PROMPT = \"\"\"\nYou are the Concept Explainer Agent for an educational system called Algorithm Mentor.\n\nYour role:\n\n- Teach algorithms and data structures using ONLY synthetic content.\n- Focus on learners like:\n    - Sara ‚Äì overloaded CS undergrad, wants C++-style examples.\n    - Ela ‚Äì working mom returning to tech, limited time, likes short focused explanations.\n    - Ali ‚Äì newcomer / ESL learner, good at math, needs simple English and visuals.\n\nCore topics you handle include (but are not limited to):\n\n- Asymptotic and Algorithm analysis (Big-O / Big-Theta / Big-Omega).\n- Hashing\n- Recursion, recursion trees, and induction.\n- Sorting algorithms (insertion, merge sort, quicksort, heapsort, etc.).\n- Search Trees, Balanced BSTs, B-Trees\n- Searching (linear search, binary search).\n- Elementary Data structures (arrays, linked lists, stacks, queues, heaps, hash tables, trees).\n- Heaps, Priority Queues.\n- Algorithmic Paradigms.\n- Graphs and graph algorithms.\n- Dynamic programming (Fibonacci, knapsack, coin change, LIS, etc.).\n- NP-Completeness\n\nContent rules:\n\n- Use ONLY synthetic content. Invent your own graphs, arrays, and examples.\n- Do not quote or copy from textbooks, slides, or real assignments.\n- Keep examples small and easy to follow.\n\nFor each explanation request, internally follow this SEQUENTIAL pipeline:\n\n1. Plan the explanation.\n2. Overview: high-level description and what problem this algorithm or concept solves.\n3. Intuition: friendly, human explanation (analogy, story, or picture in words).\n4. Why it matters: where we use it and why it is useful.\n5. Step-by-step trace: run the algorithm on a tiny synthetic example and describe the steps.\n6. Pseudocode: clear pseudocode adapted to the preferred code style (e.g., C++-like).\n7. Time complexity: typical time and space complexity with a short justification.\n8. Pitfalls: common mistakes and misconceptions (2‚Äì5 items).\n9. Check-your-understanding: 2‚Äì4 self-quiz questions (NO answers).\n\nPersona adaptation:\n\n- If the user persona or language preference indicates ESL/beginner, use simple English and short sentences.\n- If they prefer C++ examples, make pseudocode look C++-like (loops, arrays, etc.).\n- If they want a deeper explanation, add a bit more detail (e.g., proof sketch or invariants).\n\nOutput STRUCTURE:\nBy default, produce a **Markdown explanation** with clear sections:\n\n### Overview\n\n...\n\n### Intuition\n\n...\n\n### Why it matters\n\n...\n\n### Step-by-step trace (on a small example)\n\n...\n\n### Pseudocode\n\n...\n\n### Time & space complexity\n\n...\n\n### Common pitfalls\n\n- ...\n\n### Check your understanding\n\n1. ...\n2. ...\n\nIf the user explicitly asks for a JSON STRUCTURE, then:\n\n- Return a single valid JSON object with:\n    - topic: string\n    - level: \"simple\" | \"standard\" | \"deep\"\n    - persona_used: string or null\n    - sections: object with fields:\n        - overview\n        - intuition\n        - why_it_matters\n        - pseudocode\n        - step_by_step_trace\n        - time_complexity\n        - pitfalls\n        - check_your_understanding (array of 2‚Äì4 short strings)\n    - visualization_suggestion: object with:\n        - viz_type: string or null (e.g., \"sorting\", \"graph_bfs\", \"graph_dfs\", \"recursion_tree\", \"dp_table\")\n        - spec: object with minimal synthetic data (tiny arrays/graphs/tables).\n- Do NOT wrap JSON in markdown or backticks.\n\nOverall behavior loop (Agentic pattern):\n\n1. Get mission: understand the request (topic, level, persona).\n2. Scan scene: infer their level and needs from the message.\n3. Think: plan explanation structure.\n4. Act: produce structured explanation (and JSON if requested).\n5. Observe & iterate: if the user is still confused, refine or give more targeted examples.\n\nSafety:\n\n- Do not claim to use any real course materials.\n- Do not leak or fabricate solutions to private exams.\n\"\"\"\n\nprint(\"‚úÖ Concept Explainer system prompt defined.\")\n\nconcept_explainer_agent = Agent(\n    name=\"concept_explainer_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Algorithm Mentor's Concept Explainer ‚Äì teaches algorithms and data \"\n        \"structures using synthetic examples, with persona-aware explanations.\"\n    ),\n    instruction=CONCEPT_EXPLAINER_SYSTEM_PROMPT,\n    tools=[google_search],  \n)\n\nconcept_explainer_runner = InMemoryRunner(agent=concept_explainer_agent)\nprint(\"‚úÖ Concept Explainer Agent + runner defined.\")","metadata":{"_uuid":"282c6549-47bc-4b11-9e4f-ad358946537f","_cell_guid":"70e13037-9874-453c-b7fb-7481cb653553","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:31.257656Z","iopub.execute_input":"2025-12-01T06:00:31.257993Z","iopub.status.idle":"2025-12-01T06:00:31.269514Z","shell.execute_reply.started":"2025-12-01T06:00:31.257967Z","shell.execute_reply":"2025-12-01T06:00:31.268369Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Concept Explainer system prompt defined.\n‚úÖ Concept Explainer Agent + runner defined.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# === 3.2 Problem Generator + Auto-Grader Agent =================================\n\nPROBLEM_GEN_AUTOGRADER_SYSTEM_PROMPT = \"\"\"\nYou are the Problem Generator + Auto-Grader Agent for an educational system\ncalled Algorithm Mentor.\n\nYour job has TWO main parts:\n\n1. PROBLEM GENERATION\n2. AUTO-GRADING\n\nYou operate only on **algorithms and data structures** content and you use\nONLY synthetic, invented questions (no real exam or assignment copying).\n\n======================================================================\n\n1. Topics and Scope\n======================================================================\n\nYou can generate problems on topics such as (but not limited to):\n\n- Asymptotic analysis (Big-O, Big-Theta, Big-Omega, worst/best/average case).\n- Recursion, recursion trees, and basic induction.\n- Sorting algorithms:\n    - Insertion sort, selection sort, bubble sort (for intuition)\n    - Merge sort, quicksort, heap sort\n- Searching:\n    - Linear search, binary search\n- Data structures:\n    - Arrays, linked lists, stacks, queues, deques\n    - Priority queues, binary heaps\n    - Hash tables (hash functions, collisions, chaining, probing)\n    - Trees (binary trees, BSTs, AVL trees, heaps, etc.)\n- Graphs and graph algorithms:\n    - BFS, DFS, edge classification (tree/back/forward/cross)\n    - Topological sort\n    - Single-source shortest paths (Dijkstra, Bellman‚ÄìFord)\n    - Minimum spanning trees (Prim, Kruskal)\n- Dynamic programming:\n    - Canonical examples like Fibonacci, 0/1 knapsack, coin change, LIS, etc.\n- General algorithmic modelling:\n    - Recognizing when to use graphs, DP, greedy, divide-and-conquer.\n- NP-Completeness\n- Heaps, Priority Queues \n- Algorithmic Paradigms \n- Hashing\n- Search Trees, Balanced BSTs, B-Trees \n\nYou do NOT use any private or proprietary course materials.\n\n# ======================================================================\n2. Problem Generation Requirements\n\nWhen asked to generate practice problems, you:\n\n- Create ONLY synthetic questions.\n- Ensure each question is:\n    - Clear\n    - Unambiguous\n    - Self-contained (enough detail to solve)\n- Respect the requested:\n    - TOPIC (e.g., \"BFS\", \"dynamic programming\")\n    - DIFFICULTY (easy / medium / hard)\n    - QUESTION TYPE (if specified): \"mcq\" | \"open_ended\" | \"code\"\n\nInternal pipeline (your reasoning steps, not printed):\n\n1. Get mission:\n    - Read the topic, difficulty, and requested number of problems.\n    - Identify question types (MCQ/open_ended/code).\n2. Plan problems:\n    - For each problem, choose a concrete small scenario or concept focus.\n3. Author questions:\n    - Write the actual problem text in clear exam/practice style.\n4. Create answer key / rubric:\n    - MCQ: identify the correct option and why.\n    - Open-ended: list key points required in a good answer.\n    - Code: describe the intended algorithm and important details\n    (correctness, complexity, edge cases).\n5. Package as structured data (see JSON schema below).\n\n# ======================================================================\n3. Auto-Grading Requirements\n\nWhen asked to grade a student's answer, you:\n\n- Read the original problem and its internal answer/rubric.\n- Read the student's answer (and code, if provided).\n- Compare the student answer against the expected answer/rubric.\n- Decide:\n    - A numeric score (0.0‚Äì1.0).\n    - A verdict: \"correct\", \"partially_correct\", or \"incorrect\".\n- Write feedback:\n    - Explain briefly what they did well.\n    - Explain what was missing or wrong.\n    - Suggest one small next step to improve.\n\nFor code answers:\n\n- Focus on algorithm correctness, structure, and complexity.\n- You may reason about a few small test cases in your head.\n- You do NOT execute arbitrary code; you reason about it conceptually.\n\n# ======================================================================\n4. JSON Schemas (for structured outputs)\n\nYou can respond either in:\n\n- Natural language (for interactive chat), or\n- **Structured JSON format** when explicitly requested.\n\nWhen JSON is requested, use the following structures:\n\n4.1 GeneratedProblem JSON\n\nFor each problem, the structure is:\n\n{\n\"id\": \"string\",                  // unique within the generated set\n\"topic\": \"string\",               // e.g., \"BFS\"\n\"difficulty\": \"easy|medium|hard\",\n\"question_type\": \"mcq|open_ended|code\",\n\"prompt\": \"string\",              // the question text\n\"choices\": [\"...\"] or null,      // for MCQ, else null\n\"correct_answer\": { ... },       // internal answer representation\n\"rubric\": \"string\"               // description of what a good answer should contain\n}\n\n- For MCQ:\n    - \"choices\": list of option strings, e.g., [\"A) ...\", \"B) ...\", ...]\n    - \"correct_answer\": e.g., { \"type\": \"mcq\", \"correct_index\": 1 }\n- For open_ended:\n    - \"choices\": null\n    - \"correct_answer\": e.g., { \"type\": \"open_ended\", \"key_points\": [\"...\", \"...\"] }\n- For code:\n    - \"choices\": null\n    - \"correct_answer\": e.g., {\n    \"type\": \"code\",\n    \"intended_algorithm\": \"description\",\n    \"required_properties\": [\"...\", \"...\"]\n    }\n\n4.2 GradingResult JSON\n\nWhen grading, use:\n\n{\n\"status\": \"success\" | \"error\",\n\"problem_id\": \"string\",\n\"score\": float,                  // 0.0 to 1.0\n\"verdict\": \"correct\" | \"partially_correct\" | \"incorrect\",\n\"feedback\": \"string\",            // explanation to student\n\"expected_key_points\": [\"...\"],  // what a good answer should include\n\"missing_points\": [\"...\"],       // what the student missed\n\"extra_notes\": \"string or null\", // optional\n\"error_message\": \"string or null\"\n}\n\nIf grading fails due to bad input:\n\n- status = \"error\"\n- error_message describes the issue.\n\n# ======================================================================\n5. Safety & Academic Integrity\n\n- You MUST generate **only synthetic** problems and rubrics.\n- Do NOT copy or imitate any specific real university exam or homework.\n- If a user pastes what looks like a real assignment or exam question and\nasks for a full solution, you may:\n    - Guide them with hints and teaching.\n    - Encourage them to learn and think through the problem.\n    - But you should not simply write full exam solutions in a cheating style.\n\n# ======================================================================\n6. Response Style Summary\n\n- For normal conversation:\n    - You can answer in friendly, structured natural language.\n- When JSON is requested (e.g., for tools or other agents):\n    - Output a **single valid JSON object or JSON list** with no markdown,\n    code fences, or extra commentary.\n- Be concise but clear, and always aligned with the Algorithm Mentor goal:\n    - Help the student practice and understand algorithms and data structures.\n\"\"\"\n\nprint(\"‚úÖ ProblemGenAutoGrader system prompt defined.\")\n\nproblem_agent = Agent(\n    name=\"problem_gen_autograder_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Algorithm Mentor's Problem Generator + Auto-Grader ‚Äì creates synthetic \"\n        \"practice problems for algorithms & data structures and grades answers.\"\n    ),\n    instruction=PROBLEM_GEN_AUTOGRADER_SYSTEM_PROMPT,\n    tools=[google_search],\n)\n\nproblem_runner = InMemoryRunner(agent=problem_agent)\nprint(\"‚úÖ ProblemGen + Auto-Grader Agent + runner defined.\")","metadata":{"_uuid":"69975f69-77a1-4ceb-b2cb-514154c29cb2","_cell_guid":"0ce9a7b8-107f-42b2-9048-e397fa0b09c5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:32.064692Z","iopub.execute_input":"2025-12-01T06:00:32.065208Z","iopub.status.idle":"2025-12-01T06:00:32.077471Z","shell.execute_reply.started":"2025-12-01T06:00:32.065175Z","shell.execute_reply":"2025-12-01T06:00:32.076334Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ProblemGenAutoGrader system prompt defined.\n‚úÖ ProblemGen + Auto-Grader Agent + runner defined.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# === 3.3 Visualization Agent ===================================================\n\nVISUALIZATION_AGENT_SYSTEM_PROMPT = \"\"\"\nYou are the Visualization Agent for an educational system called Algorithm Mentor.\n\nYour job:\n\n- Take algorithm / data-structure concepts and create **step-by-step visualizations**.\n- Output:\n    - Clear, structured **plain-language descriptions**, and\n    - When requested, a **single JSON visualization spec** that another system\n    (e.g., UI or tool) can render.\n\n======================================================================\n\n1. Supported Visualization Types (viz_type)\n======================================================================\n\nYou handle at least these visualization types:\n\n1. sorting\n\n    - Example algorithms: insertion sort, selection sort, bubble sort, merge sort, quicksort, heap sort.\n\n    - Visual form: array snapshots over time, highlighting elements being compared/moved/swapped, and showing subarrays or partitions.\n\n2. graph_traversal\n\n    - Algorithms: BFS, DFS, and edge classification (tree/back/forward/cross), etc.\n\n    - Visual form: a graph with nodes and edges; at each step, show:\n\n    current node, visited set, frontier (queue or stack), edge types as they are discovered (for DFS).\n\n3. shortest_paths_and_mst\n\n    - Algorithms: Dijkstra, Bellman‚ÄìFord, Prim, Kruskal, etc.\n\n    - Visual form: a weighted graph where each step shows:\n\n    current distances (for shortest paths) or current tree edges (for MST), which edge/node is being relaxed/added, the evolving shortest-path tree or spanning tree.\n\n4. dp_table\n\n    - Problems: coin change, 0/1 knapsack, Fibonacci DP, LIS, etc.\n\n    - Visual form: a 2D (or 1D) table with:\n        - row/column labels,\n        - the value in each cell,\n        - the order in which cells are filled,\n        - annotations for the recurrence used at important steps.\n\n5. recursion_tree\n\n    - Problems: recursive algorithms like merge sort, quicksort, recursive Fibonacci, divide-and-conquer recurrences.\n\n    - Visual form: a tree where:\n        - nodes are function calls or subproblems,\n        - edges show recursive calls,\n        - each node may show subproblem size and cost contribution.\n\n6. heap_and_priority_queue\n\n    - Data structures: binary heaps, priority queues.\n\n    - Visual form:\n        - a tree-shaped heap diagram (array index ‚Üî tree node),\n        - snapshots of insert, extract-min/extract-max, heapify operations,\n        - highlighting the nodes being swapped or bubbled up/down.\n\n7. hash_table\n\n    - Data structures: hashing with chaining or open addressing (linear probing, quadratic probing, etc.).\n\n    - Visual form:\n        - an array of buckets (for chaining) or slots (for probing),\n        - a small set of keys with their hash values,\n        - step-by-step insertion and lookup,\n        - visualization of collisions and how they are resolved.\n\n8. search_tree_structure\n\n    - Data structures: BSTs, AVL trees, B-trees, and other balanced search trees.\n    \n    - Visual form:\n        - tree diagrams showing node keys and child pointers,\n        - step-by-step insertion/deletion,\n        - rotations (for AVL) or splits/merges (for B-trees),\n        - highlighting the path taken during search.\n\n9. complexity_growth\n\n    - Topics: asymptotic analysis (Big-O, Big-Theta, Big-Omega), worst/best/average case.\n    \n    - Visual form:\n        - simple plots or tables comparing O(1), O(log n), O(n), O(n log n), O(n^2) on small input sizes,\n        - step-by-step ‚Äúwhat happens when n doubles?‚Äù style summaries.\n\n10. np_completeness_and_reductions (high-level / conceptual)\n\n    - Topics: NP, NP-hard, NP-complete, reductions.\n    \n    - Visual form:\n        - small diagrams showing how one problem is transformed into another,\n        - boxes representing problems and arrows representing reductions,\n        - labels explaining ‚Äúif we could solve B fast, we could solve A fast via this mapping‚Äù.\n\nYou can also combine a short textual explanation with the visualization spec.\n\n# ======================================================================\n2. General Rules\n\n- Always use **synthetic examples**:\n    - Small arrays (length 5‚Äì8).\n    - Tiny graphs (4‚Äì7 nodes).\n    - Small DP tables.\n    - Compact recursion trees.\n- Inputs may be partially specified, e.g., \"visualize merge sort on [4,1,3,9,7]\"\nor \"visualize BFS on a tiny unweighted graph\".\n- If the user does not specify an input, invent a tiny, reasonable example.\n- Explanations must be:\n    - Step-by-step.\n    - Concrete (show actual values).\n    - Friendly to a stressed undergraduate.\n\n# ======================================================================\n3. Behavior for Normal (Non-JSON) Responses\n\nWhen the user just says something like:\n\n- \"Visualize merge sort on [4,1,3,9,7]\"\n- \"Show BFS step-by-step on a small graph\"\n\nYou:\n\n1. Decide the viz_type (sorting, graph_traversal, dp_table, recursion_tree, etc.).\n2. Choose or confirm the small example.\n3. Explain step-by-step in **Markdown**:\n\n    ### Overview\n\n    ...\n\n    ### Step-by-step\n\n    Step 0: ...\n    Step 1: ...\n    Step 2: ...\n\n    You may use simple ASCII art or tables, such as:\n\n    Array: [4, 1, 3, 9, 7]\n    Step 1: [1, 4, 3, 9, 7]  (compare 4 and 1, swap)\n\n    Or for BFS:\n\n    Step 0:\n\n    - visited = {A}\n    - frontier (queue) = [A]\n\n    Step 1:\n\n    - visited = {A, B, C}\n    - frontier = [B, C]\n4. End with a short \"What this picture tells you\" summary.\n\n# ======================================================================\n4. JSON VisualizationSpec for Structured Output\n\nSometimes you will be asked to output a **single JSON visualization spec**\ninstead of Markdown. When that happens:\n\n- You MUST output **only a JSON object**, with no markdown, no comments, no\nbackticks.\n- The object must conform to this general schema:\n\n{\n\"viz_type\": \"sorting\" | \"graph_traversal\" | \"dp_table\" | \"recursion_tree\",\n\"title\": \"string\",\n\"description\": \"string\",\n\"data\": { ... }\n}\n\nWhere:\n\n4.1 For viz_type == \"sorting\":\n\n\"data\" should contain:\n{\n\"algorithm\": \"string\",              // e.g., \"merge sort\"\n\"initial_array\": [4, 1, 3, 9, 7],\n\"steps\": [\n{\n\"step_index\": 0,\n\"array_state\": [4, 1, 3, 9, 7],\n\"highlighted_indices\": [0, 1],\n\"explanation\": \"Compare 4 and 1; 1 should come first.\"\n},\n...\n]\n}\n\n4.2 For viz_type == \"graph_traversal\":\n\n\"data\" should contain:\n{\n\"algorithm\": \"BFS\" or \"DFS\",\n\"nodes\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n\"edges\": [[\"A\",\"B\"], [\"A\",\"C\"], [\"B\",\"D\"], [\"C\",\"E\"]],\n\"start_node\": \"A\",\n\"steps\": [\n{\n\"step_index\": 0,\n\"current_node\": \"A\",\n\"visited\": [\"A\"],\n\"frontier\": [\"A\"],\n\"explanation\": \"Start at A; mark it visited and put it in the queue.\"\n},\n...\n]\n}\n\n4.3 For viz_type == \"dp_table\":\n\n\"data\" should contain:\n{\n\"problem_name\": \"Coin change for amount 5 with coins [1,2,5]\",\n\"row_labels\": [...],\n\"col_labels\": [...],\n\"table\": [\n[0, 1, 1, 2, 2, 1],\n...\n],\n\"fill_order\": [\n{\n\"step_index\": 0,\n\"i\": 0,\n\"j\": 0,\n\"new_value\": 1,\n\"explanation\": \"Base case: 0 ways to make positive amount with 0 coins.\"\n},\n...\n]\n}\n\n4.4 For viz_type == \"recursion_tree\":\n\n\"data\" should contain:\n{\n\"problem_name\": \"Merge sort on [4,1,3,9]\",\n\"root_id\": \"n0\",\n\"nodes\": [\n{\n\"node_id\": \"n0\",\n\"label\": \"[4,1,3,9]\",\n\"children\": [\"n1\", \"n2\"],\n\"explanation\": \"Split into left and right halves.\"\n},\n...\n]\n}\n\n# ======================================================================\n5. Safety & Content Rules\n\n- Use only synthetic examples and small sizes.\n- Do not copy from any real textbook or slides; you can use standard algorithm\nknowledge and your own words.\n- Visualizations are for **learning and intuition**, not for cheating on exams.\n\n# ======================================================================\n6. Output Style Rules (Summary)\n\n- If the user asks for a normal explanation:\n    - Use structured Markdown with headings and bullet points.\n- If the user explicitly asks for JSON or a \"VisualizationSpec\", then:\n    - Output a single JSON object with fields:\n        - viz_type\n        - title\n        - description\n        - data { ... }\n    - No backticks, no markdown, no trailing commentary.\n\nYour priority:\n\n- Make the algorithm's behavior **visible** and **intuitive**.\n\"\"\"\n\nprint(\"‚úÖ Visualization Agent system prompt defined.\")\n\nviz_agent = Agent(\n    name=\"visualization_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Algorithm Mentor's Visualization Agent ‚Äì creates step-by-step, synthetic \"\n        \"visualizations of algorithms and data structures.\"\n    ),\n    static_instruction=VISUALIZATION_AGENT_SYSTEM_PROMPT,\n    tools=[google_search],\n)\n\nviz_runner = InMemoryRunner(agent=viz_agent)\nprint(\"‚úÖ Visualization Agent + runner defined.\")","metadata":{"_uuid":"681850a7-e3fc-4a69-928f-c370e9a4a649","_cell_guid":"b077fd6d-ad34-4e03-9cfa-00ad1c2e1452","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:32.819211Z","iopub.execute_input":"2025-12-01T06:00:32.819616Z","iopub.status.idle":"2025-12-01T06:00:32.832350Z","shell.execute_reply.started":"2025-12-01T06:00:32.819586Z","shell.execute_reply":"2025-12-01T06:00:32.831193Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Visualization Agent system prompt defined.\n‚úÖ Visualization Agent + runner defined.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# === 3.4 Diagnostic + Personalization (Orchestrator) Agent =====================\n\nDIAGNOSTIC_PERSONALIZATION_SYSTEM_PROMPT = \"\"\"\nYou are the **Diagnostic + Personalization Agent** for an educational system\ncalled Algorithm Mentor.\n\nYour role:\n\n- Read the student's message and the current session state.\n- Diagnose what the student actually needs right now.\n- Choose the mode (tutor / practice / exam / review).\n- Choose the topic and difficulty.\n- Plan which specialist agents to call:\n    - Concept Explainer Agent\n    - ProblemGen + Auto-Grader Agent\n    - Visualization Agent\n- Output:\n    - A short, friendly explanation for the student.\n    - A machine-readable orchestration plan as a JSON object called OrchestratorTurn.\n\n======================================================================\n\n1. Student & Session Context\n======================================================================\n\nYou will be given a compact JSON summary of:\n\n- SessionState:\n    - turn_index\n    - mode\n    - current_topic\n    - current_difficulty\n    - student_profile (preferred_language, preferred_code_lang,\n    explanation_level, goal_description)\n    - mastery_map: topics like bfs, dfs, sorting, dp_knapsack, recursion\n    - recent_intents: recent high-level intents you inferred\n- The latest student message.\n\nAssume:\n\n- The student is smart but may be stressed, tired, or anxious.\n- English may not be their first language.\n- They often have gaps in math, recursion, or graph intuition.\n\nYou must always take this context into account when planning the next step.\n\n# ======================================================================\n2. Intents & Modes\n\nInternally, classify the student's message into one or more **intents** such as:\n\n- EXPLAIN_CONCEPT\n- PRACTICE_PROBLEMS\n- EXAM_MODE\n- CODE_HELP\n- VISUALIZE\n- STUDY_ADVICE\n- META (talking about goals, motivation, progress, etc.)\n\nThen decide the **mode** for this turn:\n\n- \"tutor\"\n    - Gentle explanation + small practice.\n- \"practice\"\n    - More questions, grading, and feedback.\n- \"exam\"\n    - Simulate an exam: limited hints, more serious tone.\n- \"review\"\n    - Focus on weaker topics in the mastery map.\n\nGuidelines:\n\n- If the student says they are lost/confused/anxious -> prefer mode = \"tutor\".\n- If they explicitly ask for more questions -> mode = \"practice\".\n- If they explicitly request exam simulation -> mode = \"exam\".\n- If they ask what to review before an exam -> mode = \"review\".\n\n# ======================================================================\n3. Topics & Difficulty\n\nYou must also choose:\n\n- topic:\n    - Use explicit mentions like \"BFS\", \"DFS\", \"AVL tree\", \"hash table\",\n    \"dynamic programming knapsack\", \"shortest paths\", etc.\n    - If not given, infer from context or choose a topic where the mastery map\n    shows low mastery_level.\n- difficulty:\n    - \"easy\" | \"medium\" | \"hard\"\n    - Reflect student's anxiety and mastery:\n        - If mastery is low or they are anxious -> \"easy\".\n        - If mastery is medium and they ask for a challenge -> \"medium\" or \"hard\".\n        - If they are strong and near exam -> \"medium\" or \"hard\".\n\n# ======================================================================\n4. Planning Actions (Coordinator Pattern)\n\nYou do NOT execute algorithms or grade code yourself. Instead, you plan\nwhich specialist to call.\n\nYou have these abstract actions available:\n\n- CALL_CONCEPT_EXPLAINER\n    - When the student needs an explanation, example, or conceptual overview.\n- CALL_PROBLEM_GEN_AUTOGRADER\n    - When they need practice problems and/or grading.\n- CALL_VISUALIZATION\n    - When a visual or step-by-step simulation (sorting, BFS, DP table,\n    recursion tree) would help.\n\nYou can combine them in a sequence, for example:\n\n- Explain BFS intuition (Concept Explainer).\n- Then run a small BFS visualization (Visualization Agent).\n- Then give 2 easy BFS practice questions (ProblemGen + Auto-Grader).\n\nThe plan is represented as an array of **PlannedAction** objects with:\n\n- type: string (e.g., \"CALL_CONCEPT_EXPLAINER\")\n- payload: JSON object with parameters, e.g.:\n\n    {\n    \"type\": \"CALL_CONCEPT_EXPLAINER\",\n    \"payload\": {\n    \"topic\": \"bfs\",\n    \"focus\": \"edge types and intuition\",\n    \"mode\": \"tutor\"\n    }\n    }\n\n# ======================================================================\n5. Mastery Updates (Memory-lite)\n\nYou should optionally propose an update to the student's mastery map.\n\nRepresent mastery updates as a **MasteryUpdate** object:\n\n- topic: string\n- delta: float (how much to adjust mastery_level, e.g., +0.1 or -0.2)\n- reason: string (short explanation)\n\nExamples:\n\n- If the student says \"I finally get BFS now\" -> positive delta.\n- If they say \"I still do not understand DFS tree vs back edges\" -> negative delta.\n- If they struggled in practice questions (you can be told that in context),\nyou can use a negative delta.\n\nIf no update is appropriate, mastery_update can be null.\n\n# ======================================================================\n6. OrchestratorTurn JSON Schema\n\nWhen specifically asked (in the user message), you must output a **single\nOrchestratorTurn JSON object** with this structure:\n\n{\n\"intent\": \"EXPLAIN_CONCEPT\",\n\"selected_mode\": \"tutor\",\n\"topic\": \"bfs\",\n\"difficulty\": \"easy\",\n\"actions\": [\n{\n\"type\": \"CALL_CONCEPT_EXPLAINER\",\n\"payload\": {\n\"topic\": \"bfs\",\n\"emphasis\": \"edge types and intuition\",\n\"mode\": \"tutor\"\n}\n},\n{\n\"type\": \"CALL_PROBLEM_GEN_AUTOGRADER\",\n\"payload\": {\n\"topic\": \"bfs\",\n\"difficulty\": \"easy\",\n\"num_questions\": 2\n}\n}\n],\n\"mastery_update\": {\n\"topic\": \"bfs\",\n\"delta\": -0.2,\n\"reason\": \"student explicitly said they are confused\"\n},\n\"notes_for_subagents\": \"Use simple language and concrete examples; avoid heavy notation.\"\n}\n\nRules:\n\n- All fields must be present:\n    - intent (string)\n    - selected_mode (string)\n    - topic (string or null)\n    - difficulty (string or null)\n    - actions (array of objects with type and payload)\n    - mastery_update (object or null)\n    - notes_for_subagents (string or null)\n- actions must not be empty unless the student is only asking META questions.\n- The JSON must be valid and parseable.\n\n# ======================================================================\n7. Response Format for This Notebook\n\nWhen the notebook asks you to output **both** an explanation and an\nOrchestratorTurn JSON object, you must follow this format:\n\n1. First, write a short explanation for the student in natural language.\n2. Then on a new line write exactly:\nORCHESTRATOR_JSON:\n3. On the very next line, output ONLY a single JSON object representing\nthe OrchestratorTurn, with no extra markdown or backticks.\n\nExample pattern:\n\nI think you are mainly struggling with BFS intuition, especially how the queue\ndrives the order of exploration. We should start with a clear explanation and\nthen do two easy practice questions.\n\nORCHESTRATOR_JSON:\n{\n\"intent\": \"EXPLAIN_CONCEPT\",\n\"selected_mode\": \"tutor\",\n...\n}\n\nDo not wrap the JSON in backticks or markdown fences.\n\n# ======================================================================\n8. Safety & Academic Integrity\n\n- Encourage understanding, not cheating.\n- You may help with exam-style questions, but:\n    - Prefer to offer hints, explanations, and scaffolding.\n    - Avoid behaving like an answer-dump for real assignments or exams.\n- Do not claim to use any private or proprietary course materials.\n- Use only high-level, generic algorithm knowledge.\n\n# ======================================================================\n9. Style for Student-Facing Text\n\n- Be kind, concise, and structured.\n- Use short paragraphs and bullet points when helpful.\n- Acknowledge anxiety briefly if obvious:\n    - e.g., \"This topic is genuinely tricky; it is normal to feel stuck here.\"\n- End with 1‚Äì3 suggestions for what the student can ask next:\n\n    For example:\n\n    - \"We can now: (a) walk through a BFS example, (b) practice 2 easy questions,\n    or (c) visualize BFS on a small graph. Which would you prefer?\"\n\"\"\"\n\nprint(\"‚úÖ Diagnostic + Personalization system prompt defined.\")\n\ndiagnostic_agent = Agent(\n    name=\"diagnostic_personalization_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Diagnostic + Personalization agent that interprets the student's needs, \"\n        \"recommends mode/topic/difficulty, and plans calls to specialist agents.\"\n    ),\n    instruction=DIAGNOSTIC_PERSONALIZATION_SYSTEM_PROMPT,\n    tools=[google_search],\n)\n\ndiagnostic_runner = InMemoryRunner(agent=diagnostic_agent)\nprint(\"‚úÖ Diagnostic + Personalization Agent + runner defined.\")","metadata":{"_uuid":"d332073f-ff32-467e-91bc-7a5030b2cd7c","_cell_guid":"baa315f1-6043-4e93-9a56-bebcd8acb4d6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:33.544331Z","iopub.execute_input":"2025-12-01T06:00:33.544645Z","iopub.status.idle":"2025-12-01T06:00:33.556847Z","shell.execute_reply.started":"2025-12-01T06:00:33.544621Z","shell.execute_reply":"2025-12-01T06:00:33.555699Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Diagnostic + Personalization system prompt defined.\n‚úÖ Diagnostic + Personalization Agent + runner defined.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# === 3.5 Judge Agent (Evaluation Scaffold) =====================================\n\nJUDGE_SYSTEM_PROMPT = \"\"\"\nYou are the Judge Agent for Algorithm Mentor.\n\nYour role:\n\n- Evaluate the quality of outputs from:\n    - Concept Explainer Agent\n    - ProblemGen + Auto-Grader Agent\n    - Visualization Agent\n    - Diagnostic + Personalization Agent (orchestrator)\n- Use a simple, structured JSON rubric.\n\nGeneral behavior:\n\n- You will be given:\n    - A description of the test case.\n    - The requirements / expected properties.\n    - The actual agent output (as text).\n- You must:\n    - Read the description and requirements carefully.\n    - Inspect the agent output.\n    - Score it from 0.0 to 1.0.\n    - Decide whether it passes (score >= 0.7).\n    - Provide brief notes.\n\nOutput:\n\nReturn a SINGLE JSON object with:\n\n{\n\"score\": float,              // 0.0 to 1.0\n\"passed\": bool,              // true if score >= 0.7\n\"notes\": \"string\"            // short explanation of reasoning\n}\n\nRules:\n\n- Do NOT wrap this JSON in markdown or backticks.\n- Be strict but fair.\n- Focus on:\n    - Correctness\n    - Clarity and structure\n    - Whether the required sections/properties are present\n\"\"\"\n\njudge_agent = Agent(\n    name=\"judge_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=\"Judge Agent to evaluate Algorithm Mentor sub-agent outputs.\",\n    instruction=JUDGE_SYSTEM_PROMPT,\n    tools=[],\n)\n\njudge_runner = InMemoryRunner(agent=judge_agent)\nprint(\"‚úÖ Judge Agent + runner defined.\")","metadata":{"_uuid":"993007c5-3300-4d9b-81cc-7b319409b0e4","_cell_guid":"1d63f099-cd51-4cee-bbda-f1a56bace614","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:34.236524Z","iopub.execute_input":"2025-12-01T06:00:34.237052Z","iopub.status.idle":"2025-12-01T06:00:34.246708Z","shell.execute_reply.started":"2025-12-01T06:00:34.237017Z","shell.execute_reply":"2025-12-01T06:00:34.245445Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Judge Agent + runner defined.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# =====================================================================\n# 4. Session & Memory Helpers ‚Äì mastery + lightweight long-term memory\n# =====================================================================\n\nMEMORY_FILE_PATH = \"/kaggle/working/algorithm_mentor_memory.json\"\n\n\ndef init_default_state() -> SessionState:\n    \"\"\"\n    Initialize a fresh session state with default values.\n    \"\"\"\n    profile = StudentProfile(\n        persona=None,\n        preferred_language_level=\"standard\",\n        preferred_code_language=\"C++\",\n        explanation_level=\"standard\",\n        goal_description=\"Learn algorithms and data structures with Algorithm Mentor.\",\n    )\n    state = SessionState(\n        turn_index=0,\n        mode=\"tutor\",\n        current_topic=None,\n        current_difficulty=None,\n        student_profile=profile,\n        mastery_map={},\n        recent_intents=[],\n        chat_history=[],\n        rolling_summary=None,\n        long_term_notes=[],\n    )\n    return state\n\n\ndef apply_mastery_update(state: SessionState, update: MasteryUpdate) -> None:\n    \"\"\"\n    Apply a mastery update to the session state in-place.\n\n    - Ensures the topic exists in mastery_map.\n    - Adjusts mastery_level by delta and clamps to [0.0, 1.0].\n    - Updates last_updated_turn.\n    \"\"\"\n    topic = update.topic\n    if topic not in state.mastery_map:\n        state.mastery_map[topic] = MasteryEntry(topic=topic, mastery_level=0.0, last_updated_turn=state.turn_index)\n\n    entry = state.mastery_map[topic]\n    new_level = entry.mastery_level + update.delta\n    # Clamp to [0.0, 1.0]\n    new_level = max(0.0, min(1.0, new_level))\n    entry.mastery_level = new_level\n    entry.last_updated_turn = state.turn_index\n\n\ndef compact_history_if_needed(state: SessionState, max_turns: int = 12) -> None:\n    \"\"\"\n     context compaction strategy:\n\n    - If chat_history is longer than max_turns:\n      - Move older messages into `rolling_summary` (as plain text).\n      - Keep only the last `max_turns` events verbatim.\n\n    This mimics \"keep last N turns + compress earlier content\" without\n    needing an extra LLM summarization call.\n    \"\"\"\n    if len(state.chat_history) <= max_turns:\n        return\n\n    old_events = state.chat_history[:-max_turns]\n    tail_events = state.chat_history[-max_turns:]\n\n    condensed_lines = []\n    for ev in old_events:\n        role = ev.get(\"role\", \"unknown\")\n        content = ev.get(\"content\", \"\")\n        condensed_lines.append(f\"{role}: {content}\")\n\n    merged = \"\\n\".join(condensed_lines)\n    if state.rolling_summary:\n        state.rolling_summary += \"\\n\\n[Earlier conversation continued]\\n\" + merged\n    else:\n        state.rolling_summary = merged\n\n    state.chat_history = tail_events\n\n\ndef save_long_term_memory(state: SessionState, path: str = MEMORY_FILE_PATH) -> None:\n    \"\"\"\n    Persist a small subset of state as JSON \"long-term memory\".\n\n    This is a simple stand-in for a Memory Bank:\n    - student_profile\n    - mastery_map (topic + mastery_level)\n    - long_term_notes\n    \"\"\"\n    try:\n        data = {\n            \"student_profile\": {\n                \"persona\": state.student_profile.persona,\n                \"preferred_language_level\": state.student_profile.preferred_language_level,\n                \"preferred_code_language\": state.student_profile.preferred_code_language,\n                \"explanation_level\": state.student_profile.explanation_level,\n                \"goal_description\": state.student_profile.goal_description,\n            },\n            \"mastery_map\": {\n                topic: {\n                    \"mastery_level\": entry.mastery_level,\n                    \"last_updated_turn\": entry.last_updated_turn,\n                }\n                for topic, entry in state.mastery_map.items()\n            },\n            \"long_term_notes\": list(state.long_term_notes),\n        }\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(data, f, indent=2)\n        # print(\"üíæ Long-term memory saved.\")\n    except Exception as e:\n        print(\"‚ö†Ô∏è Error saving long-term memory:\", e)\n\n\ndef load_long_term_memory(state: SessionState, path: str = MEMORY_FILE_PATH) -> None:\n    \"\"\"\n    Load prior long-term memory (if any) and merge into current SessionState.\n    \"\"\"\n    if not os.path.exists(path):\n        print(\"‚ÑπÔ∏è No existing long-term memory file found (fresh start).\")\n        return\n\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            data = json.load(f)\n    except Exception as e:\n        print(\"‚ö†Ô∏è Error loading long-term memory:\", e)\n        return\n\n    # Merge student_profile\n    sp = data.get(\"student_profile\", {})\n    state.student_profile.persona = sp.get(\"persona\", state.student_profile.persona)\n    state.student_profile.preferred_language_level = sp.get(\n        \"preferred_language_level\", state.student_profile.preferred_language_level\n    )\n    state.student_profile.preferred_code_language = sp.get(\n        \"preferred_code_language\", state.student_profile.preferred_code_language\n    )\n    state.student_profile.explanation_level = sp.get(\n        \"explanation_level\", state.student_profile.explanation_level\n    )\n    state.student_profile.goal_description = sp.get(\n        \"goal_description\", state.student_profile.goal_description\n    )\n\n    # Merge mastery_map\n    mm = data.get(\"mastery_map\", {})\n    for topic, info in mm.items():\n        level = float(info.get(\"mastery_level\", 0.0))\n        last_turn = int(info.get(\"last_updated_turn\", 0))\n        state.mastery_map[topic] = MasteryEntry(topic=topic, mastery_level=level, last_updated_turn=last_turn)\n\n    # Merge long_term_notes\n    ltn = data.get(\"long_term_notes\", [])\n    state.long_term_notes.extend([str(x) for x in ltn])\n\n    print(\"‚úÖ Long-term memory loaded into session_state.\")\n\n\nprint(\"‚úÖ Session helpers (init_default_state / apply_mastery_update / compaction / memory IO) defined.\")","metadata":{"_uuid":"473f0f7c-337a-4e42-91c4-afec163e3fff","_cell_guid":"329c2f4b-7e91-4483-a0dd-767423a7e98f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:35.224709Z","iopub.execute_input":"2025-12-01T06:00:35.225043Z","iopub.status.idle":"2025-12-01T06:00:35.248111Z","shell.execute_reply.started":"2025-12-01T06:00:35.225020Z","shell.execute_reply":"2025-12-01T06:00:35.246732Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Session helpers (init_default_state / apply_mastery_update / compaction / memory IO) defined.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 4.1 Initialize global session_state once per kernel and load memory (Day 3)\n\ntry:\n    session_state\n    print(\"‚ÑπÔ∏è session_state already exists.\")\nexcept NameError:\n    session_state = init_default_state()\n    load_long_term_memory(session_state)\n    print(\"‚úÖ session_state initialized with init_default_state() + long-term memory load.\")","metadata":{"_uuid":"038a62bc-63e7-4697-b2d8-b7d5577354b7","_cell_guid":"71eccae5-7bdc-40c1-a1a2-05734544b21d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:36.232368Z","iopub.execute_input":"2025-12-01T06:00:36.232829Z","iopub.status.idle":"2025-12-01T06:00:36.240090Z","shell.execute_reply.started":"2025-12-01T06:00:36.232768Z","shell.execute_reply":"2025-12-01T06:00:36.238722Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Long-term memory loaded into session_state.\n‚úÖ session_state initialized with init_default_state() + long-term memory load.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# =====================================================================\n# 5. UX Helpers (Agent Calls) ‚Äì notebook-friendly wrappers\n# =====================================================================\n\ndef build_diagnostic_prompt(user_message: str, state: \"SessionState\") -> str:\n    \"\"\"\n    Build the user message for the Diagnostic Agent.\n\n    We include:\n    - A JSON dump of the current session state (already compacted).\n    - The student's latest natural-language message.\n    - A reminder of the required ORCHESTRATOR_JSON format.\n    \"\"\"\n    state_json = json.dumps(state.to_dict(), indent=2)\n\n    prompt = (\n        \"You are the Diagnostic + Personalization Agent.\\n\\n\"\n        \"Here is the current session state in JSON (already compacted):\\n\\n\"\n        f\"{state_json}\\n\\n\"\n        \"Student message:\\n\"\n        f\"\\\"\\\"\\\"{user_message}\\\"\\\"\\\"\\n\\n\"\n        \"Your tasks:\\n\\n\"\n        \"1. Briefly explain (in 2‚Äì4 sentences) what you think this student needs next.\\n\"\n        \"   - Consider the mastery_map, mode, and student_profile from the JSON.\\n\"\n        \"2. Then output a single OrchestratorTurn JSON object exactly as described\\n\"\n        \"   in your system prompt, using this pattern:\\n\\n\"\n        \"Explanation for the student.\\n\\n\"\n        \"ORCHESTRATOR_JSON:\\n\"\n        \"{ ... one valid JSON object ... }\\n\\n\"\n        \"Rules:\\n\"\n        \"- Do NOT wrap the JSON in backticks or markdown fences.\\n\"\n        \"- The JSON must include:\\n\"\n        \"  - intent\\n\"\n        \"  - selected_mode\\n\"\n        \"  - topic\\n\"\n        \"  - difficulty\\n\"\n        \"  - actions (non-empty, unless pure META)\\n\"\n        \"  - mastery_update (object or null)\\n\"\n        \"  - notes_for_subagents (string or null)\\n\"\n        \"- At least one action should call:\\n\"\n        \"  - CALL_CONCEPT_EXPLAINER, CALL_PROBLEM_GEN_AUTOGRADER, or CALL_VISUALIZATION,\\n\"\n        \"    depending on what the student needs.\\n\\n\"\n        \"Now respond following this format.\\n\"\n    )\n    return prompt\n\n\nprint(\"‚úÖ build_diagnostic_prompt(...) defined.\")","metadata":{"_uuid":"1aed3504-3e02-4dbb-90e3-3d810d622619","_cell_guid":"bc6f5cf0-f34a-4b66-a211-fb8b36e0b7e4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:37.277562Z","iopub.execute_input":"2025-12-01T06:00:37.278217Z","iopub.status.idle":"2025-12-01T06:00:37.286126Z","shell.execute_reply.started":"2025-12-01T06:00:37.278182Z","shell.execute_reply":"2025-12-01T06:00:37.284886Z"}},"outputs":[{"name":"stdout","text":"‚úÖ build_diagnostic_prompt(...) defined.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from typing import Any as _Any\n\nasync def run_diagnostic_turn(user_message: str) -> _Any:\n    \"\"\"\n    Run a single turn of the Diagnostic + Personalization Agent.\n\n    Uses:\n    - global `session_state`\n    - global `diagnostic_runner` (InMemoryRunner for `diagnostic_agent`)\n\n    Also:\n    - updates turn_index\n    - appends to chat_history\n    - compacts history if needed\n    - saves long-term memory snapshot\n    \"\"\"\n    global session_state\n\n    if \"diagnostic_runner\" not in globals():\n        print(\"‚ùå diagnostic_runner not found. Make sure you defined it earlier.\")\n        return None\n    if \"session_state\" not in globals():\n        print(\"‚ùå session_state not found. Make sure you initialized it earlier.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.chat_history.append({\"role\": \"user\", \"content\": user_message})\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    print(\"\\nüöÄ Running Diagnostic + Personalization turn...\")\n    prompt = build_diagnostic_prompt(user_message, session_state)\n    response = await diagnostic_runner.run_debug(prompt)\n\n    # We don't have structured access to the LLM text here, but we still record a placeholder.\n    session_state.chat_history.append({\"role\": \"assistant\", \"content\": \"[Diagnostic response above]\"})\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    # Track a recent intent tag for analytics / personalization\n    session_state.recent_intents.append(\"DIAGNOSTIC_TURN\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    return response\n\n\nprint(\"‚úÖ run_diagnostic_turn(...) defined.\")","metadata":{"_uuid":"654ed248-ab77-4304-b42f-ce4e3e252588","_cell_guid":"e03528af-1fc6-4dab-b393-009262036999","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:38.165866Z","iopub.execute_input":"2025-12-01T06:00:38.166700Z","iopub.status.idle":"2025-12-01T06:00:38.175071Z","shell.execute_reply.started":"2025-12-01T06:00:38.166667Z","shell.execute_reply":"2025-12-01T06:00:38.173825Z"}},"outputs":[{"name":"stdout","text":"‚úÖ run_diagnostic_turn(...) defined.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"async def call_concept_explainer(\n    topic: str,\n    level: str = \"standard\",\n    persona_hint: str = \"\",\n) -> _Any:\n    \"\"\"\n    Call the Concept Explainer Agent via its runner.\n\n    Also:\n    - updates session_state.turn_index\n    - sets current_topic\n    - appends \"EXPLAIN_CONCEPT\" intent\n    - updates chat_history + compaction\n    - saves long-term memory\n    \"\"\"\n    global session_state\n\n    if \"concept_explainer_runner\" not in globals():\n        print(\"‚ùå concept_explainer_runner not found. Define it before calling this helper.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.current_topic = topic\n    session_state.recent_intents.append(\"EXPLAIN_CONCEPT\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    # Log a pseudo-user request for history purposes\n    session_state.chat_history.append(\n        {\"role\": \"user\", \"content\": f\"[Request explanation for topic '{topic}' at level '{level}']\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    user_prompt = (\n        \"You are Algorithm Mentor's Concept Explainer Agent.\\n\\n\"\n        \"Student persona hint:\\n\"\n        f\"{persona_hint}\\n\\n\"\n        \"Task:\\n\"\n        f'Explain the topic \"{topic}\" at a {level.upper()} level, following your\\n'\n        \"sequential pipeline (Overview, Intuition, Why it matters, Step-by-step trace,\\n\"\n        \"Pseudocode, Time & space complexity, Common pitfalls, Check your understanding).\\n\\n\"\n        \"Use Markdown sections.\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling Concept Explainer for topic: {topic}, level: {level}\")\n    response = await concept_explainer_runner.run_debug(user_prompt)\n\n    session_state.chat_history.append(\n        {\"role\": \"assistant\", \"content\": f\"[Concept explanation for {topic} shown above]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    return response\n\n\nasync def call_problem_generator(\n    topic: str,\n    difficulty: str = \"easy\",\n    num_questions: int = 2,\n) -> _Any:\n    \"\"\"\n    Call the ProblemGen + Auto-Grader Agent to generate practice problems.\n\n    Also:\n    - updates session_state.turn_index\n    - sets current_topic/current_difficulty\n    - appends \"PRACTICE_PROBLEMS\" intent\n    - updates chat_history + compaction\n    - saves long-term memory\n    \"\"\"\n    global session_state\n\n    if \"problem_runner\" not in globals():\n        print(\"‚ùå problem_runner not found. Define it before calling this helper.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.current_topic = topic\n    session_state.current_difficulty = difficulty\n    session_state.recent_intents.append(\"PRACTICE_PROBLEMS\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    session_state.chat_history.append(\n        {\n            \"role\": \"user\",\n            \"content\": f\"[Request {num_questions} {difficulty} practice problems on '{topic}']\",\n        }\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    user_prompt = (\n        \"You are the Problem Generator + Auto-Grader Agent for Algorithm Mentor.\\n\\n\"\n        \"Task:\\n\"\n        f\"Generate {num_questions} {difficulty} practice problems on \\\"{topic}\\\".\\n\\n\"\n        \"Requirements:\\n\"\n        \"- Use only synthetic problems (no copying real exams).\\n\"\n        \"- Make the questions clear and self-contained.\\n\"\n        \"- For each problem, provide:\\n\"\n        \"  - The question text.\\n\"\n        \"  - A brief internal answer/rubric.\\n\"\n        \"You may respond in structured, well-formatted natural language (no need for JSON here).\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling ProblemGen + Auto-Grader for topic: {topic}, difficulty: {difficulty}\")\n    response = await problem_runner.run_debug(user_prompt)\n\n    session_state.chat_history.append(\n        {\"role\": \"assistant\", \"content\": f\"[Generated practice problems for {topic} shown above]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    return response\n\n\nasync def call_visualization_agent(\n    viz_request: str,\n) -> _Any:\n    \"\"\"\n    Call the Visualization Agent via its runner.\n\n    Also:\n    - updates session_state.turn_index\n    - appends \"VISUALIZE\" intent\n    - updates chat_history + compaction\n    - saves long-term memory\n    \"\"\"\n    global session_state\n\n    if \"viz_runner\" not in globals():\n        print(\"‚ùå viz_runner not found. Define it before calling this helper.\")\n        return None\n\n    session_state.turn_index += 1\n    session_state.recent_intents.append(\"VISUALIZE\")\n    if len(session_state.recent_intents) > 12:\n        session_state.recent_intents = session_state.recent_intents[-12:]\n\n    session_state.chat_history.append(\n        {\"role\": \"user\", \"content\": f\"[Request visualization: {viz_request}]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    user_prompt = (\n        f\"{viz_request}\\n\\n\"\n        \"Please:\\n\\n\"\n        \"Choose the appropriate viz_type (sorting, graph_traversal, dp_table,\\n\"\n        \"recursion_tree, heap_and_priority_queue, hash_table, search_tree_structure,\\n\"\n        \"complexity_growth, or np_completeness_and_reductions).\\n\\n\"\n        \"Use a tiny synthetic example.\\n\\n\"\n        \"Produce a step-by-step visualization in Markdown, with sections:\\n\\n\"\n        \"Overview\\n\\n\"\n        \"Step-by-step\\n\\n\"\n        \"What this picture tells you\\n\"\n    )\n\n    print(\"\\nüöÄ Calling Visualization Agent...\")\n    response = await viz_runner.run_debug(user_prompt)\n\n    session_state.chat_history.append(\n        {\"role\": \"assistant\", \"content\": \"[Visualization explanation shown above]\"}\n    )\n    compact_history_if_needed(session_state)\n    save_long_term_memory(session_state)\n\n    return response\n\n\nprint(\n    \"‚úÖ call_concept_explainer(...), call_problem_generator(...), \"\n    \"call_visualization_agent(...) defined.\"\n)","metadata":{"_uuid":"75e8173a-fdec-4964-88b6-9b8a2165ca74","_cell_guid":"a6fc78f8-7b6a-4b12-8c2f-23715c5e6cba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:39.041130Z","iopub.execute_input":"2025-12-01T06:00:39.042096Z","iopub.status.idle":"2025-12-01T06:00:39.060381Z","shell.execute_reply.started":"2025-12-01T06:00:39.042049Z","shell.execute_reply":"2025-12-01T06:00:39.058824Z"}},"outputs":[{"name":"stdout","text":"‚úÖ call_concept_explainer(...), call_problem_generator(...), call_visualization_agent(...) defined.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# =====================================================================\n# 6. Demo Cells ‚Äì end-to-end tutoring examples\n# =====================================================================\n\n# Example ‚Äì Concept Explainer\nawait call_concept_explainer(\n    topic=\"Dijkstra's algorithm\",\n    level=\"standard\",\n    persona_hint=\"Sara, overloaded CS undergrad, prefers C++-style pseudocode.\"\n)","metadata":{"_uuid":"1fd31874-47c6-4e7f-a675-af737105e89b","_cell_guid":"153a62c9-5cd5-4b5b-aae1-01550a5c34f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:40.088138Z","iopub.execute_input":"2025-12-01T06:00:40.088486Z","iopub.status.idle":"2025-12-01T06:00:47.055499Z","shell.execute_reply.started":"2025-12-01T06:00:40.088461Z","shell.execute_reply":"2025-12-01T06:00:47.054374Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Calling Concept Explainer for topic: Dijkstra's algorithm, level: standard\n\n ### Created new session: debug_session_id\n\nUser > You are Algorithm Mentor's Concept Explainer Agent.\n\nStudent persona hint:\nSara, overloaded CS undergrad, prefers C++-style pseudocode.\n\nTask:\nExplain the topic \"Dijkstra's algorithm\" at a STANDARD level, following your\nsequential pipeline (Overview, Intuition, Why it matters, Step-by-step trace,\nPseudocode, Time & space complexity, Common pitfalls, Check your understanding).\n\nUse Markdown sections.\n\nconcept_explainer_agent > ### Overview\n\nDijkstra's algorithm is a classic graph search algorithm used to find the shortest path between a designated source node and all other nodes in a weighted graph. It works by iteratively exploring the graph, always selecting the unvisited node with the smallest known distance from the source.\n\n### Intuition\n\nImagine you're trying to find the quickest way to deliver packages to different locations in a city, starting from your depot. You have a map with roads connecting various locations, and each road has a \"travel time\" associated with it. Dijkstra's algorithm is like a smart delivery planner. It starts at your depot and explores outwards, always prioritizing the next location that is *closest* to reach from the depot. It keeps track of the shortest time found so far to reach each location. If it discovers a new, faster route to a location it has already visited, it updates its record. It continues this process until it has found the shortest delivery time to every location.\n\n### Why it matters\n\nDijkstra's algorithm is fundamental in computer science and has numerous real-world applications:\n\n*   **Navigation Systems:** Used by GPS devices and mapping applications (like Google Maps or Waze) to find the shortest or fastest routes between two points.\n*   **Network Routing:** In computer networks, it helps determine the most efficient path for data packets to travel from a source to a destination.\n*   **Logistics and Transportation:** Optimizing delivery routes or transportation schedules.\n*   **Robotics:** Path planning for robots in complex environments.\n\n### Step-by-step trace (on a small example)\n\nLet's find the shortest paths from node 'A' to all other nodes in this sample graph:\n\nNodes: A, B, C, D\nEdges (with weights):\nA -> B (2)\nA -> C (5)\nB -> C (1)\nB -> D (6)\nC -> D (3)\n\nWe'll use a distance array `dist` (initialized to infinity, except for the source 'A' which is 0) and a set `visited` to keep track of visited nodes.\n\n**Initialization:**\n`dist = {A: 0, B: inf, C: inf, D: inf}`\n`visited = {}`\n`priority_queue = {(0, A)}` (stores (distance, node))\n\n**Iteration 1:**\n1.  **Extract Min:** Pop `(0, A)` from the priority queue.\n2.  **Mark Visited:** Add 'A' to `visited`.\n3.  **Relax Neighbors:**\n    *   Neighbor 'B': `dist[A] + weight(A, B) = 0 + 2 = 2`. Since `2 < dist[B]` (inf), update `dist[B] = 2`. Add `(2, B)` to PQ.\n    *   Neighbor 'C': `dist[A] + weight(A, C) = 0 + 5 = 5`. Since `5 < dist[C]` (inf), update `dist[C] = 5`. Add `(5, C)` to PQ.\n    `dist = {A: 0, B: 2, C: 5, D: inf}`\n    `visited = {A}`\n    `priority_queue = {(2, B), (5, C)}`\n\n**Iteration 2:**\n1.  **Extract Min:** Pop `(2, B)` from the priority queue.\n2.  **Mark Visited:** Add 'B' to `visited`.\n3.  **Relax Neighbors:**\n    *   Neighbor 'A': Already visited. Skip.\n    *   Neighbor 'C': `dist[B] + weight(B, C) = 2 + 1 = 3`. Since `3 < dist[C]` (5), update `dist[C] = 3`. Add `(3, C)` to PQ.\n    *   Neighbor 'D': `dist[B] + weight(B, D) = 2 + 6 = 8`. Since `8 < dist[D]` (inf), update `dist[D] = 8`. Add `(8, D)` to PQ.\n    `dist = {A: 0, B: 2, C: 3, D: 8}`\n    `visited = {A, B}`\n    `priority_queue = {(3, C), (5, C), (8, D)}` (Note: PQ might have duplicates, or implementations handle updates efficiently)\n\n**Iteration 3:**\n1.  **Extract Min:** Pop `(3, C)` from the priority queue.\n2.  **Mark Visited:** Add 'C' to `visited`.\n3.  **Relax Neighbors:**\n    *   Neighbor 'A': Already visited. Skip.\n    *   Neighbor 'B': Already visited. Skip.\n    *   Neighbor 'D': `dist[C] + weight(C, D) = 3 + 3 = 6`. Since `6 < dist[D]` (8), update `dist[D] = 6`. Add `(6, D)` to PQ.\n    `dist = {A: 0, B: 2, C: 3, D: 6}`\n    `visited = {A, B, C}`\n    `priority_queue = {(5, C), (8, D), (6, D)}`\n\n**Iteration 4:**\n1.  **Extract Min:** Pop `(5, C)` from the priority queue. 'C' is already visited. Skip.\n    `priority_queue = {(8, D), (6, D)}`\n\n**Iteration 5:**\n1.  **Extract Min:** Pop `(6, D)` from the priority queue.\n2.  **Mark Visited:** Add 'D' to `visited`.\n3.  **Relax Neighbors:** Node 'D' has no unvisited neighbors with edges.\n    `dist = {A: 0, B: 2, C: 3, D: 6}`\n    `visited = {A, B, C, D}`\n    `priority_queue = {(8, D)}`\n\nThe algorithm terminates as all nodes are visited. The shortest distances from A are: A:0, B:2, C:3, D:6.\n\n### Pseudocode\n\n```cpp\n// Assume graph is represented by an adjacency list:\n// vector<pair<int, int>> adj[num_vertices]; // adj[u] stores pairs of {v, weight}\n\n// Function to find shortest paths from a source vertex\nvector<int> dijkstra(int num_vertices, vector<pair<int, int>> adj[], int source) {\n    // Initialize distances: infinity for all, 0 for source\n    vector<int> dist(num_vertices, INT_MAX); // INT_MAX represents infinity\n    dist[source] = 0;\n\n    // Priority queue to store {distance, vertex} pairs.\n    // We use greater to make it a min-priority queue.\n    priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq;\n    pq.push({0, source}); // Push {distance, vertex}\n\n    // Set to keep track of visited vertices\n    // (Alternative: check if dist[u] is still its initial value before processing)\n    vector<bool> visited(num_vertices, false);\n\n    while (!pq.empty()) {\n        // Get the vertex with the smallest distance from the priority queue\n        int d = pq.top().first;\n        int u = pq.top().second;\n        pq.pop();\n\n        // If we have already processed this vertex, skip it.\n        // This can happen if we found a shorter path earlier and pushed it.\n        if (visited[u]) {\n            continue;\n        }\n\n        // Mark the vertex as visited\n        visited[u] = true;\n\n        // Relax all adjacent vertices of u\n        for (auto& edge : adj[u]) {\n            int v = edge.first;\n            int weight = edge.second;\n\n            // If a shorter path to v is found through u\n            if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) {\n                dist[v] = dist[u] + weight;\n                pq.push({dist[v], v}); // Push the updated distance and vertex\n            }\n        }\n    }\n\n    return dist; // Returns the vector of shortest distances from the source\n}\n```\n\n### Time & space complexity\n\n*   **Time Complexity:**\n    *   Using a binary heap (like `std::priority_queue` in C++): O((V + E) log V) or O(E log V) if E > V, where V is the number of vertices and E is the number of edges. Each vertex is extracted from the priority queue once (V extractions), and each edge relaxation can lead to a priority queue insertion (at most E insertions). Each PQ operation takes O(log V).\n    *   Using a Fibonacci heap: O(E + V log V) which is better for dense graphs.\n\n*   **Space Complexity:** O(V + E) to store the graph (adjacency list) and O(V) for the distance array and the priority queue.\n\n### Common pitfalls\n\n*   **Negative Edge Weights:** Dijkstra's algorithm is NOT guaranteed to work correctly if the graph contains negative edge weights. For graphs with negative edge weights, Bellman-Ford algorithm should be used.\n*   **Graph Representation:** Using an adjacency matrix for sparse graphs can lead to a higher time complexity (O(V^2)) compared to an adjacency list.\n*   **Priority Queue Implementation:** Incorrectly implementing the priority queue (e.g., not using a min-priority queue or handling updates poorly) can lead to incorrect results or much slower performance.\n*   **Ignoring Visited Nodes:** Not properly tracking visited nodes can lead to infinite loops in graphs with cycles, or redundant processing of nodes, impacting performance.\n\n### Check your understanding\n\n1.  Can Dijkstra's algorithm find the shortest path in a graph with a negative edge weight? Why or why not?\n2.  What data structure is commonly used to efficiently retrieve the node with the smallest distance, and what is its typical time complexity for extraction and insertion?\n3.  If a graph has 100 vertices and 500 edges, and all edge weights are positive, approximately what would be the time complexity of Dijkstra's algorithm using a binary heap?\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       text=\"\"\"### Overview\n \n Dijkstra's algorithm is a classic graph search algorithm used to find the shortest path between a designated source node and all other nodes in a weighted graph. It works by iteratively exploring the graph, always selecting the unvisited node with the smallest known distance from the source.\n \n ### Intuition\n \n Imagine you're trying to find the quickest way to deliver packages to different locations in a city, starting from your depot. You have a map with roads connecting various locations, and each road has a \"travel time\" associated with it. Dijkstra's algorithm is like a smart delivery planner. It starts at your depot and explores outwards, always prioritizing the next location that is *closest* to reach from the depot. It keeps track of the shortest time found so far to reach each location. If it discovers a new, faster route to a location it has already visited, it updates its record. It continues this process until it has found the shortest delivery time to every location.\n \n ### Why it matters\n \n Dijkstra's algorithm is fundamental in computer science and has numerous real-world applications:\n \n *   **Navigation Systems:** Used by GPS devices and mapping applications (like Google Maps or Waze) to find the shortest or fastest routes between two points.\n *   **Network Routing:** In computer networks, it helps determine the most efficient path for data packets to travel from a source to a destination.\n *   **Logistics and Transportation:** Optimizing delivery routes or transportation schedules.\n *   **Robotics:** Path planning for robots in complex environments.\n \n ### Step-by-step trace (on a small example)\n \n Let's find the shortest paths from node 'A' to all other nodes in this sample graph:\n \n Nodes: A, B, C, D\n Edges (with weights):\n A -> B (2)\n A -> C (5)\n B -> C (1)\n B -> D (6)\n C -> D (3)\n \n We'll use a distance array `dist` (initialized to infinity, except for the source 'A' which is 0) and a set `visited` to keep track of visited nodes.\n \n **Initialization:**\n `dist = {A: 0, B: inf, C: inf, D: inf}`\n `visited = {}`\n `priority_queue = {(0, A)}` (stores (distance, node))\n \n **Iteration 1:**\n 1.  **Extract Min:** Pop `(0, A)` from the priority queue.\n 2.  **Mark Visited:** Add 'A' to `visited`.\n 3.  **Relax Neighbors:**\n     *   Neighbor 'B': `dist[A] + weight(A, B) = 0 + 2 = 2`. Since `2 < dist[B]` (inf), update `dist[B] = 2`. Add `(2, B)` to PQ.\n     *   Neighbor 'C': `dist[A] + weight(A, C) = 0 + 5 = 5`. Since `5 < dist[C]` (inf), update `dist[C] = 5`. Add `(5, C)` to PQ.\n     `dist = {A: 0, B: 2, C: 5, D: inf}`\n     `visited = {A}`\n     `priority_queue = {(2, B), (5, C)}`\n \n **Iteration 2:**\n 1.  **Extract Min:** Pop `(2, B)` from the priority queue.\n 2.  **Mark Visited:** Add 'B' to `visited`.\n 3.  **Relax Neighbors:**\n     *   Neighbor 'A': Already visited. Skip.\n     *   Neighbor 'C': `dist[B] + weight(B, C) = 2 + 1 = 3`. Since `3 < dist[C]` (5), update `dist[C] = 3`. Add `(3, C)` to PQ.\n     *   Neighbor 'D': `dist[B] + weight(B, D) = 2 + 6 = 8`. Since `8 < dist[D]` (inf), update `dist[D] = 8`. Add `(8, D)` to PQ.\n     `dist = {A: 0, B: 2, C: 3, D: 8}`\n     `visited = {A, B}`\n     `priority_queue = {(3, C), (5, C), (8, D)}` (Note: PQ might have duplicates, or implementations handle updates efficiently)\n \n **Iteration 3:**\n 1.  **Extract Min:** Pop `(3, C)` from the priority queue.\n 2.  **Mark Visited:** Add 'C' to `visited`.\n 3.  **Relax Neighbors:**\n     *   Neighbor 'A': Already visited. Skip.\n     *   Neighbor 'B': Already visited. Skip.\n     *   Neighbor 'D': `dist[C] + weight(C, D) = 3 + 3 = 6`. Since `6 < dist[D]` (8), update `dist[D] = 6`. Add `(6, D)` to PQ.\n     `dist = {A: 0, B: 2, C: 3, D: 6}`\n     `visited = {A, B, C}`\n     `priority_queue = {(5, C), (8, D), (6, D)}`\n \n **Iteration 4:**\n 1.  **Extract Min:** Pop `(5, C)` from the priority queue. 'C' is already visited. Skip.\n     `priority_queue = {(8, D), (6, D)}`\n \n **Iteration 5:**\n 1.  **Extract Min:** Pop `(6, D)` from the priority queue.\n 2.  **Mark Visited:** Add 'D' to `visited`.\n 3.  **Relax Neighbors:** Node 'D' has no unvisited neighbors with edges.\n     `dist = {A: 0, B: 2, C: 3, D: 6}`\n     `visited = {A, B, C, D}`\n     `priority_queue = {(8, D)}`\n \n The algorithm terminates as all nodes are visited. The shortest distances from A are: A:0, B:2, C:3, D:6.\n \n ### Pseudocode\n \n \"\"\"\n     ),\n     Part(\n       text=\"\"\"```cpp\n // Assume graph is represented by an adjacency list:\n // vector<pair<int, int>> adj[num_vertices]; // adj[u] stores pairs of {v, weight}\n \n // Function to find shortest paths from a source vertex\n vector<int> dijkstra(int num_vertices, vector<pair<int, int>> adj[], int source) {\n     // Initialize distances: infinity for all, 0 for source\n     vector<int> dist(num_vertices, INT_MAX); // INT_MAX represents infinity\n     dist[source] = 0;\n \n     // Priority queue to store {distance, vertex} pairs.\n     // We use greater to make it a min-priority queue.\n     priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq;\n     pq.push({0, source}); // Push {distance, vertex}\n \n     // Set to keep track of visited vertices\n     // (Alternative: check if dist[u] is still its initial value before processing)\n     vector<bool> visited(num_vertices, false);\n \n     while (!pq.empty()) {\n         // Get the vertex with the smallest distance from the priority queue\n         int d = pq.top().first;\n         int u = pq.top().second;\n         pq.pop();\n \n         // If we have already processed this vertex, skip it.\n         // This can happen if we found a shorter path earlier and pushed it.\n         if (visited[u]) {\n             continue;\n         }\n \n         // Mark the vertex as visited\n         visited[u] = true;\n \n         // Relax all adjacent vertices of u\n         for (auto& edge : adj[u]) {\n             int v = edge.first;\n             int weight = edge.second;\n \n             // If a shorter path to v is found through u\n             if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) {\n                 dist[v] = dist[u] + weight;\n                 pq.push({dist[v], v}); // Push the updated distance and vertex\n             }\n         }\n     }\n \n     return dist; // Returns the vector of shortest distances from the source\n }\n ```\"\"\"\n     ),\n     Part(\n       text=\"\"\"\n \n ### Time & space complexity\n \n *   **Time Complexity:**\n     *   Using a binary heap (like `std::priority_queue` in C++): O((V + E) log V) or O(E log V) if E > V, where V is the number of vertices and E is the number of edges. Each vertex is extracted from the priority queue once (V extractions), and each edge relaxation can lead to a priority queue insertion (at most E insertions). Each PQ operation takes O(log V).\n     *   Using a Fibonacci heap: O(E + V log V) which is better for dense graphs.\n \n *   **Space Complexity:** O(V + E) to store the graph (adjacency list) and O(V) for the distance array and the priority queue.\n \n ### Common pitfalls\n \n *   **Negative Edge Weights:** Dijkstra's algorithm is NOT guaranteed to work correctly if the graph contains negative edge weights. For graphs with negative edge weights, Bellman-Ford algorithm should be used.\n *   **Graph Representation:** Using an adjacency matrix for sparse graphs can lead to a higher time complexity (O(V^2)) compared to an adjacency list.\n *   **Priority Queue Implementation:** Incorrectly implementing the priority queue (e.g., not using a min-priority queue or handling updates poorly) can lead to incorrect results or much slower performance.\n *   **Ignoring Visited Nodes:** Not properly tracking visited nodes can lead to infinite loops in graphs with cycles, or redundant processing of nodes, impacting performance.\n \n ### Check your understanding\n \n 1.  Can Dijkstra's algorithm find the shortest path in a graph with a negative edge weight? Why or why not?\n 2.  What data structure is commonly used to efficiently retrieve the node with the smallest distance, and what is its typical time complexity for extraction and insertion?\n 3.  If a graph has 100 vertices and 500 edges, and all edge weights are positive, approximately what would be the time complexity of Dijkstra's algorithm using a binary heap?\"\"\"\n     ),\n   ],\n   role='model'\n ), grounding_metadata=GroundingMetadata(), partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=2317,\n   prompt_token_count=1094,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=1094\n     ),\n   ],\n   total_token_count=3411\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-35980a89-fbb3-4e40-a61b-aaea0b48f080', author='concept_explainer_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='6b94fd7c-0893-44a9-9820-278237de1c7b', timestamp=1764568840.101565)]"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Example ‚Äì Problem Generator\nawait call_problem_generator(\n    topic=\"binary search\",\n    difficulty=\"easy\",\n    num_questions=2,\n)","metadata":{"_uuid":"ba5c17ec-4c9a-47ec-bc79-7370ff4c1807","_cell_guid":"46d5b8ae-b20c-49db-9365-9c7896759489","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:47.057191Z","iopub.execute_input":"2025-12-01T06:00:47.057567Z","iopub.status.idle":"2025-12-01T06:00:51.855341Z","shell.execute_reply.started":"2025-12-01T06:00:47.057536Z","shell.execute_reply":"2025-12-01T06:00:51.854254Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Calling ProblemGen + Auto-Grader for topic: binary search, difficulty: easy\n\n ### Created new session: debug_session_id\n\nUser > You are the Problem Generator + Auto-Grader Agent for Algorithm Mentor.\n\nTask:\nGenerate 2 easy practice problems on \"binary search\".\n\nRequirements:\n- Use only synthetic problems (no copying real exams).\n- Make the questions clear and self-contained.\n- For each problem, provide:\n  - The question text.\n  - A brief internal answer/rubric.\nYou may respond in structured, well-formatted natural language (no need for JSON here).\n\nproblem_gen_autograder_agent > Here are 2 easy practice problems on binary search, designed to be synthetic and self-contained:\n\n---\n\n### Problem 1\n\n**Topic:** Binary Search\n**Difficulty:** Easy\n**Question Type:** open_ended\n\n**Prompt:**\nImagine you have a sorted array of integers named `data` where `data[0] < data[1] < ... < data[n-1]`. You are given a target integer `target`. Describe, in your own words, the step-by-step process of how you would use binary search to find the index of `target` within `data`. If `target` is not present in the array, what would be the outcome of your process?\n\n**Internal Answer/Rubric:**\nA good answer should describe the following key steps:\n1.  **Initialization:** Set two pointers, `low` to the start index (0) and `high` to the end index (`n-1`).\n2.  **Loop Condition:** Continue searching as long as `low <= high`.\n3.  **Midpoint Calculation:** Calculate the middle index: `mid = floor((low + high) / 2)`.\n4.  **Comparison:**\n    *   If `data[mid]` equals `target`, the index `mid` is found.\n    *   If `data[mid]` is less than `target`, discard the left half by setting `low = mid + 1`.\n    *   If `data[mid]` is greater than `target`, discard the right half by setting `high = mid - 1`.\n5.  **Not Found:** If the loop finishes without finding `target` (i.e., `low > high`), the target is not in the array. The value of `low` (or `high + 1`) often indicates where it *would* be inserted.\n\n---\n\n### Problem 2\n\n**Topic:** Binary Search\n**Difficulty:** Easy\n**Question Type:** mcq\n\n**Prompt:**\nConsider a sorted array `A = [2, 5, 8, 12, 16, 23, 38, 56, 72, 91]`. You want to find the index of the number `23` using binary search. What is the sequence of `mid` values calculated during the search process?\n\n**Choices:**\nA) 4, 7, 5\nB) 4, 6, 5\nC) 5, 7, 5\nD) 5, 6, 5\n\n**Correct Answer:**\n*   **Type:** mcq\n*   **Correct Index:** 1 (Option B)\n*   **Explanation:**\n    1.  Initial: `low = 0`, `high = 9`. `mid = floor((0+9)/2) = 4`. `A[4] = 16`. Since `16 < 23`, `low` becomes `mid + 1 = 5`.\n    2.  Next: `low = 5`, `high = 9`. `mid = floor((5+9)/2) = 7`. `A[7] = 56`. Since `56 > 23`, `high` becomes `mid - 1 = 6`.\n    3.  Next: `low = 5`, `high = 6`. `mid = floor((5+6)/2) = 5`. `A[5] = 23`. Target found at index 5.\n    The sequence of calculated `mid` values is 4, 7, 5.\n\n---\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       text=\"\"\"Here are 2 easy practice problems on binary search, designed to be synthetic and self-contained:\n \n ---\n \n ### Problem 1\n \n **Topic:** Binary Search\n **Difficulty:** Easy\n **Question Type:** open_ended\n \n **Prompt:**\n Imagine you have a sorted array of integers named `data` where `data[0] < data[1] < ... < data[n-1]`. You are given a target integer `target`. Describe, in your own words, the step-by-step process of how you would use binary search to find the index of `target` within `data`. If `target` is not present in the array, what would be the outcome of your process?\n \n **Internal Answer/Rubric:**\n A good answer should describe the following key steps:\n 1.  **Initialization:** Set two pointers, `low` to the start index (0) and `high` to the end index (`n-1`).\n 2.  **Loop Condition:** Continue searching as long as `low <= high`.\n 3.  **Midpoint Calculation:** Calculate the middle index: `mid = floor((low + high) / 2)`.\n 4.  **Comparison:**\n     *   If `data[mid]` equals `target`, the index `mid` is found.\n     *   If `data[mid]` is less than `target`, discard the left half by setting `low = mid + 1`.\n     *   If `data[mid]` is greater than `target`, discard the right half by setting `high = mid - 1`.\n 5.  **Not Found:** If the loop finishes without finding `target` (i.e., `low > high`), the target is not in the array. The value of `low` (or `high + 1`) often indicates where it *would* be inserted.\n \n ---\n \n ### Problem 2\n \n **Topic:** Binary Search\n **Difficulty:** Easy\n **Question Type:** mcq\n \n **Prompt:**\n Consider a sorted array `A = [2, 5, 8, 12, 16, 23, 38, 56, 72, 91]`. You want to find the index of the number `23` using binary search. What is the sequence of `mid` values calculated during the search process?\n \n **Choices:**\n A) 4, 7, 5\n B) 4, 6, 5\n C) 5, 7, 5\n D) 5, 6, 5\n \n **Correct Answer:**\n *   **Type:** mcq\n *   **Correct Index:** 1 (Option B)\n *   **Explanation:**\n     1.  Initial: `low = 0`, `high = 9`. `mid = floor((0+9)/2) = 4`. `A[4] = 16`. Since `16 < 23`, `low` becomes `mid + 1 = 5`.\n     2.  Next: `low = 5`, `high = 9`. `mid = floor((5+9)/2) = 7`. `A[7] = 56`. Since `56 > 23`, `high` becomes `mid - 1 = 6`.\n     3.  Next: `low = 5`, `high = 6`. `mid = floor((5+6)/2) = 5`. `A[5] = 23`. Target found at index 5.\n     The sequence of calculated `mid` values is 4, 7, 5.\n \n ---\"\"\"\n     ),\n   ],\n   role='model'\n ), grounding_metadata=GroundingMetadata(), partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=785,\n   prompt_token_count=1783,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=1783\n     ),\n   ],\n   total_token_count=2568\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-c37ef231-6894-433a-b09b-b312ee0d54e7', author='problem_gen_autograder_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='f51302dd-d4bb-4db2-b972-8754c05fed12', timestamp=1764568847.062073)]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Example ‚Äì Diagnostic (Orchestrator)\nawait run_diagnostic_turn(\n    \"I'm confused about dynamic programming, especially 0/1 knapsack tables.\"\n)","metadata":{"_uuid":"e6d9caeb-6545-478a-a1b2-36756a03e355","_cell_guid":"09a46c2d-6579-4211-87ff-2f5dca7d67d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:00:51.856371Z","iopub.execute_input":"2025-12-01T06:00:51.856658Z","iopub.status.idle":"2025-12-01T06:00:55.147632Z","shell.execute_reply.started":"2025-12-01T06:00:51.856630Z","shell.execute_reply":"2025-12-01T06:00:55.146663Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Running Diagnostic + Personalization turn...\n\n ### Created new session: debug_session_id\n\nUser > You are the Diagnostic + Personalization Agent.\n\nHere is the current session state in JSON (already compacted):\n\n{\n  \"turn_index\": 3,\n  \"mode\": \"tutor\",\n  \"current_topic\": \"binary search\",\n  \"current_difficulty\": \"easy\",\n  \"student_profile\": {\n    \"persona\": null,\n    \"preferred_language_level\": \"standard\",\n    \"preferred_code_language\": \"C++\",\n    \"explanation_level\": \"standard\",\n    \"goal_description\": \"Learn algorithms and data structures with Algorithm Mentor.\"\n  },\n  \"mastery_map\": {},\n  \"recent_intents\": [\n    \"EXPLAIN_CONCEPT\",\n    \"PRACTICE_PROBLEMS\"\n  ],\n  \"chat_history_tail\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"[Request explanation for topic 'Dijkstra's algorithm' at level 'standard']\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"[Concept explanation for Dijkstra's algorithm shown above]\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"[Request 2 easy practice problems on 'binary search']\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"[Generated practice problems for binary search shown above]\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"I'm confused about dynamic programming, especially 0/1 knapsack tables.\"\n    }\n  ],\n  \"rolling_summary\": null,\n  \"long_term_notes\": []\n}\n\nStudent message:\n\"\"\"I'm confused about dynamic programming, especially 0/1 knapsack tables.\"\"\"\n\nYour tasks:\n\n1. Briefly explain (in 2‚Äì4 sentences) what you think this student needs next.\n   - Consider the mastery_map, mode, and student_profile from the JSON.\n2. Then output a single OrchestratorTurn JSON object exactly as described\n   in your system prompt, using this pattern:\n\nExplanation for the student.\n\nORCHESTRATOR_JSON:\n{ ... one valid JSON object ... }\n\nRules:\n- Do NOT wrap the JSON in backticks or markdown fences.\n- The JSON must include:\n  - intent\n  - selected_mode\n  - topic\n  - difficulty\n  - actions (non-empty, unless pure META)\n  - mastery_update (object or null)\n  - notes_for_subagents (string or null)\n- At least one action should call:\n  - CALL_CONCEPT_EXPLAINER, CALL_PROBLEM_GEN_AUTOGRADER, or CALL_VISUALIZATION,\n    depending on what the student needs.\n\nNow respond following this format.\n\ndiagnostic_personalization_agent > It looks like you're finding dynamic programming, specifically the 0/1 knapsack problem and its table representation, a bit tricky. This is a common sticking point, so it's completely understandable to feel confused. We should start by clarifying the core concepts of DP and how they apply to the knapsack problem, possibly with a visual aid.\n\nORCHESTRATOR_JSON:\n{\n  \"intent\": \"EXPLAIN_CONCEPT\",\n  \"selected_mode\": \"tutor\",\n  \"topic\": \"dynamic programming 0/1 knapsack\",\n  \"difficulty\": \"easy\",\n  \"actions\": [\n    {\n      \"type\": \"CALL_CONCEPT_EXPLAINER\",\n      \"payload\": {\n        \"topic\": \"dynamic programming 0/1 knapsack\",\n        \"focus\": \"table construction and intuition\",\n        \"mode\": \"tutor\"\n      }\n    },\n    {\n      \"type\": \"CALL_VISUALIZATION\",\n      \"payload\": {\n        \"topic\": \"dynamic programming 0/1 knapsack\",\n        \"visualization_type\": \"table building\",\n        \"mode\": \"tutor\"\n      }\n    }\n  ],\n  \"mastery_update\": {\n    \"topic\": \"dynamic programming 0/1 knapsack\",\n    \"delta\": -0.3,\n    \"reason\": \"student explicitly stated confusion about DP and 0/1 knapsack tables\"\n  },\n  \"notes_for_subagents\": \"Use clear, step-by-step explanations focusing on how each cell in the DP table is computed. Emphasize the overlapping subproblems and optimal substructure properties as they relate to knapsack.\"\n}\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       text=\"\"\"It looks like you're finding dynamic programming, specifically the 0/1 knapsack problem and its table representation, a bit tricky. This is a common sticking point, so it's completely understandable to feel confused. We should start by clarifying the core concepts of DP and how they apply to the knapsack problem, possibly with a visual aid.\n \n ORCHESTRATOR_JSON:\n {\n   \"intent\": \"EXPLAIN_CONCEPT\",\n   \"selected_mode\": \"tutor\",\n   \"topic\": \"dynamic programming 0/1 knapsack\",\n   \"difficulty\": \"easy\",\n   \"actions\": [\n     {\n       \"type\": \"CALL_CONCEPT_EXPLAINER\",\n       \"payload\": {\n         \"topic\": \"dynamic programming 0/1 knapsack\",\n         \"focus\": \"table construction and intuition\",\n         \"mode\": \"tutor\"\n       }\n     },\n     {\n       \"type\": \"CALL_VISUALIZATION\",\n       \"payload\": {\n         \"topic\": \"dynamic programming 0/1 knapsack\",\n         \"visualization_type\": \"table building\",\n         \"mode\": \"tutor\"\n       }\n     }\n   ],\n   \"mastery_update\": {\n     \"topic\": \"dynamic programming 0/1 knapsack\",\n     \"delta\": -0.3,\n     \"reason\": \"student explicitly stated confusion about DP and 0/1 knapsack tables\"\n   },\n   \"notes_for_subagents\": \"Use clear, step-by-step explanations focusing on how each cell in the DP table is computed. Emphasize the overlapping subproblems and optimal substructure properties as they relate to knapsack.\"\n }\"\"\"\n     ),\n   ],\n   role='model'\n ), grounding_metadata=GroundingMetadata(), partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=373,\n   prompt_token_count=2652,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=2652\n     ),\n   ],\n   total_token_count=3025\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-ca69c64b-feda-44db-b8af-007fe2dbee5a', author='diagnostic_personalization_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='41c27366-af17-49b2-b0b4-1de61b623470', timestamp=1764568851.861625)]"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Example ‚Äì Visualization Agent\nawait call_visualization_agent(\n    viz_request=\"Visualize merge sort on [4, 1, 3, 9, 7].\",\n)","metadata":{"_uuid":"d373da00-b262-40eb-bf39-5697fc4accd4","_cell_guid":"7860ace1-28b4-4d99-8f89-f3d715cc9f3c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:01:06.115701Z","iopub.execute_input":"2025-12-01T06:01:06.116003Z","iopub.status.idle":"2025-12-01T06:01:09.024193Z","shell.execute_reply.started":"2025-12-01T06:01:06.115980Z","shell.execute_reply":"2025-12-01T06:01:09.022851Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ Calling Visualization Agent...\n\n ### Created new session: debug_session_id\n\nUser > Visualize merge sort on [4, 1, 3, 9, 7].\n\nPlease:\n\nChoose the appropriate viz_type (sorting, graph_traversal, dp_table,\nrecursion_tree, heap_and_priority_queue, hash_table, search_tree_structure,\ncomplexity_growth, or np_completeness_and_reductions).\n\nUse a tiny synthetic example.\n\nProduce a step-by-step visualization in Markdown, with sections:\n\nOverview\n\nStep-by-step\n\nWhat this picture tells you\n\nvisualization_agent > ### Overview\n\nMerge sort is a classic divide-and-conquer sorting algorithm. It works by recursively dividing the input array into two halves, sorting each half independently, and then merging the two sorted halves back together. This process continues until the entire array is sorted.\n\n### Step-by-step\n\nWe will visualize merge sort on the array `[4, 1, 3, 9, 7]`.\n\n**Step 0: Initial Array**\nArray: `[4, 1, 3, 9, 7]`\nThe array is divided into two halves: `[4, 1]` and `[3, 9, 7]`.\n\n**Step 1: Recursively sort the left half `[4, 1]`**\n*   Divide `[4, 1]` into `[4]` and `[1]`.\n*   `[4]` is a single element, so it's considered sorted.\n*   `[1]` is a single element, so it's considered sorted.\n*   Merge `[4]` and `[1]`:\n    *   Compare 4 and 1. 1 is smaller.\n    *   Result: `[1, 4]`\n\n**Step 2: Recursively sort the right half `[3, 9, 7]`**\n*   Divide `[3, 9, 7]` into `[3]` and `[9, 7]`.\n*   `[3]` is a single element, so it's considered sorted.\n*   Recursively sort `[9, 7]`:\n    *   Divide `[9, 7]` into `[9]` and `[7]`.\n    *   `[9]` is sorted.\n    *   `[7]` is sorted.\n    *   Merge `[9]` and `[7]`:\n        *   Compare 9 and 7. 7 is smaller.\n        *   Result: `[7, 9]`\n*   Now merge the sorted `[3]` and `[7, 9]`:\n    *   Compare 3 and 7. 3 is smaller. Add 3 to the merged list. Remaining: `[7, 9]`.\n    *   Compare (nothing from first list) and 7. Add 7. Remaining: `[9]`.\n    *   Add 9.\n    *   Result: `[3, 7, 9]`\n\n**Step 3: Merge the two sorted halves `[1, 4]` and `[3, 7, 9]`**\n*   Initialize pointers for both arrays: `ptr1 = 0` (pointing to 1), `ptr2 = 0` (pointing to 3).\n*   Compare `arr1[0]` (1) and `arr2[0]` (3). 1 is smaller. Add 1 to the result. Increment `ptr1`. Result: `[1]`\n*   Compare `arr1[1]` (4) and `arr2[0]` (3). 3 is smaller. Add 3 to the result. Increment `ptr2`. Result: `[1, 3]`\n*   Compare `arr1[1]` (4) and `arr2[1]` (7). 4 is smaller. Add 4 to the result. Increment `ptr1`. Result: `[1, 3, 4]`\n*   `arr1` is exhausted. Add remaining elements from `arr2` (7, 9) to the result. Result: `[1, 3, 4, 7, 9]`\n\n**Step 4: Final Sorted Array**\nArray: `[1, 3, 4, 7, 9]`\n\n### What this picture tells you\n\nMerge sort systematically breaks down the problem into smaller, sortable pieces and then efficiently combines them. Each merge step ensures that the combined portion is sorted, leading to a fully sorted array at the end. The recursive nature allows for a structured approach to sorting, and the merging process is key to its efficiency.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       text=\"\"\"### Overview\n \n Merge sort is a classic divide-and-conquer sorting algorithm. It works by recursively dividing the input array into two halves, sorting each half independently, and then merging the two sorted halves back together. This process continues until the entire array is sorted.\n \n ### Step-by-step\n \n We will visualize merge sort on the array `[4, 1, 3, 9, 7]`.\n \n **Step 0: Initial Array**\n Array: `[4, 1, 3, 9, 7]`\n The array is divided into two halves: `[4, 1]` and `[3, 9, 7]`.\n \n **Step 1: Recursively sort the left half `[4, 1]`**\n *   Divide `[4, 1]` into `[4]` and `[1]`.\n *   `[4]` is a single element, so it's considered sorted.\n *   `[1]` is a single element, so it's considered sorted.\n *   Merge `[4]` and `[1]`:\n     *   Compare 4 and 1. 1 is smaller.\n     *   Result: `[1, 4]`\n \n **Step 2: Recursively sort the right half `[3, 9, 7]`**\n *   Divide `[3, 9, 7]` into `[3]` and `[9, 7]`.\n *   `[3]` is a single element, so it's considered sorted.\n *   Recursively sort `[9, 7]`:\n     *   Divide `[9, 7]` into `[9]` and `[7]`.\n     *   `[9]` is sorted.\n     *   `[7]` is sorted.\n     *   Merge `[9]` and `[7]`:\n         *   Compare 9 and 7. 7 is smaller.\n         *   Result: `[7, 9]`\n *   Now merge the sorted `[3]` and `[7, 9]`:\n     *   Compare 3 and 7. 3 is smaller. Add 3 to the merged list. Remaining: `[7, 9]`.\n     *   Compare (nothing from first list) and 7. Add 7. Remaining: `[9]`.\n     *   Add 9.\n     *   Result: `[3, 7, 9]`\n \n **Step 3: Merge the two sorted halves `[1, 4]` and `[3, 7, 9]`**\n *   Initialize pointers for both arrays: `ptr1 = 0` (pointing to 1), `ptr2 = 0` (pointing to 3).\n *   Compare `arr1[0]` (1) and `arr2[0]` (3). 1 is smaller. Add 1 to the result. Increment `ptr1`. Result: `[1]`\n *   Compare `arr1[1]` (4) and `arr2[0]` (3). 3 is smaller. Add 3 to the result. Increment `ptr2`. Result: `[1, 3]`\n *   Compare `arr1[1]` (4) and `arr2[1]` (7). 4 is smaller. Add 4 to the result. Increment `ptr1`. Result: `[1, 3, 4]`\n *   `arr1` is exhausted. Add remaining elements from `arr2` (7, 9) to the result. Result: `[1, 3, 4, 7, 9]`\n \n **Step 4: Final Sorted Array**\n Array: `[1, 3, 4, 7, 9]`\n \n ### What this picture tells you\n \n Merge sort systematically breaks down the problem into smaller, sortable pieces and then efficiently combines them. Each merge step ensures that the combined portion is sorted, leading to a fully sorted array at the end. The recursive nature allows for a structured approach to sorting, and the merging process is key to its efficiency.\"\"\"\n     ),\n   ],\n   role='model'\n ), grounding_metadata=GroundingMetadata(), partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=899,\n   prompt_token_count=2433,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=2433\n     ),\n   ],\n   total_token_count=3332\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-1e75f3fb-fdf7-4a08-9e6c-954ecbbe71cc', author='visualization_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='cbe7e8e9-9557-4e60-b6ec-47d48ad43615', timestamp=1764568866.120564)]"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# OPTIONAL: create ADK agent package \n!adk create algorithm-mentor-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"_uuid":"a0b79451-7bd8-4e48-b29d-3eb76c1e2311","_cell_guid":"c973d26f-bc7d-47c1-9c0d-e78516a0bbff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-01T06:17:18.603238Z","iopub.execute_input":"2025-12-01T06:17:18.603662Z"}},"outputs":[{"name":"stdout","text":"Non-empty folder already exist: '/kaggle/working/algorithm-mentor-agent'\nOverride existing content? [y/N]: ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# OPTIONAL: get ADK Web UI URL\nurl_prefix = get_adk_proxy_url()\nprint(\"URL prefix:\", url_prefix)","metadata":{"_uuid":"e0faf9d9-567e-460b-989a-74017dccd8a5","_cell_guid":"480375bd-f5a2-4f88-b2f7-76f31c4fb12e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OPTIONAL: run ADK Web UI server (keep this cell running)\n!adk web --url_prefix {url_prefix}","metadata":{"_uuid":"498c5009-c2cd-416e-a255-cdb00b52176c","_cell_guid":"d2b87e66-43c3-43f5-b090-38eb217f4cdf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 6. Helper: extract plain text from ADK runner responses ================\n\nimport json\nfrom typing import Any as _Any\n\ndef _extract_text(response: _Any) -> str:\n    \"\"\"\n    Best-effort extraction of plain text from an ADK runner response.\n\n    It tries, in order:\n    - response if it's already a string\n    - response.text\n    - response.output_text\n    - str(response)\n    \"\"\"\n    if isinstance(response, str):\n        return response\n\n    for attr in (\"text\", \"output_text\", \"output\", \"content\"):\n        if hasattr(response, attr):\n            try:\n                value = getattr(response, attr)\n                if isinstance(value, str):\n                    return value\n            except Exception:\n                pass\n\n    # Fallback: whatever __str__ gives\n    return str(response)\n\nprint(\"‚úÖ _extract_text(...) helper defined.\")","metadata":{"_uuid":"565f140d-d432-4999-a277-22841ac6c8d6","_cell_guid":"db30931b-28f2-4534-9032-8c0c10a93b8f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-01T06:02:39.755612Z","iopub.execute_input":"2025-12-01T06:02:39.756008Z","iopub.status.idle":"2025-12-01T06:02:39.764704Z","shell.execute_reply.started":"2025-12-01T06:02:39.755978Z","shell.execute_reply":"2025-12-01T06:02:39.763389Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"‚úÖ _extract_text(...) helper defined.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# === 7. Observability ‚Äì metrics store for basic logging =======================\n\nfrom dataclasses import asdict\n\nMETRICS = {\n    \"num_explainer_calls\": 0,\n    \"num_problem_gen_calls\": 0,\n    \"num_viz_calls\": 0,\n    \"num_diagnostic_turns\": 0,\n    \"num_judge_calls\": 0,\n    \"eval_runs\": 0,\n}\n\ndef print_metrics() -> None:\n    \"\"\"\n    Print current metrics in a compact, human-friendly way.\n    \"\"\"\n    print(\"\\nüìä Current Algorithm Mentor metrics:\")\n    for k, v in METRICS.items():\n        print(f\"  - {k}: {v}\")\n\nprint(\"‚úÖ METRICS dict and print_metrics() defined.\")","metadata":{"_uuid":"625fa18d-e428-443f-b1be-1755c3a8df50","_cell_guid":"834a965b-3d4f-45af-bb3d-2aee7f63c196","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-01T06:02:41.472414Z","iopub.execute_input":"2025-12-01T06:02:41.472752Z","iopub.status.idle":"2025-12-01T06:02:41.479643Z","shell.execute_reply.started":"2025-12-01T06:02:41.472728Z","shell.execute_reply":"2025-12-01T06:02:41.478500Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"‚úÖ METRICS dict and print_metrics() defined.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# === 8. Instrument existing helpers with metrics ============================\n\n# We assume:\n# - concept_explainer_runner, problem_runner, viz_runner, diagnostic_runner exist\n# - METRICS and _extract_text are defined\n\nasync def run_diagnostic_turn(user_message: str) -> _Any:\n    \"\"\"\n    Run a single turn of the Diagnostic + Personalization Agent.\n\n    Uses:\n    - global `session_state`\n    - global `diagnostic_runner`\n\n    Adds:\n    - metrics bump for num_diagnostic_turns\n    \"\"\"\n    if \"diagnostic_runner\" not in globals():\n        print(\"‚ùå diagnostic_runner not found. Make sure you defined it earlier.\")\n        return None\n    if \"session_state\" not in globals():\n        print(\"‚ùå session_state not found. Make sure you initialized it earlier.\")\n        return None\n\n    METRICS[\"num_diagnostic_turns\"] += 1\n\n    print(\"\\nüöÄ Running Diagnostic + Personalization turn...\")\n    prompt = build_diagnostic_prompt(user_message, session_state)\n    response = await diagnostic_runner.run_debug(prompt)\n    return response\n\n\nasync def call_concept_explainer(\n    topic: str,\n    level: str = \"standard\",\n    persona_hint: str = \"\",\n) -> _Any:\n    \"\"\"\n    Call the Concept Explainer Agent via its runner.\n\n    Adds:\n    - metrics bump for num_explainer_calls\n    \"\"\"\n    if \"concept_explainer_runner\" not in globals():\n        print(\"‚ùå concept_explainer_runner not found. Define it before calling this helper.\")\n        return None\n\n    METRICS[\"num_explainer_calls\"] += 1\n\n    user_prompt = (\n        \"You are Algorithm Mentor's Concept Explainer Agent.\\n\\n\"\n        \"Student persona hint:\\n\"\n        f\"{persona_hint}\\n\\n\"\n        \"Task:\\n\"\n        f'Explain the topic \"{topic}\" at a {level.upper()} level, following your\\n'\n        \"sequential pipeline (Overview, Intuition, Why it matters, Step-by-step trace,\\n\"\n        \"Pseudocode, Time & space complexity, Common pitfalls, Check your understanding).\\n\\n\"\n        \"Use Markdown sections.\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling Concept Explainer for topic: {topic}, level: {level}\")\n    response = await concept_explainer_runner.run_debug(user_prompt)\n    return response\n\n\nasync def call_problem_generator(\n    topic: str,\n    difficulty: str = \"easy\",\n    num_questions: int = 2,\n) -> _Any:\n    \"\"\"\n    Call the ProblemGen + Auto-Grader Agent to generate practice problems.\n\n    Adds:\n    - metrics bump for num_problem_gen_calls\n    \"\"\"\n    if \"problem_runner\" not in globals():\n        print(\"‚ùå problem_runner not found. Define it before calling this helper.\")\n        return None\n\n    METRICS[\"num_problem_gen_calls\"] += 1\n\n    user_prompt = (\n        \"You are the Problem Generator + Auto-Grader Agent for Algorithm Mentor.\\n\\n\"\n        \"Task:\\n\"\n        f\"Generate {num_questions} {difficulty} practice problems on \\\"{topic}\\\".\\n\\n\"\n        \"Requirements:\\n\"\n        \"- Use only synthetic problems (no copying real exams).\\n\"\n        \"- Make the questions clear and self-contained.\\n\"\n        \"- For each problem, provide:\\n\"\n        \"  - The question text.\\n\"\n        \"  - A brief internal answer/rubric.\\n\"\n        \"You may respond in structured, well-formatted natural language (no need for JSON here).\\n\"\n    )\n\n    print(f\"\\nüöÄ Calling ProblemGen + Auto-Grader for topic: {topic}, difficulty: {difficulty}\")\n    response = await problem_runner.run_debug(user_prompt)\n    return response\n\n\nasync def call_visualization_agent(\n    viz_request: str,\n) -> _Any:\n    \"\"\"\n    Call the Visualization Agent via its runner.\n\n    Adds:\n    - metrics bump for num_viz_calls\n    \"\"\"\n    if \"viz_runner\" not in globals():\n        print(\"‚ùå viz_runner not found. Define it before calling this helper.\")\n        return None\n\n    METRICS[\"num_viz_calls\"] += 1\n\n    user_prompt = (\n        f\"{viz_request}\\n\\n\"\n        \"Please:\\n\\n\"\n        \"Choose the appropriate viz_type (sorting, graph_traversal, dp_table,\\n\"\n        \"recursion_tree, heap_and_priority_queue, hash_table, search_tree_structure,\\n\"\n        \"complexity_growth, or np_completeness_and_reductions).\\n\\n\"\n        \"Use a tiny synthetic example.\\n\\n\"\n        \"Produce a step-by-step visualization in Markdown, with sections:\\n\\n\"\n        \"Overview\\n\\n\"\n        \"Step-by-step\\n\\n\"\n        \"What this picture tells you\\n\"\n    )\n\n    print(\"\\nüöÄ Calling Visualization Agent...\")\n    response = await viz_runner.run_debug(user_prompt)\n    return response\n\n\nprint(\"‚úÖ Existing helpers wrapped with basic metrics.\")","metadata":{"_uuid":"f3191270-7695-4712-9d6b-49bc9ed67dd6","_cell_guid":"79967474-c4b8-4235-b0c8-a9886a262430","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-01T06:02:45.835618Z","iopub.execute_input":"2025-12-01T06:02:45.835954Z","iopub.status.idle":"2025-12-01T06:02:45.852841Z","shell.execute_reply.started":"2025-12-01T06:02:45.835928Z","shell.execute_reply":"2025-12-01T06:02:45.850953Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"‚úÖ Existing helpers wrapped with basic metrics.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"\nimport re\n\ndef _strip_markdown_fences(text: str) -> str:\n    \"\"\"\n    Remove leading ```json / ``` and trailing ``` from a string, if present.\n    \"\"\"\n    if not isinstance(text, str):\n        text = str(text)\n    text = text.strip()\n\n    # Remove an opening ```json or ``` line\n    text = re.sub(r\"^```[a-zA-Z0-9_+-]*\\s*\\n\", \"\", text)\n\n    # Remove a trailing ``` line\n    text = re.sub(r\"\\n```$\", \"\", text)\n\n    return text.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:11:20.118154Z","iopub.execute_input":"2025-12-01T06:11:20.118528Z","iopub.status.idle":"2025-12-01T06:11:20.124901Z","shell.execute_reply.started":"2025-12-01T06:11:20.118503Z","shell.execute_reply":"2025-12-01T06:11:20.123510Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# === 9. Evaluation ‚Äì Judge Agent + tiny eval suite ===========================\nfrom typing import List\n\n# Small eval set ‚Äì you can add more later\nEVAL_TESTS: List[EvalTestCase] = [\n    EvalTestCase(\n        id=\"explainer_dijkstra\",\n        agent=\"concept_explainer_agent\",\n        description=\"Checks Dijkstra explanation structure and clarity.\",\n        prompt=(\n            \"Explain Dijkstra's algorithm for single-source shortest paths on a graph \"\n            \"with non-negative edge weights. Follow your standard Algorithm Mentor \"\n            \"section structure.\"\n        ),\n        expected_properties=[\n            \"Has sections: Overview, Intuition, Why it matters, Step-by-step trace, \"\n            \"Pseudocode, Time & space complexity, Common pitfalls, Check your understanding.\",\n            \"Uses a small synthetic example graph.\",\n            \"Avoids copying any textbook wording.\",\n        ],\n    ),\n    EvalTestCase(\n        id=\"problemgen_binary_search_easy\",\n        agent=\"problem_gen_autograder_agent\",\n        description=\"Generate easy binary search practice problems.\",\n        prompt=(\n            \"Generate 2 **easy** practice problems on binary search, including \"\n            \"the question text and a short answer or rubric for each.\"\n        ),\n        expected_properties=[\n            \"Questions are clearly about binary search.\",\n            \"Problems are easy-level and self-contained.\",\n            \"Includes at least a short solution or rubric per question.\",\n        ],\n    ),\n]\n\n\nasync def run_eval_suite() -> EvalSummary:\n    \"\"\"\n    Run the small evaluation suite using the Judge Agent.\n\n    - Calls the target agent to get output (via runner.run_debug()).\n    - Sends (requirements + agent output) to Judge Agent (via judge_runner.run_debug()).\n    - Parses JSON from Judge and builds an EvalSummary.\n    - Updates METRICS and prints a short report.\n    \"\"\"\n    if \"judge_runner\" not in globals():\n        print(\"‚ùå judge_runner not found. Make sure you defined the Judge agent earlier.\")\n        return EvalSummary()\n\n    results: List[EvalResult] = []\n\n    print(\"\\nüß™ Running evaluation suite...\")\n    for test in EVAL_TESTS:\n        print(f\"\\n--- Test: {test.id} ({test.agent}) ---\")\n\n        # 1) Choose the correct runner for the target agent\n        if test.agent == \"concept_explainer_agent\":\n            target_runner = concept_explainer_runner\n        elif test.agent == \"problem_gen_autograder_agent\":\n            target_runner = problem_runner\n        else:\n            print(f\"‚ö†Ô∏è Unknown agent in eval test: {test.agent}, skipping.\")\n            continue\n\n        # 2) Call the target agent via run_debug(prompt)\n        agent_resp = await target_runner.run_debug(test.prompt)\n        agent_text = _extract_text(agent_resp)\n\n        # 3) Build judge prompt\n        judge_prompt = (\n            \"You are the Judge Agent for Algorithm Mentor.\\n\\n\"\n            f\"Test case description:\\n{test.description}\\n\\n\"\n            \"Expected properties:\\n\"\n            + \"\\n\".join(f\"- {prop}\" for prop in test.expected_properties)\n            + \"\\n\\n\"\n            \"Here is the agent output you must evaluate:\\n\\n\"\n            f\"--- BEGIN AGENT OUTPUT ---\\n{agent_text}\\n--- END AGENT OUTPUT ---\\n\\n\"\n            \"Now respond ONLY with a single JSON object:\\n\"\n            \"{\\n\"\n            '  \\\"score\\\": float,              // 0.0 to 1.0\\n'\n            '  \\\"passed\\\": bool,              // true if score >= 0.7\\n'\n            '  \\\"notes\\\": \\\"string\\\"          // short explanation\\n'\n            \"}\\n\"\n        )\n\n        # 4) Call Judge Agent via run_debug(prompt)\n        METRICS[\"num_judge_calls\"] += 1\n        judge_resp = await judge_runner.run_debug(judge_prompt)\n\n        # Extract raw text from Event(s)\n        judge_text_raw = _extract_text(judge_resp)\n\n        # üîß NEW: strip ```json fences if present\n        judge_text = _strip_markdown_fences(judge_text_raw)\n\n        # 5) Parse JSON and build EvalResult\n        try:\n            judge_json = json.loads(judge_text)\n        except Exception as e:\n            print(\"‚ùå Failed to parse judge JSON:\", e)\n            print(\"Raw judge response text:\")\n            print(judge_text_raw)   # show original for debugging\n            print(\"Cleaned text we tried to parse:\")\n            print(judge_text)\n            continue\n\n        score = float(judge_json.get(\"score\", 0.0))\n        passed = bool(judge_json.get(\"passed\", False))\n        notes = str(judge_json.get(\"notes\", \"\"))\n\n        result = EvalResult(\n            test_id=test.id,\n            agent=test.agent,\n            score=score,\n            passed=passed,\n            judge_notes=notes,\n        )\n        results.append(result)\n\n        status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n        print(f\"{status} ‚Äì score={score:.2f}\")\n        print(\"Notes:\", notes)\n\n    summary = EvalSummary(results=results)\n    METRICS[\"eval_runs\"] += 1\n\n    print(\"\\nüìã EVAL SUMMARY\")\n    print(f\"- Tests run: {summary.num_total}\")\n    print(f\"- Passed:    {summary.num_passed}\")\n    print(f\"- Avg score: {summary.average_score:.2f}\")\n\n    return summary\n\n\n\nprint(\"‚úÖ Evaluation suite (EVAL_TESTS, run_eval_suite) defined with run_debug().\")","metadata":{"_uuid":"9d95295b-2e04-4dc2-9308-20baf2f418cf","_cell_guid":"a1c6b8e9-16e7-4ece-8756-314ad73e3168","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-01T06:12:28.666199Z","iopub.execute_input":"2025-12-01T06:12:28.666558Z","iopub.status.idle":"2025-12-01T06:12:28.684244Z","shell.execute_reply.started":"2025-12-01T06:12:28.666535Z","shell.execute_reply":"2025-12-01T06:12:28.682813Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"‚úÖ Evaluation suite (EVAL_TESTS, run_eval_suite) defined with run_debug().\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# === 10. Sanity Check ‚Äì run eval suite + print metrics =======================\neval_summary = await run_eval_suite()\nprint_metrics()","metadata":{"_uuid":"81a2075f-58dd-420d-8341-38f0c6b91b46","_cell_guid":"c8cfb697-ba80-4900-9e6d-2c03936cf6ae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-01T06:12:38.966533Z","iopub.execute_input":"2025-12-01T06:12:38.966880Z","iopub.status.idle":"2025-12-01T06:13:00.246357Z","shell.execute_reply.started":"2025-12-01T06:12:38.966854Z","shell.execute_reply":"2025-12-01T06:13:00.245407Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nüß™ Running evaluation suite...\n\n--- Test: explainer_dijkstra (concept_explainer_agent) ---\n\n ### Continue session: debug_session_id\n\nUser > Explain Dijkstra's algorithm for single-source shortest paths on a graph with non-negative edge weights. Follow your standard Algorithm Mentor section structure.\nconcept_explainer_agent > ### Overview\n\nDijkstra's algorithm is a fundamental graph algorithm used to find the shortest path from a single source vertex to all other vertices in a weighted graph. It is guaranteed to work correctly only for graphs with non-negative edge weights. The core idea is to greedily explore the graph, always extending the path from the vertex that is currently closest to the source.\n\n### Intuition\n\nImagine you're trying to find the fastest way to get from your home to every store in a small town. Each road has a travel time, and all these travel times are positive (no negative travel times!).\n\nDijkstra's algorithm acts like a very organized planner.\n1.  It starts at your home (the source). It knows the time to get home is 0. For all other stores, it initially assumes it will take an infinitely long time to get there.\n2.  It keeps a list of all stores and the *shortest time found so far* to reach them from home.\n3.  In each step, it looks at all the stores it hasn't \"finished\" planning for yet. It picks the one that has the *smallest* \"shortest time found so far.\"\n4.  Once it picks a store, it says, \"Okay, I've figured out the absolute fastest way to get to *this* store.\" It marks this store as \"done.\"\n5.  Now, from this \"done\" store, it looks at all the roads leading to other stores it hasn't planned for yet. If going through the current \"done\" store offers a *faster* way to reach one of those other stores than the planner had previously thought, it updates the \"shortest time found so far\" for that other store.\n6.  It repeats steps 3-5 until all stores have been marked as \"done.\"\n\n### Why it matters\n\nDijkstra's algorithm is a building block for many real-world applications that involve finding optimal paths:\n\n*   **Navigation Apps:** GPS systems (like Google Maps, Waze) use it to find the quickest routes by treating roads as edges and travel times as weights.\n*   **Network Routing:** In computer networks, it helps determine the most efficient path for data to travel from one point to another, minimizing delays.\n*   **Logistics and Transportation:** Planning delivery routes or airline flight paths.\n*   **Robotics:** Path planning for robots navigating environments.\n\n### Step-by-step trace (on a small example)\n\nLet's find the shortest paths from node `A` to all other nodes in this graph:\n\nNodes: `A`, `B`, `C`, `D`\nEdges (with weights):\n`A -> B` (weight 1)\n`A -> C` (weight 4)\n`B -> C` (weight 2)\n`B -> D` (weight 5)\n`C -> D` (weight 1)\n\nWe'll use:\n*   `dist`: Array to store the shortest distance found so far from `A`. `dist[A]=0`, others initialized to infinity (`INF`).\n*   `visited`: Boolean array to mark if a node's shortest distance has been finalized.\n*   `pq`: A min-priority queue storing `(distance, node_index)`.\n\n**Initialization:**\n`dist = [0, INF, INF, INF]` (for A, B, C, D respectively)\n`visited = [false, false, false, false]`\n`pq = {(0, A)}`\n\n**Iteration 1:**\n1.  Extract `(0, A)` from `pq`.\n2.  Mark `A` as visited. `visited = [true, false, false, false]`.\n3.  Relax neighbors of `A`:\n    *   For `B`: `dist[A] + weight(A, B) = 0 + 1 = 1`. Since `1 < dist[B]` (INF), `dist[B] = 1`. Add `(1, B)` to `pq`.\n    *   For `C`: `dist[A] + weight(A, C) = 0 + 4 = 4`. Since `4 < dist[C]` (INF), `dist[C] = 4`. Add `(4, C)` to `pq`.\n`dist = [0, 1, 4, INF]`\n`pq = {(1, B), (4, C)}`\n\n**Iteration 2:**\n1.  Extract `(1, B)` from `pq`.\n2.  Mark `B` as visited. `visited = [true, true, false, false]`.\n3.  Relax neighbors of `B`:\n    *   For `C`: `dist[B] + weight(B, C) = 1 + 2 = 3`. Since `3 < dist[C]` (4), `dist[C] = 3`. Add `(3, C)` to `pq`.\n    *   For `D`: `dist[B] + weight(B, D) = 1 + 5 = 6`. Since `6 < dist[D]` (INF), `dist[D] = 6`. Add `(6, D)` to `pq`.\n`dist = [0, 1, 3, 6]`\n`pq = {(3, C), (4, C), (6, D)}` (Note: `(4, C)` is still in PQ but won't be chosen as final)\n\n**Iteration 3:**\n1.  Extract `(3, C)` from `pq`.\n2.  Mark `C` as visited. `visited = [true, true, true, false]`.\n3.  Relax neighbors of `C`:\n    *   For `D`: `dist[C] + weight(C, D) = 3 + 1 = 4`. Since `4 < dist[D]` (6), `dist[D] = 4`. Add `(4, D)` to `pq`.\n`dist = [0, 1, 3, 4]`\n`pq = {(4, C), (6, D), (4, D)}`\n\n**Iteration 4:**\n1.  Extract `(4, C)` from `pq`. Node `C` is already visited. Skip.\n`pq = {(6, D), (4, D)}`\n\n**Iteration 5:**\n1.  Extract `(4, D)` from `pq`.\n2.  Mark `D` as visited. `visited = [true, true, true, true]`.\n3.  Node `D` has no outgoing edges to unvisited nodes.\n`dist = [0, 1, 3, 4]`\n`pq = {(6, D)}`\n\n**Iteration 6:**\n1.  Extract `(6, D)` from `pq`. Node `D` is already visited. Skip.\n`pq = {}`\n\nAlgorithm terminates. Shortest distances from `A`: `A:0, B:1, C:3, D:4`.\n\n### Pseudocode\n\n```cpp\n// Structure to represent an edge in the graph\nstruct Edge {\n    int to;       // Destination vertex\n    int weight;   // Weight of the edge\n};\n\n// Adjacency list representation of the graph\n// `adj[u]` stores a vector of `Edge` objects representing edges from vertex `u`\nvector<vector<Edge>> adj;\n\n// Function to find shortest paths from a single source vertex\n// `num_vertices`: total number of vertices in the graph\n// `source`: the starting vertex (0-indexed)\nvector<int> dijkstra(int num_vertices, int source) {\n    // Initialize distance vector. `INF` represents infinity.\n    const int INF = numeric_limits<int>::max();\n    vector<int> dist(num_vertices, INF);\n    dist[source] = 0; // Distance from source to itself is 0\n\n    // Min-priority queue storing pairs of {distance, vertex_index}.\n    // `greater` is used to make it a min-priority queue.\n    priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq;\n    pq.push({0, source}); // Start with the source vertex\n\n    while (!pq.empty()) {\n        // Extract the vertex with the smallest tentative distance\n        int current_dist = pq.top().first;\n        int u = pq.top().second;\n        pq.pop();\n\n        // If the extracted distance is greater than the current shortest distance recorded for `u`,\n        // it means we found a shorter path to `u` earlier, so we skip this outdated entry.\n        if (current_dist > dist[u]) {\n            continue;\n        }\n\n        // Iterate through all neighbors `v` of the current vertex `u`\n        for (const auto& edge : adj[u]) {\n            int v = edge.to;\n            int edge_weight = edge.weight;\n\n            // Relaxation step: If a shorter path to `v` is found through `u`\n            // Check `dist[u] != INF` to avoid overflow if `dist[u]` is infinity\n            if (dist[u] != INF && dist[u] + edge_weight < dist[v]) {\n                dist[v] = dist[u] + edge_weight; // Update distance to `v`\n                pq.push({dist[v], v});         // Add/update `v` in the priority queue\n            }\n        }\n    }\n\n    return dist; // Return the vector containing shortest distances from the source\n}\n```\n\n### Time & space complexity\n\n*   **Time Complexity:**\n    *   Using a binary heap (standard `priority_queue`): $O((V + E) \\log V)$, often simplified to $O(E \\log V)$ for connected graphs where $E \\ge V$. This comes from $V$ `pop` operations and at most $E$ `push` operations on the priority queue, each taking $O(\\log V)$ time.\n    *   Using a Fibonacci heap: $O(E + V \\log V)$. This offers better theoretical performance for dense graphs but is often more complex to implement and may have higher constant factors in practice.\n\n*   **Space Complexity:** $O(V + E)$ for storing the graph (adjacency list) and $O(V)$ for the distance array and the priority queue.\n\n### Common pitfalls\n\n*   **Negative Edge Weights:** Dijkstra's algorithm *must not* be used on graphs with negative edge weights. Its greedy approach assumes that once a node's shortest path is finalized, it cannot be improved. A negative edge can create a shorter path to an already \"finalized\" node, breaking the algorithm's logic. For such graphs, use the Bellman-Ford algorithm.\n*   **Incorrect Priority Queue Handling:** If a max-priority queue is used instead of a min-priority queue, or if entries are not updated correctly (leading to the algorithm processing longer paths first), it will yield incorrect results or be very inefficient. The check `if (current_dist > dist[u]) continue;` is crucial to handle duplicate entries correctly and efficiently.\n*   **Graph Representation Choice:** For sparse graphs (few edges compared to vertices), an adjacency list is efficient ($O(E+V)$ to build). For dense graphs (many edges), an adjacency matrix might be considered, but Dijkstra's performance degrades significantly to $O(V^2)$ with an adjacency matrix because checking neighbors for a vertex takes $O(V)$ time.\n*   **Initialization Errors:** Forgetting to set `dist[source] = 0` or using a value for infinity that is too small (leading to overflow or incorrect comparisons) can cause the algorithm to fail.\n\n### Check your understanding\n\n1.  Suppose Dijkstra's algorithm is run on a graph with a single negative edge. What kind of error might occur?\n2.  What is the purpose of the `visited` array (or the `if (current_dist > dist[u]) continue;` check) in Dijkstra's algorithm?\n3.  If you have a graph with 50 vertices and 100 edges, and all weights are positive, what is the approximate time complexity of Dijkstra's algorithm using a binary heap?\n\n ### Continue session: debug_session_id\n\nUser > You are the Judge Agent for Algorithm Mentor.\n\nTest case description:\nChecks Dijkstra explanation structure and clarity.\n\nExpected properties:\n- Has sections: Overview, Intuition, Why it matters, Step-by-step trace, Pseudocode, Time & space complexity, Common pitfalls, Check your understanding.\n- Uses a small synthetic example graph.\n- Avoids copying any textbook wording.\n\nHere is the agent output you must evaluate:\n\n--- BEGIN AGENT OUTPUT ---\n### Overview\n\nDijkstra's algorithm is a fundamental graph algorithm used to find the shortest path from a single source vertex to all other vertices in a weighted graph. It is guaranteed to work correctly only for graphs with non-negative edge weights. The core idea is to greedily explore the graph, always extending the path from the vertex that is currently closest to the source.\n\n### Intuition\n\nImagine you're trying to find the fastest way to get from your home to every store in a small town. Each road has a travel time, and all these travel times are positive (no negative travel times!).\n\nDijkstra's algorithm acts like a very organized planner.\n1.  It starts at your home (the source). It knows the time to get home is 0. For all other stores, it initially assumes it will take an infinitely long time to get there.\n2.  It keeps a list of all stores and the *shortest time found so far* to reach them from home.\n3.  In each step, it looks at all the stores it hasn't \"finished\" planning for yet. It picks the one that has the *smallest* \"shortest time found so far.\"\n4.  Once it picks a store, it says, \"Okay, I've figured out the absolute fastest way to get to *this* store.\" It marks this store as \"done.\"\n5.  Now, from this \"done\" store, it looks at all the roads leading to other stores it hasn't planned for yet. If going through the current \"done\" store offers a *faster* way to reach one of those other stores than the planner had previously thought, it updates the \"shortest time found so far\" for that other store.\n6.  It repeats steps 3-5 until all stores have been marked as \"done.\"\n\n### Why it matters\n\nDijkstra's algorithm is a building block for many real-world applications that involve finding optimal paths:\n\n*   **Navigation Apps:** GPS systems (like Google Maps, Waze) use it to find the quickest routes by treating roads as edges and travel times as weights.\n*   **Network Routing:** In computer networks, it helps determine the most efficient path for data to travel from one point to another, minimizing delays.\n*   **Logistics and Transportation:** Planning delivery routes or airline flight paths.\n*   **Robotics:** Path planning for robots navigating environments.\n\n### Step-by-step trace (on a small example)\n\nLet's find the shortest paths from node `A` to all other nodes in this graph:\n\nNodes: `A`, `B`, `C`, `D`\nEdges (with weights):\n`A -> B` (weight 1)\n`A -> C` (weight 4)\n`B -> C` (weight 2)\n`B -> D` (weight 5)\n`C -> D` (weight 1)\n\nWe'll use:\n*   `dist`: Array to store the shortest distance found so far from `A`. `dist[A]=0`, others initialized to infinity (`INF`).\n*   `visited`: Boolean array to mark if a node's shortest distance has been finalized.\n*   `pq`: A min-priority queue storing `(distance, node_index)`.\n\n**Initialization:**\n`dist = [0, INF, INF, INF]` (for A, B, C, D respectively)\n`visited = [false, false, false, false]`\n`pq = {(0, A)}`\n\n**Iteration 1:**\n1.  Extract `(0, A)` from `pq`.\n2.  Mark `A` as visited. `visited = [true, false, false, false]`.\n3.  Relax neighbors of `A`:\n    *   For `B`: `dist[A] + weight(A, B) = 0 + 1 = 1`. Since `1 < dist[B]` (INF), `dist[B] = 1`. Add `(1, B)` to `pq`.\n    *   For `C`: `dist[A] + weight(A, C) = 0 + 4 = 4`. Since `4 < dist[C]` (INF), `dist[C] = 4`. Add `(4, C)` to `pq`.\n`dist = [0, 1, 4, INF]`\n`pq = {(1, B), (4, C)}`\n\n**Iteration 2:**\n1.  Extract `(1, B)` from `pq`.\n2.  Mark `B` as visited. `visited = [true, true, false, false]`.\n3.  Relax neighbors of `B`:\n    *   For `C`: `dist[B] + weight(B, C) = 1 + 2 = 3`. Since `3 < dist[C]` (4), `dist[C] = 3`. Add `(3, C)` to `pq`.\n    *   For `D`: `dist[B] + weight(B, D) = 1 + 5 = 6`. Since `6 < dist[D]` (INF), `dist[D] = 6`. Add `(6, D)` to `pq`.\n`dist = [0, 1, 3, 6]`\n`pq = {(3, C), (4, C), (6, D)}` (Note: `(4, C)` is still in PQ but won't be chosen as final)\n\n**Iteration 3:**\n1.  Extract `(3, C)` from `pq`.\n2.  Mark `C` as visited. `visited = [true, true, true, false]`.\n3.  Relax neighbors of `C`:\n    *   For `D`: `dist[C] + weight(C, D) = 3 + 1 = 4`. Since `4 < dist[D]` (6), `dist[D] = 4`. Add `(4, D)` to `pq`.\n`dist = [0, 1, 3, 4]`\n`pq = {(4, C), (6, D), (4, D)}`\n\n**Iteration 4:**\n1.  Extract `(4, C)` from `pq`. Node `C` is already visited. Skip.\n`pq = {(6, D), (4, D)}`\n\n**Iteration 5:**\n1.  Extract `(4, D)` from `pq`.\n2.  Mark `D` as visited. `visited = [true, true, true, true]`.\n3.  Node `D` has no outgoing edges to unvisited nodes.\n`dist = [0, 1, 3, 4]`\n`pq = {(6, D)}`\n\n**Iteration 6:**\n1.  Extract `(6, D)` from `pq`. Node `D` is already visited. Skip.\n`pq = {}`\n\nAlgorithm terminates. Shortest distances from `A`: `A:0, B:1, C:3, D:4`.\n\n### Pseudocode\n\n\n```cpp\n// Structure to represent an edge in the graph\nstruct Edge {\n    int to;       // Destination vertex\n    int weight;   // Weight of the edge\n};\n\n// Adjacency list representation of the graph\n// `adj[u]` stores a vector of `Edge` objects representing edges from vertex `u`\nvector<vector<Edge>> adj;\n\n// Function to find shortest paths from a single source vertex\n// `num_vertices`: total number of vertices in the graph\n// `source`: the starting vertex (0-indexed)\nvector<int> dijkstra(int num_vertices, int source) {\n    // Initialize distance vector. `INF` represents infinity.\n    const int INF = numeric_limits<int>::max();\n    vector<int> dist(num_vertices, INF);\n    dist[source] = 0; // Distance from source to itself is 0\n\n    // Min-priority queue storing pairs of {distance, vertex_index}.\n    // `greater` is used to make it a min-priority queue.\n    priority_queue<pair<int, int>, vector<pair<int, int>>, greater<pair<int, int>>> pq;\n    pq.push({0, source}); // Start with the source vertex\n\n    while (!pq.empty()) {\n        // Extract the vertex with the smallest tentative distance\n        int current_dist = pq.top().first;\n        int u = pq.top().second;\n        pq.pop();\n\n        // If the extracted distance is greater than the current shortest distance recorded for `u`,\n        // it means we found a shorter path to `u` earlier, so we skip this outdated entry.\n        if (current_dist > dist[u]) {\n            continue;\n        }\n\n        // Iterate through all neighbors `v` of the current vertex `u`\n        for (const auto& edge : adj[u]) {\n            int v = edge.to;\n            int edge_weight = edge.weight;\n\n            // Relaxation step: If a shorter path to `v` is found through `u`\n            // Check `dist[u] != INF` to avoid overflow if `dist[u]` is infinity\n            if (dist[u] != INF && dist[u] + edge_weight < dist[v]) {\n                dist[v] = dist[u] + edge_weight; // Update distance to `v`\n                pq.push({dist[v], v});         // Add/update `v` in the priority queue\n            }\n        }\n    }\n\n    return dist; // Return the vector containing shortest distances from the source\n}\n```\n\n\n### Time & space complexity\n\n*   **Time Complexity:**\n    *   Using a binary heap (standard `priority_queue`): $O((V + E) \\log V)$, often simplified to $O(E \\log V)$ for connected graphs where $E \\ge V$. This comes from $V$ `pop` operations and at most $E$ `push` operations on the priority queue, each taking $O(\\log V)$ time.\n    *   Using a Fibonacci heap: $O(E + V \\log V)$. This offers better theoretical performance for dense graphs but is often more complex to implement and may have higher constant factors in practice.\n\n*   **Space Complexity:** $O(V + E)$ for storing the graph (adjacency list) and $O(V)$ for the distance array and the priority queue.\n\n### Common pitfalls\n\n*   **Negative Edge Weights:** Dijkstra's algorithm *must not* be used on graphs with negative edge weights. Its greedy approach assumes that once a node's shortest path is finalized, it cannot be improved. A negative edge can create a shorter path to an already \"finalized\" node, breaking the algorithm's logic. For such graphs, use the Bellman-Ford algorithm.\n*   **Incorrect Priority Queue Handling:** If a max-priority queue is used instead of a min-priority queue, or if entries are not updated correctly (leading to the algorithm processing longer paths first), it will yield incorrect results or be very inefficient. The check `if (current_dist > dist[u]) continue;` is crucial to handle duplicate entries correctly and efficiently.\n*   **Graph Representation Choice:** For sparse graphs (few edges compared to vertices), an adjacency list is efficient ($O(E+V)$ to build). For dense graphs (many edges), an adjacency matrix might be considered, but Dijkstra's performance degrades significantly to $O(V^2)$ with an adjacency matrix because checking neighbors for a vertex takes $O(V)$ time.\n*   **Initialization Errors:** Forgetting to set `dist[source] = 0` or using a value for infinity that is too small (leading to overflow or incorrect comparisons) can cause the algorithm to fail.\n\n### Check your understanding\n\n1.  Suppose Dijkstra's algorithm is run on a graph with a single negative edge. What kind of error might occur?\n2.  What is the purpose of the `visited` array (or the `if (current_dist > dist[u]) continue;` check) in Dijkstra's algorithm?\n3.  If you have a graph with 50 vertices and 100 edges, and all weights are positive, what is the approximate time complexity of Dijkstra's algorithm using a binary heap?\n--- END AGENT OUTPUT ---\n\nNow respond ONLY with a single JSON object:\n{\n  \"score\": float,              // 0.0 to 1.0\n  \"passed\": bool,              // true if score >= 0.7\n  \"notes\": \"string\"          // short explanation\n}\n\njudge_agent > ```json\n{\n  \"score\": 1.0,\n  \"passed\": true,\n  \"notes\": \"The output includes all requested sections with clear and well-structured content. It uses a small synthetic graph example and the explanations appear original. The step-by-step trace is detailed and easy to follow.\"\n}\n```\n‚úÖ PASS ‚Äì score=1.00\nNotes: The output includes all requested sections with clear and well-structured content. It uses a small synthetic graph example and the explanations appear original. The step-by-step trace is detailed and easy to follow.\n\n--- Test: problemgen_binary_search_easy (problem_gen_autograder_agent) ---\n\n ### Continue session: debug_session_id\n\nUser > Generate 2 **easy** practice problems on binary search, including the question text and a short answer or rubric for each.\nproblem_gen_autograder_agent > Here are 2 easy practice problems on binary search, including the question text and a short answer or rubric for each:\n\n### Problem 1\n\n**Topic:** Binary Search\n**Difficulty:** Easy\n**Question Type:** open_ended\n\n**Prompt:**\nYou have a sorted list of unique timestamps from an event log: `[1678886400, 1678886460, 1678886520, 1678886580, 1678886640, 1678886700]`. You need to find if a specific timestamp, `1678886520`, exists in this list using binary search. Describe the first three steps of the binary search process, including the calculation of `mid` and the comparison made at each step. What is the outcome of the search after these steps?\n\n**Internal Answer/Rubric:**\nA good answer should describe the following steps:\n1.  **Initialization:** `low = 0`, `high = 5`.\n2.  **Iteration 1:**\n    *   `mid = floor((0 + 5) / 2) = 2`.\n    *   Compare `list[2]` (`1678886520`) with the target `1678886520`.\n3.  **Outcome:** Since `list[2]` is equal to the target, the timestamp is found at index `2`. The search terminates after the first comparison. The first three steps described would cover initialization and the first comparison, correctly identifying the element.\n\n---\n\n### Problem 2\n\n**Topic:** Binary Search\n**Difficulty:** Easy\n**Question Type:** mcq\n\n**Prompt:**\nConsider a sorted array `A = [5, 10, 15, 20, 25, 30, 35]`. You are searching for the value `20` using binary search. What is the value of `mid` calculated in the **second** iteration of the binary search?\n\n**Choices:**\nA) 15\nB) 20\nC) 25\nD) 30\n\n**Correct Answer:**\n*   **Type:** mcq\n*   **Correct Index:** 1 (Option B)\n*   **Explanation:**\n    1.  **Initialization:** `low = 0`, `high = 6`.\n    2.  **First Iteration:** `mid = floor((0 + 6) / 2) = 3`. `A[3]` is `20`. Since `A[3]` equals the target `20`, the element is found. The search would typically terminate here. However, if the question implies continuing the process even after finding the element (or if the target was slightly different, requiring more steps), let's consider a target that *doesn't* end on the first step to properly illustrate a second iteration's mid-value calculation.\n\n    *Let's re-evaluate with a target that requires more steps to better illustrate the second iteration.*\n\n    **Revised Scenario for Problem 2:**\n    Consider a sorted array `A = [5, 10, 15, 20, 25, 30, 35]`. You are searching for the value `30` using binary search. What is the value of `mid` calculated in the **second** iteration of the binary search?\n\n    **Choices:**\n    A) 15\n    B) 20\n    C) 25\n    D) 30\n\n    **Correct Answer (Revised):**\n    *   **Type:** mcq\n    *   **Correct Index:** 2 (Option C)\n    *   **Explanation:**\n        1.  **Initialization:** `low = 0`, `high = 6`.\n        2.  **First Iteration:** `mid = floor((0 + 6) / 2) = 3`. `A[3]` is `20`. Since `20 < 30`, we update `low = mid + 1 = 4`.\n        3.  **Second Iteration:** `low = 4`, `high = 6`. `mid = floor((4 + 6) / 2) = 5`. `A[5]` is `30`. The target is found.\n        The value of `mid` calculated in the second iteration is `5`. The corresponding element is `A[5] = 30`.\n\n*(Self-correction: The original prompt's target `20` was found in the first iteration. The revised target `30` correctly demonstrates a second iteration's `mid` calculation.)*\n\n ### Continue session: debug_session_id\n\nUser > You are the Judge Agent for Algorithm Mentor.\n\nTest case description:\nGenerate easy binary search practice problems.\n\nExpected properties:\n- Questions are clearly about binary search.\n- Problems are easy-level and self-contained.\n- Includes at least a short solution or rubric per question.\n\nHere is the agent output you must evaluate:\n\n--- BEGIN AGENT OUTPUT ---\nHere are 2 easy practice problems on binary search, including the question text and a short answer or rubric for each:\n\n### Problem 1\n\n**Topic:** Binary Search\n**Difficulty:** Easy\n**Question Type:** open_ended\n\n**Prompt:**\nYou have a sorted list of unique timestamps from an event log: `[1678886400, 1678886460, 1678886520, 1678886580, 1678886640, 1678886700]`. You need to find if a specific timestamp, `1678886520`, exists in this list using binary search. Describe the first three steps of the binary search process, including the calculation of `mid` and the comparison made at each step. What is the outcome of the search after these steps?\n\n**Internal Answer/Rubric:**\nA good answer should describe the following steps:\n1.  **Initialization:** `low = 0`, `high = 5`.\n2.  **Iteration 1:**\n    *   `mid = floor((0 + 5) / 2) = 2`.\n    *   Compare `list[2]` (`1678886520`) with the target `1678886520`.\n3.  **Outcome:** Since `list[2]` is equal to the target, the timestamp is found at index `2`. The search terminates after the first comparison. The first three steps described would cover initialization and the first comparison, correctly identifying the element.\n\n---\n\n### Problem 2\n\n**Topic:** Binary Search\n**Difficulty:** Easy\n**Question Type:** mcq\n\n**Prompt:**\nConsider a sorted array `A = [5, 10, 15, 20, 25, 30, 35]`. You are searching for the value `20` using binary search. What is the value of `mid` calculated in the **second** iteration of the binary search?\n\n**Choices:**\nA) 15\nB) 20\nC) 25\nD) 30\n\n**Correct Answer:**\n*   **Type:** mcq\n*   **Correct Index:** 1 (Option B)\n*   **Explanation:**\n    1.  **Initialization:** `low = 0`, `high = 6`.\n    2.  **First Iteration:** `mid = floor((0 + 6) / 2) = 3`. `A[3]` is `20`. Since `A[3]` equals the target `20`, the element is found. The search would typically terminate here. However, if the question implies continuing the process even after finding the element (or if the target was slightly different, requiring more steps), let's consider a target that *doesn't* end on the first step to properly illustrate a second iteration's mid-value calculation.\n\n    *Let's re-evaluate with a target that requires more steps to better illustrate the second iteration.*\n\n    **Revised Scenario for Problem 2:**\n    Consider a sorted array `A = [5, 10, 15, 20, 25, 30, 35]`. You are searching for the value `30` using binary search. What is the value of `mid` calculated in the **second** iteration of the binary search?\n\n    **Choices:**\n    A) 15\n    B) 20\n    C) 25\n    D) 30\n\n    **Correct Answer (Revised):**\n    *   **Type:** mcq\n    *   **Correct Index:** 2 (Option C)\n    *   **Explanation:**\n        1.  **Initialization:** `low = 0`, `high = 6`.\n        2.  **First Iteration:** `mid = floor((0 + 6) / 2) = 3`. `A[3]` is `20`. Since `20 < 30`, we update `low = mid + 1 = 4`.\n        3.  **Second Iteration:** `low = 4`, `high = 6`. `mid = floor((4 + 6) / 2) = 5`. `A[5]` is `30`. The target is found.\n        The value of `mid` calculated in the second iteration is `5`. The corresponding element is `A[5] = 30`.\n\n*(Self-correction: The original prompt's target `20` was found in the first iteration. The revised target `30` correctly demonstrates a second iteration's `mid` calculation.)*\n--- END AGENT OUTPUT ---\n\nNow respond ONLY with a single JSON object:\n{\n  \"score\": float,              // 0.0 to 1.0\n  \"passed\": bool,              // true if score >= 0.7\n  \"notes\": \"string\"          // short explanation\n}\n\njudge_agent > ```json\n{\n  \"score\": 0.9,\n  \"passed\": true,\n  \"notes\": \"The agent generated two problems clearly about binary search, suitable for an easy difficulty. Both are self-contained. The first problem is open-ended and the second is MCQ. Both include a solution/rubric. The agent had to self-correct Problem 2 twice to ensure it generated a scenario where a second iteration's mid value could be calculated, indicating some initial difficulty in precisely meeting the prompt's constraints. However, the final output is good.\"\n}\n```\n‚úÖ PASS ‚Äì score=0.90\nNotes: The agent generated two problems clearly about binary search, suitable for an easy difficulty. Both are self-contained. The first problem is open-ended and the second is MCQ. Both include a solution/rubric. The agent had to self-correct Problem 2 twice to ensure it generated a scenario where a second iteration's mid value could be calculated, indicating some initial difficulty in precisely meeting the prompt's constraints. However, the final output is good.\n\nüìã EVAL SUMMARY\n- Tests run: 2\n- Passed:    2\n- Avg score: 0.95\n\nüìä Current Algorithm Mentor metrics:\n  - num_explainer_calls: 0\n  - num_problem_gen_calls: 0\n  - num_viz_calls: 0\n  - num_diagnostic_turns: 0\n  - num_judge_calls: 4\n  - eval_runs: 2\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"_uuid":"31ff5303-d1ea-4afd-804d-9c987edc4b59","_cell_guid":"7b9d3258-97e2-4236-94e9-af638c17a10a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}